{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "import shutil \n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "logger = logging.getLogger(\"pymc\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# Function to get the current git tag\n",
    "def get_git_tag():\n",
    "        try:\n",
    "            tag = subprocess.check_output([\"git\", \"describe\", \"--tags\"], stderr=subprocess.DEVNULL).strip().decode()\n",
    "            return tag\n",
    "        except subprocess.CalledProcessError:\n",
    "            return \"No tag found\"\n",
    "\n",
    "\n",
    "def generate_iid_samples(posterior_type = None, num_samples=2000, rng=None,**params):\n",
    "    \"\"\"\n",
    "    Generate IID samples from a mixture distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "    - component_params: List of dictionaries with parameters for each component.\n",
    "    - num_samples: Number of samples to generate.\n",
    "    - weights: List of weights for the components.\n",
    "    - rng: Random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - iid_samples: Array of generated IID samples.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = rng or np.random.default_rng()\n",
    "\n",
    "    # Mapping from string names to scipy sampling functions\n",
    "    scipy_distributions = {\n",
    "        \"Normal\": lambda p: sp.norm.rvs(loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"StudentT\": lambda p: sp.t.rvs(df=p[\"nu\"], loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"Beta\": lambda p: sp.beta.rvs(a=p[\"a\"], b=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"Cauchy\": lambda p: sp.cauchy.rvs(loc=p[\"loc\"], scale=p[\"scale\"], size=num_samples, random_state=rng),\n",
    "        \"Laplace\": lambda p: sp.laplace.rvs(loc=p[\"mu\"], scale=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"MvNormal\": lambda p: rng.multivariate_normal(mean=np.array(p[\"mu\"]), cov=np.array(p[\"cov\"]), size=num_samples),\n",
    "    }\n",
    "\n",
    "    # Handle Skewed Student-T (which needs PyMC)\n",
    "    if posterior_type == \"SkewStudentT\":\n",
    "        with pm.Model():\n",
    "            skewed_t = pm.SkewStudentT.dist(a=params[\"a\"], b=params[\"b\"], mu=params[\"mu\"], sigma=params[\"sigma\"])\n",
    "            return pm.draw(skewed_t, draws=num_samples, random_seed=rng)\n",
    "\n",
    "    # Handle single distributions\n",
    "    if posterior_type in scipy_distributions:\n",
    "        return scipy_distributions[posterior_type](params)\n",
    "\n",
    "    elif posterior_type == \"Mixture\":\n",
    "        component_types = params[\"component_types\"]\n",
    "        component_params = params[\"component_params\"]\n",
    "        weights = params[\"weights\"]\n",
    "\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        # normalize weights\n",
    "        weights = np.array(weights) / np.sum(weights)\n",
    "\n",
    "        # Choose which component each sample belongs to based on weights\n",
    "        chosen_components = rng.choice(len(component_types), size=num_samples, p=weights)\n",
    "\n",
    "        # Determine if we are in a multivariate setting\n",
    "\n",
    "        first_param = next(iter(component_params[0].values()))\n",
    "        dim = len(first_param)\n",
    "\n",
    "        # Check if all components have the same dimension\n",
    "        for comp_params in component_params:\n",
    "            param = next(iter(comp_params.values()))  # Get first parameter of each component\n",
    "            if len(param) != dim:\n",
    "                raise ValueError(\"All mixture components must have the same dimensionality.\")\n",
    "\n",
    "        if dim > 1:\n",
    "            iid_samples = np.empty((num_samples, dim))  # Multivariate case\n",
    "        else:\n",
    "            iid_samples = np.empty(num_samples)\n",
    "\n",
    "        for i, (comp_type, comp_params) in enumerate(zip(component_types, component_params)):\n",
    "            mask = chosen_components == i  # Select samples for this component\n",
    "            num_selected = mask.sum()\n",
    "            if num_selected > 0:\n",
    "                if comp_type in scipy_distributions or comp_type == \"SkewStudentT\":\n",
    "                    iid_samples[mask] = generate_iid_samples(posterior_type=comp_type, num_samples=num_selected, rng=rng, **comp_params)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported component type in IID sampling: {comp_type}\")\n",
    "                \n",
    "        return iid_samples\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported posterior type: {posterior_type}\")\n",
    "\n",
    "\n",
    "def plot_histogram(samples, title, save_path=None, posterior_type=None):\n",
    "    \"\"\"\n",
    "    Plots a histogram and KDE of the given samples.\n",
    "\n",
    "    Parameters:\n",
    "    - samples: 1D or 2D array of samples.\n",
    "    - title: Title of the plot.\n",
    "    - save_path: If provided, saves the figure to this path.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if samples.ndim == 2:\n",
    "        # Handle multivariate case\n",
    "        if samples.shape[1] == 2:\n",
    "            plt.scatter(samples[:, 0], samples[:, 1], alpha=0.3, label=\"2D Samples\")\n",
    "            plt.xlabel(\"Dimension 1\")\n",
    "            plt.ylabel(\"Dimension 2\")\n",
    "            plt.title(title)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "        elif posterior_type == \"MvNormal\" and samples.shape[1] > 2:\n",
    "            print(f\"Skipping plotting: Multivariate Normal with dimension {samples.shape[1]}.\")\n",
    "            return\n",
    "        \n",
    "    else:\n",
    "        # Standard 1D histogram + KDE\n",
    "        plt.hist(samples, bins=50, alpha=0.5, density=True, color='blue', edgecolor='black', label=\"Histogram\")\n",
    "        sns.kdeplot(samples, color='red', lw=2, label=\"KDE\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Sample Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# needs to be adapted \n",
    "def get_initvals(init_scheme, means, num_chains, rng=None):\n",
    "    \"\"\"Generates initialization values based on the chosen scheme.\"\"\"\n",
    "\n",
    "    middle_point = sum(means) / 2\n",
    "\n",
    "    if init_scheme == \"half_per_mode\":\n",
    "        # Half the chains start near the first mode, half near the second mode\n",
    "        if init_scheme == \"half_per_mode\":\n",
    "            # Dynamically assign half the chains to means[0] and the other half to means[1]\n",
    "            initvals = [{\"w\": 0.5, \"mixed_normal\": means[i < num_chains // 2]} for i in range(num_chains)]\n",
    "\n",
    "           # initvals = [\n",
    "            #{\"mixed_normal\": 0},  # Chain 1\n",
    "            #{\"mixed_normal\": 0},  # Chain 2\n",
    "            #{\"mixed_normal\": 20},  # Chain 3\n",
    "            #{\"mixed_normal\": 20}   # Chain 4\n",
    "        #]\n",
    "\n",
    "    elif init_scheme == \"one_third_first_mode\":\n",
    "        # ðŸ”¹ 1/3 of chains start in first mode, 2/3 in second mode\n",
    "        num_first_mode = num_chains // 3  # 1/3 of chains\n",
    "        num_second_mode = num_chains - num_first_mode  # Remaining 2/3\n",
    "\n",
    "        initvals = (\n",
    "            [{\"mixed_normal\": means[0]} for _ in range(num_first_mode)] +\n",
    "            [{\"mixed_normal\": means[1]} for _ in range(num_second_mode)]\n",
    "        )\n",
    "\n",
    "    elif init_scheme == \"all_in_middle\":\n",
    "        # All chains start in the middle between the two modes\n",
    "        initvals = [{\"mixed_normal\": middle_point} for _ in range(num_chains)]\n",
    "\n",
    "    elif init_scheme == \"random\":\n",
    "        # Chains are initialized randomly between the modes\n",
    "        initvals = [\n",
    "            {\"mixed_normal\": rng.uniform(means[0], means[1])}\n",
    "            for _ in range(num_chains)\n",
    "        ]\n",
    "\n",
    "    elif init_scheme == \"all_near_first_mode\":\n",
    "        # All chains start near the first mode\n",
    "        initvals = [{\"mixed_normal\": means[0]} for _ in range(num_chains)]\n",
    "\n",
    "    elif init_scheme == \"all_near_second_mode\":\n",
    "        # All chains start near the second mode\n",
    "        initvals = [{\"mixed_normal\": means[1]} for _ in range(num_chains)]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown initialization scheme: {init_scheme}\")\n",
    "\n",
    "    print(f\"Initvals: {initvals}\")\n",
    "\n",
    "    return initvals\n",
    "\n",
    "\n",
    "def sliced_wasserstein_distance(X, Y, L=100):\n",
    "    \"\"\"\n",
    "    Computes the sliced Wasserstein distance (SWD_p) between two sets of samples.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: numpy array of shape (N, d) -> first sample set\n",
    "    - Y: numpy array of shape (N, d) -> second sample set\n",
    "    - L: int, number of random projections\n",
    "    - p: int, order of Wasserstein distance (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "    - SWD_p: float, the sliced Wasserstein distance\n",
    "    \"\"\"\n",
    "    \n",
    "    #X = X.reshape(-1, 1)\n",
    "    #Y = Y.reshape(-1, 1)\n",
    "    # Ensure X and Y are at least 2D\n",
    "\n",
    "    N, d = X.shape  # Assuming X and Y have the same shape\n",
    "    S = 0  # Accumulation variable\n",
    "\n",
    "    for _ in range(L):\n",
    "        # Sample a random unit vector (projection direction)\n",
    "        theta = np.random.randn(d)\n",
    "        theta /= np.linalg.norm(theta)  # Normalize to unit sphere\n",
    "\n",
    "        # Compute projections\n",
    "        alpha = X @ theta\n",
    "        beta = Y @ theta\n",
    "\n",
    "        # Compute 1D Wasserstein distance\n",
    "        W_i = sp.wasserstein_distance(alpha, beta)\n",
    "\n",
    "        # Accumulate\n",
    "        S += W_i\n",
    "\n",
    "    # Compute final SWD\n",
    "    SWD_p = (S / L) \n",
    "\n",
    "    return SWD_p\n",
    "\n",
    "\n",
    "class PosteriorExample:\n",
    "    \"\"\"Base class for different posterior types.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None  # Placeholder for the PyMC model\n",
    "    \n",
    "    def _define_posterior(self):\n",
    "        \"\"\"Subclasses should implement this method to define the posterior.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement _define_posterior()\")\n",
    "\n",
    "    def run_sampling(self, sampler_name, num_samples=2000, tune=1000, num_chains=2, initvals=None, init_scheme=None, run_random_seed=None):\n",
    "        \"\"\"Runs MCMC sampling using the chosen sampler.\"\"\"\n",
    "        \n",
    "        with self.model:\n",
    "\n",
    "            # Define which sampler to use\n",
    "            if sampler_name == \"Metro\":\n",
    "                sampler = pm.Metropolis()\n",
    "            elif sampler_name == \"HMC\":\n",
    "                sampler = pm.NUTS()\n",
    "            elif sampler_name == \"DEMetro\":\n",
    "                sampler = pm.DEMetropolis()\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown sampler: {sampler_name}\")\n",
    "           \n",
    "            if init_scheme != None:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler,initvals=initvals, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)    #initvals=initvals,\n",
    "            else:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)\n",
    "        \n",
    "        return trace\n",
    "\n",
    "\n",
    "class SinglePosterior(PosteriorExample):\n",
    "    def __init__(self, dist_name, dist_params):\n",
    "        \"\"\"\n",
    "        A flexible class for defining unimodal posteriors.\n",
    "\n",
    "        Parameters:\n",
    "        - dist_name: String specifying the name of the PyMC distribution (e.g., \"Normal\", \"StudentT\").\n",
    "        - dist_params: Dictionary containing the parameters for the distribution.\n",
    "        \"\"\"\n",
    "        self.dist_name = dist_name\n",
    "        self.dist_params = dist_params\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        with pm.Model() as model:\n",
    "            dist_class = getattr(pm, self.dist_name)   # Retrieve the distribution class from PyMC\n",
    "            posterior_var = dist_class(\"posterior_var\", **self.dist_params)\n",
    "        return model\n",
    "\n",
    "\n",
    "class MixturePosterior(PosteriorExample):\n",
    "    \n",
    "    def __init__(self, component_types, component_params, weights=None):\n",
    "        \"\"\"\n",
    "        A flexible mixture posterior allowing any number of components and arbitrary distributions.\n",
    "\n",
    "        Parameters:\n",
    "        - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "        - component_params: List of dictionaries, where each dictionary contains the parameters for the corresponding distribution.\n",
    "        - weights: List of weights for the mixture components (defaults to uniform).\n",
    "        \"\"\"\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(component_types))  # Default: Equal weights\n",
    "\n",
    "        if len(weights) != len(component_types):\n",
    "            raise ValueError(\"Number of weights must match number of components.\")\n",
    "\n",
    "        self.component_types = component_types\n",
    "        self.component_params = component_params\n",
    "        self.weights = weights\n",
    "\n",
    "        # Normalize weights\n",
    "        self.weights = np.array(self.weights) / np.sum(self.weights)\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        with pm.Model() as model:\n",
    "\n",
    "            # Detect if components are univariate or multivariate\n",
    "            first_comp_type = self.component_types[0]\n",
    "            is_multivariate = first_comp_type == \"MvNormal\"\n",
    "\n",
    "            # Ensure consistency: All components must be either univariate or multivariate\n",
    "            for dist_type in self.component_types:\n",
    "                if (dist_type == \"mv_normal\") != is_multivariate:\n",
    "                    raise ValueError(\"Cannot mix univariate and multivariate distributions in a single mixture model.\")\n",
    "\n",
    "            # Construct component distributions dynamically\n",
    "            components = []\n",
    "            for dist_type, params in zip(self.component_types, self.component_params):\n",
    "                try:\n",
    "                    dist_class = getattr(pm, dist_type)  # Retrieve PyMC distribution dynamically\n",
    "                    components.append(dist_class.dist(**params))  # Use `.dist()` to create distribution\n",
    "                except AttributeError:\n",
    "                    raise ValueError(f\"Unsupported distribution type: {dist_type}\")\n",
    "\n",
    "            # Mixture model\n",
    "            mixed_post_var = pm.Mixture(\"mixed_post_var\", w=self.weights, comp_dists=components)\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "class CustomPosterior(PosteriorExample):\n",
    "    \"\"\"\n",
    "    A flexible class to define custom posteriors using a user-specified log-probability function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logp_func, param_names, initvals=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - logp_func: Callable function that defines the log-probability.\n",
    "                     Must accept PyMC symbolic variables.\n",
    "        - param_names: List of parameter names required by logp_func.\n",
    "        - initvals: Optional dictionary for initial values.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior(logp_func, param_names, initvals)\n",
    "\n",
    "    def _define_posterior(self, logp_func, param_names, initvals):\n",
    "        with pm.Model() as model:\n",
    "            # Define parameters as model variables\n",
    "            params = {name: pm.Normal(name, mu=0, sigma=1) for name in param_names}\n",
    "\n",
    "            # Define the custom distribution using pm.CustomDist\n",
    "            pm.CustomDist(\"custom_distribution\", logp=logp_func, **params)\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "def run_experiment(\n",
    "    posterior_type,\n",
    "    config_descr,\n",
    "    runs,\n",
    "    varying_attribute, \n",
    "    varying_values,      \n",
    "    num_samples,\n",
    "    num_chains,\n",
    "    init_scheme=None,\n",
    "    base_random_seed=None,\n",
    "    **posterior_kwargs\n",
    "):\n",
    "    print(f\"\\n===== Config {config_descr} started! =====\\n\")\n",
    "\n",
    "    # Initialize random number generator\n",
    "    rng = np.random.default_rng(base_random_seed)\n",
    "\n",
    "    # Define required parameters for each posterior type\n",
    "    required_parameters = {\n",
    "        \"Mixture\": [\"component_types\", \"component_params\", \"weights\"],\n",
    "        \"Cauchy\": [\"loc\", \"scale\"],\n",
    "        \"Beta\": [\"a\", \"b\"],\n",
    "        \"Normal\": [\"mu\", \"sigma\"],\n",
    "        \"StudentT\": [\"nu\", \"mu\", \"sigma\"],\n",
    "        \"SkewStudentT\": [\"a\", \"b\", \"mu\", \"sigma\"],\n",
    "        \"Laplace\": [\"mu\", \"b\"],\n",
    "        \"MvNormal\": [\"mu\", \"cov\"],\n",
    "    }\n",
    "\n",
    "    # Validate that required keys exist (except for varying attributes)\n",
    "    required_keys = [k for k in required_parameters.get(posterior_type) if k != varying_attribute]\n",
    "    if not all(k in posterior_kwargs for k in required_keys):\n",
    "        raise ValueError(f\"{posterior_type} posterior requires {required_keys}\")\n",
    "\n",
    "    # Create keyword arguments for IID sample generation\n",
    "    iid_kwargs = {key: posterior_kwargs.get(key, \"varies\") for key in required_parameters.get(posterior_type)}\n",
    "\n",
    "    print(f\"Using IID sample settings: {iid_kwargs}\")\n",
    "\n",
    "    # Create configuration folder inside the experiment root\n",
    "    config_folder = os.path.join(experiment_root_folder, f\"{config_descr}_with_{runs}_runs\")\n",
    "    os.makedirs(config_folder)\n",
    "\n",
    "    # Define folder for saving histograms\n",
    "    iid_histogram_folder = os.path.join(config_folder, \"KDE and Histograms of IID Samples\")\n",
    "    os.makedirs(iid_histogram_folder)\n",
    "\n",
    "    # === Handle Precomputed IID Samples for Varying Attributes ===\n",
    "    iid_samples_dict = {}\n",
    "\n",
    "    if varying_attribute in iid_kwargs or varying_attribute == \"num_samples\":\n",
    "        # If num_samples or a posterior parameter varies, generate IID samples for each value\n",
    "        for value in varying_values:\n",
    "            if varying_attribute == \"num_samples\":\n",
    "                current_num_samples = value  # Update num_samples dynamically\n",
    "            else:\n",
    "                iid_kwargs[varying_attribute] = value  # Adjust the varying posterior parameter\n",
    "                current_num_samples = num_samples  # Use fixed num_samples if not varying\n",
    "                \n",
    "            iid_samples_dict[value] = generate_iid_samples(posterior_type=posterior_type ,**iid_kwargs, num_samples=current_num_samples, rng=rng)\n",
    "\n",
    "            #Plot histogram and KDE for each varying value\n",
    "            plot_histogram(\n",
    "                samples=iid_samples_dict[value],\n",
    "                title=f\"IID Samples Histogram & KDE ({varying_attribute}={value})\",\n",
    "                save_path=os.path.join(iid_histogram_folder, f\"iid_hist_kde_{varying_attribute}_{value}.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "            )\n",
    "\n",
    "    else:\n",
    "            \n",
    "        # If the posterior is fixed (var_attr == chain or var== init_scheme), generate IID samples once\n",
    "        iid_samples = generate_iid_samples(posterior_type=posterior_type, **iid_kwargs, num_samples=num_samples, rng=rng)\n",
    "\n",
    "        plot_histogram(\n",
    "                samples=iid_samples,\n",
    "                title=\"IID Samples Histogram & KDE (fixed posterior)\",\n",
    "                save_path=os.path.join(iid_histogram_folder, \"iid_hist_kde.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "        )\n",
    "\n",
    "    # === Experiment Setup ===\n",
    "    samples_per_chain = \"varies\" if varying_attribute in [\"num_samples\", \"num_chains\"] else num_samples // num_chains\n",
    "\n",
    "    experiment_metadata = {\n",
    "        \"config_descr\": config_descr,\n",
    "        \"runs\": runs,\n",
    "        \"posterior_type\": posterior_type,\n",
    "        \"varying_attribute\": varying_attribute,\n",
    "        \"varying_values\": varying_values,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"num_chains\": num_chains,\n",
    "        \"samples_per_chain\": samples_per_chain,\n",
    "        \"init_scheme\": init_scheme,\n",
    "        \"base_random_seed\": base_random_seed,\n",
    "        \"git_tag\": get_git_tag(),\n",
    "    }\n",
    "    experiment_metadata.update(iid_kwargs)  # Add posterior-specific parameters\n",
    "\n",
    "    # Save metadata\n",
    "    metadata_filename = os.path.join(config_folder, f\"metadata_config_{config_descr}.json\")\n",
    "    with open(metadata_filename, \"w\") as f:\n",
    "        json.dump(experiment_metadata, f, indent=4)\n",
    "\n",
    "    # Define fixed colors for each sampler\n",
    "    sampler_colors = {\n",
    "        \"Metro\": \"blue\",\n",
    "        \"HMC\": \"red\",\n",
    "        \"DEMetro\": \"green\"\n",
    "    }\n",
    "\n",
    "    # === Run the Experiment ===\n",
    "    for run_id in range(1, runs + 1):\n",
    "        print(f\"\\n===== Running {config_descr} - Run {run_id} =====\\n\")\n",
    "\n",
    "        run_random_seed = int(rng.integers(1_000_000))\n",
    "\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "        traces_folder = os.path.join(run_folder, \"traces_and_trace_plots\")\n",
    "        plots_folder = os.path.join(run_folder, \"plots_of_run\")\n",
    "        \n",
    "        os.makedirs(run_folder)\n",
    "        os.makedirs(results_folder)\n",
    "        os.makedirs(traces_folder)\n",
    "        os.makedirs(plots_folder)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for value in varying_values:\n",
    "\n",
    "            var_attr_folder = os.path.join(traces_folder, f\"{varying_attribute}_{value}\")\n",
    "            os.makedirs(var_attr_folder)\n",
    "\n",
    "            if varying_attribute in iid_kwargs:\n",
    "                posterior_kwargs[varying_attribute] = value \n",
    "\n",
    "            if varying_attribute == \"num_samples\":\n",
    "                num_samples = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"num_chains\":\n",
    "                num_chains = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"init_scheme\":\n",
    "                init_scheme = value\n",
    "\n",
    "            if posterior_type == \"Mixture\":\n",
    "                model = MixturePosterior(**posterior_kwargs)\n",
    "            else:\n",
    "                model = SinglePosterior(dist_name=posterior_type, dist_params=posterior_kwargs)\n",
    "\n",
    "            # Generate initialization values\n",
    "            if init_scheme != None:\n",
    "                initvals = get_initvals(init_scheme, posterior_kwargs.get(\"mode_means\", [0]), num_chains, rng)\n",
    "            else:\n",
    "                initvals = None\n",
    "           \n",
    "            # Get IID samples for the current varying value\n",
    "            if varying_attribute != \"init_scheme\" and varying_attribute != \"num_chains\":\n",
    "                iid_samples = iid_samples_dict[value] \n",
    "\n",
    "            # Run sampling for all samplers\n",
    "            for sampler_name in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "                print(f\"Running {sampler_name} with {varying_attribute} = {value}\")\n",
    "\n",
    "                # **Measure Computation Time**\n",
    "                start_time = time.time()\n",
    "                trace = model.run_sampling(\n",
    "                    sampler_name, num_samples=samples_per_chain, num_chains=num_chains, init_scheme=init_scheme,\n",
    "                    initvals = initvals, run_random_seed=run_random_seed\n",
    "                )\n",
    "                end_time = time.time()\n",
    "                runtime = end_time - start_time\n",
    "\n",
    "\n",
    "                # Optional direct plotting of the trace\n",
    "                #print(trace.posterior[\"mixed_normal\"].values[:, 0])  # First few samples of each chain\n",
    "                az.plot_trace(trace, compact=True)\n",
    "                plt.title(f\"Trace Plot ({sampler_name}, {varying_attribute} = {value})\")\n",
    "                plt.show()\n",
    "\n",
    "                # Save trace to NetCDF file\n",
    "                trace_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace.nc\")\n",
    "                az.to_netcdf(trace, trace_filename)\n",
    "\n",
    "                # Save trace plot\n",
    "                trace_plot_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace_plot.pdf\")\n",
    "                az.plot_trace(trace, compact=True)\n",
    "                plt.savefig(trace_plot_filename, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "\n",
    "                # Select correct posterior variable name\n",
    "                if posterior_type == \"Mixture\":\n",
    "                    post_var_name = \"mixed_post_var\"\n",
    "                else:\n",
    "                    post_var_name = \"posterior_var\"\n",
    "\n",
    "                posterior_samples = trace.posterior[post_var_name].values\n",
    "        \n",
    "                # Ensure posterior_samples always has shape (N, dims)\n",
    "                if posterior_samples.ndim == 2:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, 1) \n",
    "                else:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, posterior_samples.shape[-1])\n",
    "\n",
    "                # Ensure iid_samples always has shape (N, dims)\n",
    "                if iid_samples.ndim == 1:\n",
    "                    iid_samples = iid_samples[:, np.newaxis]\n",
    "                else:\n",
    "                    iid_samples = iid_samples.reshape(-1, iid_samples.shape[-1])\n",
    "                \n",
    "                ws_distance = sliced_wasserstein_distance(posterior_samples, iid_samples, L=5)\n",
    " \n",
    "                # Compute R-hat and ESS\n",
    "                r_hat = az.rhat(trace)[post_var_name].max().item()\n",
    "                ess = az.ess(trace)[post_var_name].min().item()\n",
    "\n",
    "                results.append({\n",
    "                    varying_attribute: value,\n",
    "                    \"sampler\": sampler_name,\n",
    "                    \"wasserstein_distance\": ws_distance,\n",
    "                    \"r_hat\": r_hat,\n",
    "                    \"ess\": ess,\n",
    "                    \"runtime\": runtime\n",
    "                })\n",
    "\n",
    "        # Convert results to DataFrame and save\n",
    "        df_results = pd.DataFrame(results)\n",
    "\n",
    "        # Handle tuple-based attributes consistently\n",
    "        if isinstance(df_results[varying_attribute].iloc[0], tuple):\n",
    "            if varying_attribute == \"mode_means\":\n",
    "                df_results[\"mode_distance\"] = df_results[varying_attribute].apply(lambda x: abs(x[1] - x[0]))\n",
    "                varying_attribute_for_plot = \"mode_distance\"\n",
    "            else:\n",
    "                df_results[varying_attribute] = df_results[varying_attribute].apply(str)\n",
    "                varying_attribute_for_plot = varying_attribute\n",
    "        else:\n",
    "            varying_attribute_for_plot = varying_attribute\n",
    "\n",
    "        # Sort the DataFrame by the final chosen attribute\n",
    "        df_results = df_results.sort_values(varying_attribute_for_plot, ascending=True)\n",
    "\n",
    "        # initialize plots for all samplers\n",
    "        fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\n",
    "        fig_rhat, ax_rhat = plt.subplots(figsize=(10, 6))\n",
    "        fig_ess, ax_ess = plt.subplots(figsize=(10, 6))\n",
    "        fig_time, ax_time = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "        for sampler in df_results[\"sampler\"].unique():\n",
    "            df_sampler = df_results[df_results[\"sampler\"] == sampler]\n",
    "            csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "            df_sampler.to_csv(csv_filename, index=False)\n",
    "\n",
    "            # Plot Wasserstein Distance\n",
    "            ax_ws.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"wasserstein_distance\"], \n",
    "                marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "            # Plot R-hat values\n",
    "            ax_rhat.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"r_hat\"], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "            \n",
    "            # Plot ESS values\n",
    "            ax_ess.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"ess\"], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "            # **Plot Computation Time**\n",
    "            ax_time.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"runtime\"], \n",
    "                        marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                        color=sampler_colors.get(sampler, \"black\"))\n",
    "            \n",
    "        \n",
    "        # Set dynamic axis labels and titles\n",
    "        attribute_label = \"Mode Distance\" if varying_attribute == \"mode_means\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "        \n",
    "        # ===== Finalize and Save Wasserstein Plot =====\n",
    "        ax_ws.set_xlabel(attribute_label)\n",
    "        ax_ws.set_ylabel(\"Wasserstein Distance\")\n",
    "        ax_ws.set_title(f\"Wasserstein Distance for Samplers (config =_{config_descr})\")\n",
    "        ax_ws.legend(title=\"Sampler\")\n",
    "        ax_ws.grid(True)\n",
    "        plot_filename = os.path.join(plots_folder, f\"Wasserstein_run_{run_id}.pdf\")\n",
    "        fig_ws.savefig(plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_ws)\n",
    "\n",
    "        # ===== Finalize and Save R-hat Plot =====\n",
    "        ax_rhat.set_xlabel(attribute_label)\n",
    "        ax_rhat.set_ylabel(\"R-hat\")\n",
    "        ax_rhat.set_title(f\"R-hat for Samplers (config =_{config_descr})\")\n",
    "        ax_rhat.legend(title=\"Sampler\")\n",
    "        ax_rhat.grid(True)\n",
    "        rhat_plot_filename = os.path.join(plots_folder, f\"R-hat_run_{run_id}.pdf\")\n",
    "        fig_rhat.savefig(rhat_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_rhat)\n",
    "\n",
    "        # ===== Finalize and Save ESS Plot =====\n",
    "        ax_ess.set_xlabel(attribute_label)\n",
    "        ax_ess.set_ylabel(\"ESS\")\n",
    "        ax_ess.set_title(f\"ESS for Samplers (config =_{config_descr})\")\n",
    "        ax_ess.legend(title=\"Sampler\")\n",
    "        ax_ess.grid(True)\n",
    "        ess_plot_filename = os.path.join(plots_folder, f\"ESS_run_{run_id}.pdf\")\n",
    "        fig_ess.savefig(ess_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_ess)\n",
    "\n",
    "        # ===== Finalize and Save Time Plot =====\n",
    "        ax_time.set_xlabel(attribute_label)\n",
    "        ax_time.set_ylabel(\"Computation Time (seconds)\")\n",
    "        ax_time.set_title(f\"Computation Time for Samplers (config =_{config_descr})\")\n",
    "        ax_time.legend(title=\"Sampler\")\n",
    "        ax_time.grid(True)\n",
    "        time_plot_filename = os.path.join(plots_folder, f\"ComputationTime_run_{run_id}.pdf\")\n",
    "        fig_time.savefig(time_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_time)\n",
    "\n",
    "\n",
    "    print(\"\\n===== All Runs Completed Successfully! =====\\n\")\n",
    "\n",
    "    # ===== GLOBAL RESULTS FOLDER =====\n",
    "    global_folder = os.path.join(config_folder, \"global_results\")\n",
    "    global_results_folder = os.path.join(global_folder, \"results\")\n",
    "    global_plots_folder = os.path.join(global_folder, \"plots\")\n",
    "\n",
    "    os.makedirs(global_folder)\n",
    "    os.makedirs(global_results_folder)\n",
    "    os.makedirs(global_plots_folder)\n",
    "\n",
    "    # Collect all results from all runs\n",
    "    df_all_runs = []\n",
    "\n",
    "    for run_id in range(1, runs + 1):\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "\n",
    "        for sampler in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "            csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "            df_run = pd.read_csv(csv_filename)\n",
    "            df_run[\"run_id\"] = run_id \n",
    "            df_run[\"sampler\"] = sampler  \n",
    "            df_all_runs.append(df_run)\n",
    "\n",
    "\n",
    "    # Combine all results into a single data frame \n",
    "    df_all_runs = pd.concat(df_all_runs, ignore_index=True)\n",
    "\n",
    "    if varying_attribute == \"mode_means\":\n",
    "        df_all_runs[\"mode_distance\"] = df_all_runs[varying_attribute].apply(lambda x: abs(eval(x)[1] - eval(x)[0]))\n",
    "        df_all_runs = df_all_runs.sort_values(\"mode_distance\", ascending=True)\n",
    "        varying_attribute_for_global_plot = \"mode_distance\"\n",
    "    else:\n",
    "        df_all_runs = df_all_runs.sort_values(varying_attribute, ascending=True)\n",
    "        varying_attribute_for_global_plot = varying_attribute\n",
    "\n",
    "\n",
    "    # Initialize global plots\n",
    "    fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\n",
    "    fig_rhat, ax_rhat = plt.subplots(figsize=(10, 6))\n",
    "    fig_ess, ax_ess = plt.subplots(figsize=(10, 6))\n",
    "    fig_time, ax_time = plt.subplots(figsize=(10, 6)) \n",
    "\n",
    "    for sampler in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "        df_sampler = df_all_runs[df_all_runs[\"sampler\"] == sampler]\n",
    "\n",
    "        # Pivot tables: rows = varying attribute, columns = run_id, values = metrics\n",
    "        df_ws = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"wasserstein_distance\")\n",
    "        df_rhat = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"r_hat\")\n",
    "        df_ess = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"ess\")\n",
    "        df_time = df_sampler.pivot_table(index=varying_attribute, columns=\"run_id\", values=\"runtime\")\n",
    "    \n",
    "        # Compute mean and standard deviation for error bars\n",
    "        ws_mean, ws_std = df_ws.mean(axis=1), df_ws.std(axis=1)\n",
    "        rhat_mean, rhat_std = df_rhat.mean(axis=1), df_rhat.std(axis=1)\n",
    "        ess_mean, ess_std = df_ess.mean(axis=1), df_ess.std(axis=1)\n",
    "        time_mean, time_std = df_time.mean(axis=1), df_time.std(axis=1)\n",
    "\n",
    "        color = sampler_colors.get(sampler, \"black\")\n",
    "\n",
    "        # Plot with error bars\n",
    "        ax_ws.errorbar(ws_mean.index, ws_mean, yerr=ws_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_rhat.errorbar(rhat_mean.index, rhat_mean, yerr=rhat_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_ess.errorbar(ess_mean.index, ess_mean, yerr=ess_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_time.errorbar(time_mean.index, time_mean, yerr=time_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "\n",
    "        # Save global averages \n",
    "        df_global_avg = pd.DataFrame({\n",
    "            varying_attribute: ws_mean.index,\n",
    "            \"global_avg_ws\": ws_mean.values,\n",
    "            \"global_avg_ws_std\": ws_std.values,\n",
    "            \"global_avg_rhat\": rhat_mean.values,\n",
    "            \"global_avg_rhat_std\": rhat_std.values,\n",
    "            \"global_avg_ess\": ess_mean.values,\n",
    "            \"global_avg_ess_std\": ess_std.values,\n",
    "            \"global_avg_time\": time_mean.values,\n",
    "            \"global_avg_time_std\": time_std.values\n",
    "        })\n",
    "\n",
    "        sampler_csv_filename = os.path.join(global_results_folder, f\"Global_results_{sampler}.csv\")\n",
    "        df_global_avg.to_csv(sampler_csv_filename, index=False)\n",
    "\n",
    "    # ===== Save Global Wasserstein Plot =====\n",
    "    ax_ws.set_xlabel(attribute_label)\n",
    "    ax_ws.set_ylabel(\"Average Wasserstein Distance\")\n",
    "    ax_ws.set_title(f\"Averaged Wasserstein Distance ({runs} Runs, config = {config_descr})\")\n",
    "    ax_ws.legend(title=\"Sampler\")\n",
    "    ax_ws.grid(True)\n",
    "    fig_ws.savefig(os.path.join(global_plots_folder, \"Wasserstein_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_ws)\n",
    "\n",
    "    # ===== Save Global R-hat Plot =====\n",
    "    ax_rhat.set_xlabel(attribute_label)\n",
    "    ax_rhat.set_ylabel(\"Average R-hat\")\n",
    "    ax_rhat.set_title(f\"Averaged R-hat Values ({runs} Runs, config = {config_descr})\")\n",
    "    ax_rhat.legend(title=\"Sampler\")\n",
    "    ax_rhat.grid(True)\n",
    "    fig_rhat.savefig(os.path.join(global_plots_folder, \"Rhat_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_rhat)\n",
    "\n",
    "    # ===== Save Global ESS Plot =====\n",
    "    ax_ess.set_xlabel(attribute_label)\n",
    "    ax_ess.set_ylabel(\"Average ESS\")\n",
    "    ax_ess.set_title(f\"Averaged ESS ({runs} Runs,  config = {config_descr})\")\n",
    "    ax_ess.legend(title=\"Sampler\")\n",
    "    ax_ess.grid(True)\n",
    "    fig_ess.savefig(os.path.join(global_plots_folder, \"ESS_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_ess)\n",
    "\n",
    "    # ===== Save Global Time Plot =====\n",
    "    ax_time.set_xlabel(attribute_label)\n",
    "    ax_time.set_ylabel(\"Average Computation Time (seconds)\")\n",
    "    ax_time.set_title(f\"Averaged Computation Time ({runs} Runs, config = {config_descr})\")\n",
    "    ax_time.legend(title=\"Sampler\")\n",
    "    ax_time.grid(True)\n",
    "    fig_time.savefig(os.path.join(global_plots_folder, \"Time_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_time)\n",
    "\n",
    "    print(f\"\\n===== Config {config_descr} Completed Successfully! =====\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def validate_config(config):\n",
    "    \"\"\"Checks if the config correctly defines one varying attribute and all other attributes are fixed.\"\"\"\n",
    "    \n",
    "    REQUIRED_ATTRIBUTES = {\n",
    "    \"config_descr\",\n",
    "    \"posterior_type\",\n",
    "    \"runs\",\n",
    "    \"num_samples\",\n",
    "    \"num_chains\",\n",
    "    \"varying_attribute\",\n",
    "    \"varying_values\",\n",
    "    }\n",
    "\n",
    "    # Posterior-specific required attributes\n",
    "    POSTERIOR_ATTRIBUTES = {\n",
    "        \"Cauchy\": {\"loc\", \"scale\"},\n",
    "        \"Beta\": {\"a\", \"b\"},\n",
    "        \"Normal\": {\"mu\", \"sigma\"},\n",
    "        \"StudentT\": {\"nu\", \"mu\", \"sigma\"},\n",
    "        \"Laplace\": {\"mu\", \"b\"},\n",
    "        \"SkewStudentT\": {\"a\", \"b\", \"mu\", \"sigma\"},\n",
    "        \"Mixture\": {\"component_types\", \"component_params\", \"weights\"},\n",
    "        \"MvNormal\": {\"mu\", \"cov\"}\n",
    "    }\n",
    "\n",
    "    OPTIONAL_ATTRIBUTES = {\"base_random_seed\", \"init_scheme\"}\n",
    "\n",
    "    if \"config_descr\" not in config:\n",
    "        raise ValueError(\"Config is missing 'config_descr'.\")\n",
    "    \n",
    "    config_descr = config[\"config_descr\"]\n",
    "\n",
    "    if \"varying_attribute\" not in config:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing 'varying_attribute'.\")\n",
    "    \n",
    "    varying_attr = config[\"varying_attribute\"]\n",
    "\n",
    "    # Ensure all required attributes are present\n",
    "    missing_attrs = REQUIRED_ATTRIBUTES - config.keys() - {varying_attr}\n",
    "\n",
    "    if missing_attrs:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing required attributes: {missing_attrs}.\")\n",
    "    \n",
    "    posterior_type = config[\"posterior_type\"]\n",
    "\n",
    "    if posterior_type not in POSTERIOR_ATTRIBUTES:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'posterior_type': '{posterior_type}'.\")\n",
    "\n",
    "    # Ensure varying_attribute is a recognized attribute\n",
    "    all_valid_attributes = REQUIRED_ATTRIBUTES.union(POSTERIOR_ATTRIBUTES[posterior_type], OPTIONAL_ATTRIBUTES)\n",
    "\n",
    "    if varying_attr not in all_valid_attributes:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'varying_attribute': '{varying_attr}'.\")\n",
    "    \n",
    "    if varying_attr in config:\n",
    "        raise ValueError(f\"Config '{config['config_descr']}' incorrectly defines '{varying_attr}' as both fixed and varying.\")\n",
    "\n",
    "    # Ensure all fixed attributes are present\n",
    "    for attr in all_valid_attributes - OPTIONAL_ATTRIBUTES - {varying_attr}:\n",
    "          if attr not in config:\n",
    "            raise ValueError(f\"Config '{config_descr}' is missing required fixed attribute '{attr}'.\")\n",
    "\n",
    "# to do: if init_schme is present, check that it is a valid init scheme\n",
    "\n",
    "\n",
    "\n",
    "# posterior_type = \"Cauchy\", \"Beta\", \"Normal\", \"StudentT\", \"Laplace\", \"SkewstudentT\"\n",
    "# varying_attribute = \"num_samples\", \"num_chains\", \"init_scheme\" or posterior specific attribute\n",
    "# bimmodal specific attributes = \"mode_means\", \"std_of_modes\", \"weights\"\n",
    "# cauchy specific attributes = \"loc\", \"scale\"\n",
    "# beta specific attributes = \"a\", \"b\"\n",
    "# normal specific attributes = \"mu\", \"sigma\"\n",
    "# student_t specific attributes = \"nu\", \"mu\", \"sigma\"\n",
    "# laplace specific attributes = \"mu\", \"b\"\n",
    "# skewed_student_t specific attributes = \"a\", \"b\", \"mu\", \"sigma\"\n",
    "# all but the varying attribute must be fixed and present in the config\n",
    "\n",
    "#def my_custom_logp_function(x):\n",
    "#    w1, w2 = 0.4, 0.6\n",
    "#    mu1, mu2 = -2, 2\n",
    "#    sigma1, sigma2 = 1, 1\n",
    "\n",
    "    #log_like1 = pm.logp(pm.Normal.dist(mu=mu1, sigma=sigma1), x)\n",
    "    #log_like2 = pm.logp(pm.Normal.dist(mu=mu2, sigma=sigma2), x)\n",
    "\n",
    "    #return pm.math.logsumexp([np.log(w1) + log_like1, np.log(w2) + log_like2])\n",
    "\n",
    "# default attributes\n",
    "default_num_samples = 1000\n",
    "default_num_chains = 4\n",
    "default_base_random_seed = 42\n",
    "default_runs = 1\n",
    "\n",
    "unimodal = [\n",
    "\n",
    "    #{\n",
    "    #    \"config_descr\": \"Normal\",\n",
    "    #    \"posterior_type\": \"normal\",\n",
    "    #    \"runs\": default_runs,\n",
    "    #    \"num_samples\": default_num_samples,\n",
    "    #    \"num_chains\": default_num_chains,\n",
    "    #    \"base_random_seed\": default_base_random_seed,\n",
    "    #    \"varying_attribute\": \"mu\",\n",
    "    #    \"varying_values\": [0, 4],\n",
    "    #    \"sigma\": 1\n",
    "    #},\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Student_t\",\n",
    "        \"posterior_type\": \"StudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\":  default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 3],\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Laplace_test\",\n",
    "        \"posterior_type\": \"Laplace\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"b\",\n",
    "        \"varying_values\": [2, 20],\n",
    "        \"mu\": 0,\n",
    "    },\n",
    "]\n",
    "\n",
    "high_dim_and_correlated = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_2d_low_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"mu\": [10, -20],\n",
    "        \"cov\": [[1, 0.1], [0.1, 1]]\n",
    "    },\n",
    "\n",
    "   # {\n",
    "   #     \"config_descr\": \"Mv_normal_2d_high_corr\",\n",
    "   #     \"posterior_type\": \"MvNormal\",\n",
    "   #     \"runs\": default_runs,\n",
    "   #     \"num_chains\": default_num_chains,\n",
    "   #     \"base_random_seed\": default_base_random_seed,\n",
    "   #     \"varying_attribute\": \"num_samples\",\n",
    "   #     \"varying_values\": [1000],\n",
    "   #     \"mu\": [10, -20],\n",
    "   #     \"cov\": [[1, 0.95], [0.95, 1]]  # Very strong correlation,\n",
    "   # },\n",
    "\n",
    "    #{\n",
    "    #    \"config_descr\": \"Mv_normal_3d_low_corr\",\n",
    "    #    \"posterior_type\": \"MvNormal\",\n",
    "    #    \"runs\": default_runs,\n",
    "    #    \"num_chains\": default_num_chains,\n",
    "    #    \"base_random_seed\": default_base_random_seed,\n",
    "    #    \"varying_attribute\": \"num_samples\",\n",
    "    #    \"varying_values\": [1000],\n",
    "    #    \"mu\":  [-50, 0, 50],\n",
    "    #    \"cov\": [[1, 0.2, 0.1], \n",
    "    #            [0.2, 1, 0.15], \n",
    "    #            [0.1, 0.15, 1]]  # Works (3D Normal)\n",
    "    #},\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_3d_high_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"mu\":  [-50, 0, 50],\n",
    "        \"cov\": [[1, 0.9, 0.85], \n",
    "              [0.9, 1, 0.88], \n",
    "              [0.85, 0.88, 1]]\n",
    "    }\n",
    "]\n",
    "\n",
    "multimodal = [\n",
    "\n",
    "    {   \n",
    "        \"config_descr\": \"Normal_and_student_t\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"StudentT\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"nu\": 3, \"mu\": 5, \"sigma\": 2}],\n",
    "        \"weights\": [0.6, 0.4]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"mu\": [10, 10], \"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.3, 0.4, 0.3]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "difficult_geometries = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"SkewStudentT\",\n",
    "        \"posterior_type\": \"SkewStudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [1, 2],\n",
    "        \"b\": 1,\n",
    "        \"mu\": 1,\n",
    "        \"sigma\": 1,\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All configurations are valid. Starting experiments...\n",
      "\n",
      "===== Config Normal_and_student_t started! =====\n",
      "\n",
      "Using IID sample settings: {'component_types': ['Normal', 'StudentT'], 'component_params': [{'mu': 0, 'sigma': 1}, {'nu': 3, 'mu': 5, 'sigma': 2}], 'weights': [0.6, 0.4]}\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'comp_params' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll configurations are valid. Starting experiments...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m experiment:\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposterior_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposterior_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_descr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_descr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvarying_attribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvarying_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_scheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_random_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_random_seed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_descr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_random_seed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposterior_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass remaining keys as posterior_kwargs\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll experiments completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 451\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(posterior_type, config_descr, runs, varying_attribute, varying_values, num_samples, num_chains, init_scheme, base_random_seed, **posterior_kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     iid_kwargs[varying_attribute] \u001b[38;5;241m=\u001b[39m value  \u001b[38;5;66;03m# Adjust the varying posterior parameter\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     current_num_samples \u001b[38;5;241m=\u001b[39m num_samples  \u001b[38;5;66;03m# Use fixed num_samples if not varying\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m iid_samples_dict[value] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_iid_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposterior_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposterior_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miid_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_num_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m#Plot histogram and KDE for each varying value\u001b[39;00m\n\u001b[1;32m    454\u001b[0m plot_histogram(\n\u001b[1;32m    455\u001b[0m     samples\u001b[38;5;241m=\u001b[39miid_samples_dict[value],\n\u001b[1;32m    456\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIID Samples Histogram & KDE (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvarying_attribute\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    457\u001b[0m     save_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(iid_histogram_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miid_hist_kde_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvarying_attribute\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    458\u001b[0m     posterior_type\u001b[38;5;241m=\u001b[39mposterior_type\n\u001b[1;32m    459\u001b[0m )\n",
      "Cell \u001b[0;32mIn[49], line 85\u001b[0m, in \u001b[0;36mgenerate_iid_samples\u001b[0;34m(posterior_type, num_samples, rng, **params)\u001b[0m\n\u001b[1;32m     81\u001b[0m chosen_components \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(component_types), size\u001b[38;5;241m=\u001b[39mnum_samples, p\u001b[38;5;241m=\u001b[39mweights)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Determine if we are in a multivariate setting\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m first_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mcomp_params\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m     86\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(first_param)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Check if all components have the same dimension\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'comp_params' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "categories = [unimodal, high_dim_and_correlated, multimodal, difficult_geometries]\n",
    "\n",
    "# Choose the experiment to run\n",
    "experiment = categories[2]\n",
    "experiment_name = \"test\"\n",
    "\n",
    "# Define the root directory for all experiments\n",
    "experiment_root_folder = f\"exp_{experiment_name}\"\n",
    "\n",
    "# Check if the folder already exists\n",
    "if os.path.exists(experiment_root_folder):\n",
    "    user_input = input(\n",
    "        f\"Folder '{experiment_root_folder}' already exists and will be overwritten.\\n\"\n",
    "        \"Do you want to continue? (yes/no): \"\n",
    "    ).strip().lower()\n",
    "\n",
    "    if user_input not in [\"yes\", \"y\"]:\n",
    "        print(\"Operation aborted. No files were deleted.\")\n",
    "        exit()  # Stop execution\n",
    "    \n",
    "    shutil.rmtree(experiment_root_folder)\n",
    "\n",
    "# Create the experiment directory\n",
    "os.makedirs(experiment_root_folder)\n",
    "\n",
    "for config in experiment:\n",
    "    validate_config(config)\n",
    "\n",
    "print(\"All configurations are valid. Starting experiments...\")\n",
    "\n",
    "for config in experiment:\n",
    "    run_experiment(\n",
    "    posterior_type=config[\"posterior_type\"],\n",
    "    config_descr=config[\"config_descr\"],\n",
    "    runs=config[\"runs\"],\n",
    "    varying_attribute=config[\"varying_attribute\"],\n",
    "    varying_values=config[\"varying_values\"],\n",
    "    init_scheme=\"varies\" if config[\"varying_attribute\"] == \"init_scheme\" else config.get(\"init_scheme\", None),\n",
    "    num_samples=\"varies\" if config[\"varying_attribute\"] == \"num_samples\" else config[\"num_samples\"],\n",
    "    num_chains=\"varies\" if config[\"varying_attribute\"] == \"num_chains\" else config[\"num_chains\"],\n",
    "    base_random_seed=config.get(\"base_random_seed\", None),\n",
    "    **{k: v for k, v in config.items() if k not in [\n",
    "        \"config_descr\", \"runs\", \"varying_attribute\", \"varying_values\", \n",
    "        \"num_samples\", \"num_chains\", \"init_scheme\", \n",
    "        \"base_random_seed\", \"posterior_type\"\n",
    "    ]}  # Pass remaining keys as posterior_kwargs\n",
    ")\n",
    "\n",
    "print(\"All experiments completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_all_inference_attr = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Samples_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",    \n",
    "        \"varying_values\": [100, 200, 300],\n",
    "        \"mode_means\": (3,-3),\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1)\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"config_descr\": \"Chains_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_chains\",    \n",
    "        \"varying_values\": [4,6,8],\n",
    "        \"mode_means\": (3,-3),\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1)\n",
    "    }\n",
    "    #add init scheme test\n",
    "\n",
    "    #add burn in as well?\n",
    "    ]\n",
    "\n",
    "\n",
    "# Can select any of the posterior_type kwargs to vary, e.g., for a normal distribution, mu or sigma can be varied\n",
    "Test_all_posterior_types = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Normal_test\",\n",
    "        \"posterior_type\": \"normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 1, 2],\n",
    "        \"sigma\": 1\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Beta_test\",\n",
    "        \"posterior_type\": \"beta\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [0.5,5,1],\n",
    "        \"b\": 3,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Cauchy_test\",\n",
    "        \"posterior_type\": \"cauchy\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"loc\",\n",
    "        \"varying_values\": [0, -2, 5],\n",
    "        \"scale\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Laplace_test\",\n",
    "        \"posterior_type\": \"laplace\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"b\",\n",
    "        \"varying_values\": [1, 2, 3, 20],\n",
    "        \"mu\": 0,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Student_t_test\",\n",
    "        \"posterior_type\": \"student_t\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\":  default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 3],\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Skewed_student_t_test\",\n",
    "        \"posterior_type\": \"skewed_student_t\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [0.5, 1, 2],\n",
    "        \"b\": 1,\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Bimodal_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mode_means\",\n",
    "        \"varying_values\": [(0,0), (1,1), (2,2)],\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1),\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "test_triple_normal = [\n",
    "    \n",
    "    {\n",
    "        \"config_descr\": \"Mixture_test\",\n",
    "        \"posterior_type\": \"mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000, 2000, 8000],\n",
    "        \"component_types\": [\"normal\", \"normal\", \"normal\"],\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 10, \"sigma\": 1}, {\"mu\": -40, \"sigma\": 1}],\n",
    "        \"weights\": [0.3, 0.5, 0.2]  # Uneven weighting\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "test_normal_and_student_t = [\n",
    "    \n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_test\",\n",
    "        \"posterior_type\": \"mixture\",\n",
    "        \"component_types\": [\"normal\", \"student_t\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [10000],\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"nu\": 3, \"mu\": 5, \"sigma\": 2}],\n",
    "        \"weights\": [0.6, 0.4]\n",
    "        }\n",
    "]\n",
    "\n",
    "test_mvnormal_2d_mixture = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"MVNormal_mixture\",\n",
    "        \"posterior_type\": \"mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"component_types\": [\"mv_normal\", \"mv_normal\", \"mv_normal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},   # First component\n",
    "                {\"mu\": [10, 10], \"cov\": [[2, 0.3], [0.3, 2]]},  # Second component\n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  # Third component\n",
    "        ],\n",
    "        \"weights\": [0.3, 0.4, 0.3]\n",
    "    }\n",
    "        \n",
    "]\n",
    "\n",
    "test_mvnormal = [\n",
    "    {\n",
    "        \"config_descr\": \"MVNormal_test\",\n",
    "        \"posterior_type\": \"mv_normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"mu\": [10, -20],\n",
    "        #\"cov\": [[1, 0.5], [0.5, 1]]\n",
    "        \"cov\": [[1, 0.95], [0.95, 1]]  # Very strong correlation,\n",
    "    }\n",
    "]\n",
    "\n",
    "test_3d_normal = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"MVNormal_test\",\n",
    "        \"posterior_type\": \"mv_normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"mu\":  [-50, 0, 50],\n",
    "        \"cov\":  [[1, 0.8, 0.3], [0.8, 1, 0.4], [0.3, 0.4, 1]]  # Works (3D Normal)\n",
    "\n",
    "    }   \n",
    "\n",
    "]\n",
    "\n",
    "#Test_custom = [\n",
    "#    {\n",
    "#        \"config_descr\": \"custom_gaussian_mixture\",\n",
    "#        \"posterior_type\": \"custom\",\n",
    "#        \"runs\": 5,\n",
    "#        \"num_samples\": default_num_samples,\n",
    "#        \"num_chains\": default_num_chains,\n",
    "#        \"base_random_seed\": 42,\n",
    "#        #\"logp_func\": my_custom_logp_function,  # Custom function\n",
    "#        #\"priors\": {\"x\": pm.Uniform.dist(lower=-10, upper=10)}\n",
    "#    }\n",
    "#]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_immo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
