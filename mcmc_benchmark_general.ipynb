{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "import shutil \n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "import humanize \n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "logger = logging.getLogger(\"pymc\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# Function to get the current git tag\n",
    "def get_git_tag():\n",
    "        try:\n",
    "            tag = subprocess.check_output([\"git\", \"describe\", \"--tags\"], stderr=subprocess.DEVNULL).strip().decode()\n",
    "            return tag\n",
    "        except subprocess.CalledProcessError:\n",
    "            return \"No tag found\"\n",
    "\n",
    "def create_directories(*paths):\n",
    "    \"\"\"Creates multiple directories if they don't exist.\"\"\"\n",
    "    for path in paths:\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def plot_and_save_all_metrics(df_results, sampler_colors, varying_attribute, varying_attribute_for_plot, results_folder, plots_folder, run_id, config_descr):\n",
    "    \"\"\"\n",
    "    Generates and saves multiple metric plots for different samplers.\n",
    "\n",
    "    Parameters:\n",
    "    - df_results: DataFrame containing experiment results.\n",
    "    - sampler_colors: Dictionary mapping sampler names to colors.\n",
    "    - varying_attribute: The attribute that varies.\n",
    "    - varying_attribute_for_plot: The attribute used for plotting.\n",
    "    - plots_folder: Folder where plots should be saved.\n",
    "    - run_id: ID of the current run.\n",
    "    - config_descr: Description of the configuration.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define metric labels\n",
    "    metrics = [\"wasserstein_distance\", \"r_hat\", \"ess\", \"runtime\"]\n",
    "\n",
    "    # Initialize plots for all metrics\n",
    "    fig_ax_pairs = {key: plt.subplots(figsize=(10, 6)) for key in metrics}\n",
    "\n",
    "    # Iterate over samplers and plot all metrics\n",
    "    for sampler in df_results[\"sampler\"].unique():\n",
    "        df_sampler = df_results[df_results[\"sampler\"] == sampler]\n",
    "        csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "        df_sampler.to_csv(csv_filename, index=False)\n",
    "\n",
    "        for metric in metrics:\n",
    "            fig, ax = fig_ax_pairs[metric]\n",
    "            ax.plot(df_sampler[varying_attribute_for_plot], df_sampler[metric], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "    # Set dynamic axis labels and save plots\n",
    "    attribute_label = \"Mode Distance\" if varying_attribute == \"mu\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "\n",
    "    for metric in metrics:\n",
    "        fig, ax = fig_ax_pairs[metric]\n",
    "        finalize_and_save_plot(fig,ax, attribute_label, metric, \n",
    "                               f\"{metric} for Samplers (config =_{config_descr})\",\n",
    "                               os.path.join(plots_folder, f\"{metric}_run_{run_id}.pdf\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_and_save_global_metrics(df_all_runs, sampler_colors, varying_attribute, runs, config_descr, global_results_folder, global_plots_folder):\n",
    "    \"\"\"\n",
    "    Computes and saves global metric plots (averaged across runs) for different samplers.\n",
    "\n",
    "    Parameters:\n",
    "    - df_all_runs: DataFrame containing results from all runs.\n",
    "    - sampler_colors: Dictionary mapping sampler names to colors.\n",
    "    - varying_attribute: The attribute that varies.\n",
    "    - runs: Number of experiment runs.\n",
    "    - config_descr: Configuration description.\n",
    "    - global_results_folder: Folder to save CSVs.\n",
    "    - global_plots_folder: Folder to save plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle varying attributes for plotting\n",
    "    if varying_attribute == \"mode_means\":\n",
    "        df_all_runs[\"mode_distance\"] = df_all_runs[varying_attribute].apply(lambda x: abs(eval(x)[1] - eval(x)[0]))\n",
    "        df_all_runs = df_all_runs.sort_values(\"mode_distance\", ascending=True)\n",
    "        varying_attribute_for_plot = \"mode_distance\"\n",
    "    else:\n",
    "        df_all_runs = df_all_runs.sort_values(varying_attribute, ascending=True)\n",
    "        varying_attribute_for_plot = varying_attribute\n",
    "\n",
    "    # Define metrics for aggregation\n",
    "    metrics = [\"wasserstein_distance\", \"r_hat\", \"ess\", \"runtime\"]\n",
    "\n",
    "    # Initialize global plots\n",
    "    fig_ax_pairs_bars = {metric: plt.subplots(figsize=(10, 6)) for metric in metrics}\n",
    "\n",
    "    # New figure set (line + fill)\n",
    "    fig_ax_pairs_shaded = {metric: plt.subplots(figsize=(10, 6))\n",
    "                       for metric in metrics}\n",
    "\n",
    "\n",
    "\n",
    "    for sampler in df_all_runs[\"sampler\"].unique():\n",
    "        df_sampler = df_all_runs[df_all_runs[\"sampler\"] == sampler]\n",
    "        color = sampler_colors.get(sampler, \"black\")\n",
    "\n",
    "\n",
    "        # Pivot tables: rows = varying attribute, columns = run_id, values = metric\n",
    "        df_pivot = {metric: df_sampler.pivot_table(index=varying_attribute_for_plot, columns=\"run_id\", values=metric)\n",
    "                    for metric in metrics}\n",
    "\n",
    "        # Compute mean and standard deviation\n",
    "        metric_stats = {metric: (df_pivot[metric].mean(axis=1), df_pivot[metric].std(axis=1))\n",
    "                        for metric in metrics}\n",
    "\n",
    "        for metric, (mean, std) in metric_stats.items():\n",
    "            fig_bars, ax_bars = fig_ax_pairs_bars[metric]\n",
    "            ax_bars.errorbar(mean.index, mean, yerr=std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "\n",
    "            # New figure set (line + shaded area)\n",
    "            fig_shaded, ax_shaded = fig_ax_pairs_shaded[metric]\n",
    "            ax_shaded.plot(mean.index, mean, \"o-\", label=sampler, color=color)\n",
    "            ax_shaded.fill_between(mean.index, mean - std, mean + std, \n",
    "                                color=color, alpha=0.2)\n",
    "            \n",
    "        # Save global averages CSV\n",
    "        df_global_avg = pd.DataFrame({\n",
    "            varying_attribute: metric_stats[\"wasserstein_distance\"][0].index,\n",
    "            **{f\"global_avg_{metric}\": metric_stats[metric][0].values for metric in metrics},\n",
    "            **{f\"global_avg_{metric}_std\": metric_stats[metric][1].values for metric in metrics},\n",
    "        })\n",
    "\n",
    "\n",
    "        csv_filename = os.path.join(global_results_folder, f\"Global_results_{sampler}.csv\")\n",
    "        df_global_avg.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Save plots\n",
    "    attribute_label = \"Mode Distance\" if varying_attribute == \"mu\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "    for metric in metrics:\n",
    "        fig_bar, ax_bar = fig_ax_pairs_bars[metric]\n",
    "        fig_shaded, ax_shaded = fig_ax_pairs_shaded[metric]\n",
    "        finalize_and_save_plot(fig_bar, ax_bar, attribute_label, metric,\n",
    "                               f\"Averaged {metric.replace('_', ' ').title()} ({runs} Runs, config = {config_descr})\",\n",
    "                               os.path.join(global_plots_folder, f\"{metric}_global_plot.pdf\"))\n",
    "        \n",
    "        finalize_and_save_plot(fig_shaded, ax_shaded, attribute_label, metric,\n",
    "                               f\"Averaged {metric.replace('_', ' ').title()} ({runs} Runs, config = {config_descr})\",\n",
    "                               os.path.join(global_plots_folder, f\"{metric}_global_plot_shaded.pdf\"))\n",
    "\n",
    "\n",
    "\n",
    "def finalize_and_save_plot(fig, ax, xlabel, ylabel, title, save_path):\n",
    "    \"\"\"\n",
    "    Finalizes the plot with labels, grid, and saves it to a file.\n",
    "    \n",
    "    Parameters:\n",
    "    - fig: Matplotlib figure\n",
    "    - ax: Matplotlib axis\n",
    "    - xlabel: Label for x-axis\n",
    "    - ylabel: Label for y-axis\n",
    "    - title: Title of the plot\n",
    "    - save_path: Path to save the figure.\n",
    "    \"\"\"\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(title=\"Sampler\")\n",
    "    ax.grid(True)\n",
    "    fig.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram(samples, title, save_path=None, posterior_type=None):\n",
    "    \"\"\"\n",
    "    Plots a histogram and KDE of the given samples.\n",
    "\n",
    "    Parameters:\n",
    "    - samples: 1D or 2D array of samples.\n",
    "    - title: Title of the plot.\n",
    "    - save_path: If provided, saves the figure to this path.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if samples.ndim == 2:\n",
    "        # Handle multivariate case\n",
    "        if samples.shape[1] == 2:\n",
    "            plt.scatter(samples[:, 0], samples[:, 1], alpha=0.3, label=\"2D Samples\")\n",
    "            plt.xlabel(\"Dimension 1\")\n",
    "            plt.ylabel(\"Dimension 2\")\n",
    "            plt.title(title)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "        elif posterior_type == \"MvNormal\" and samples.shape[1] > 2:\n",
    "            print(f\"Skipping plotting: Multivariate Normal with dimension {samples.shape[1]}.\")\n",
    "            return\n",
    "        \n",
    "    else:\n",
    "        # Standard 1D histogram + KDE\n",
    "        plt.hist(samples, bins=50, alpha=0.5, density=True, color='blue', edgecolor='black', label=\"Histogram\")\n",
    "        sns.kdeplot(samples, color='red', lw=2, label=\"KDE\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Sample Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def generate_iid_samples(posterior_type = None, num_samples=2000, rng=None,**params):\n",
    "    \"\"\"\n",
    "    Generate IID samples from a mixture distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "    - component_params: List of dictionaries with parameters for each component.\n",
    "    - num_samples: Number of samples to generate.\n",
    "    - weights: List of weights for the components.\n",
    "    - rng: Random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - iid_samples: Array of generated IID samples.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = rng or np.random.default_rng()\n",
    "\n",
    "    # Mapping from string names to scipy sampling functions\n",
    "    scipy_distributions = {\n",
    "        \"Normal\": lambda p: sp.norm.rvs(loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"StudentT\": lambda p: sp.t.rvs(df=p[\"nu\"], loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"Beta\": lambda p: sp.beta.rvs(a=p[\"a\"], b=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"Cauchy\": lambda p: sp.cauchy.rvs(loc=p[\"loc\"], scale=p[\"scale\"], size=num_samples, random_state=rng),\n",
    "        \"Laplace\": lambda p: sp.laplace.rvs(loc=p[\"mu\"], scale=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"MvNormal\": lambda p: rng.multivariate_normal(mean=np.array(p[\"mu\"]), cov=np.array(p[\"cov\"]), size=num_samples),\n",
    "    }\n",
    "\n",
    "    # Handle Skewed Student-T (which needs PyMC)\n",
    "    if posterior_type == \"SkewStudentT\":\n",
    "        with pm.Model():\n",
    "            skewed_t = pm.SkewStudentT.dist(a=params[\"a\"], b=params[\"b\"], mu=params[\"mu\"], sigma=params[\"sigma\"])\n",
    "            return pm.draw(skewed_t, draws=num_samples, random_seed=rng)\n",
    "\n",
    "    # Handle single distributions\n",
    "    if posterior_type in scipy_distributions:\n",
    "        print(f\"Generating {posterior_type} samples...\", params)\n",
    "        return scipy_distributions[posterior_type](params)\n",
    "\n",
    "    elif posterior_type == \"Mixture\":\n",
    "        component_types = params[\"component_types\"]\n",
    "        component_params = params[\"component_params\"]\n",
    "        weights = params[\"weights\"]\n",
    "\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        # normalize weights\n",
    "        weights = np.array(weights) / np.sum(weights)\n",
    "\n",
    "        # Choose which component each sample belongs to based on weights\n",
    "        chosen_components = rng.choice(len(component_types), size=num_samples, p=weights)\n",
    "\n",
    "        posterior_dim = None  \n",
    "\n",
    "        # Check if all components have the same dimension\n",
    "        for comp_params in component_params:\n",
    "            first_param = next(iter(comp_params))  # Get first parameter of current component\n",
    "            first_value = comp_params[first_param]  # Get its value\n",
    "            comp_dim = len(first_value) if isinstance(first_value, (np.ndarray, list)) else 1 # Get dimensionality of the first parameter\n",
    "\n",
    "            if posterior_dim is None:\n",
    "                posterior_dim = comp_dim  # Set the posterior dimension based on the first component\n",
    "               \n",
    "            elif comp_dim != posterior_dim:\n",
    "                raise ValueError(\"All mixture components must have the same dimensionality.\")\n",
    "\n",
    "        if posterior_dim > 1:\n",
    "            iid_samples = np.empty((num_samples, posterior_dim))  # Multivariate case\n",
    "        else:\n",
    "            iid_samples = np.empty(num_samples)\n",
    "\n",
    "        for i, (comp_type, comp_params) in enumerate(zip(component_types, component_params)):\n",
    "            mask = chosen_components == i  # Select samples for this component\n",
    "            num_selected = mask.sum()\n",
    "            if num_selected > 0:\n",
    "                if comp_type in scipy_distributions or comp_type == \"SkewStudentT\":\n",
    "                    iid_samples[mask] = generate_iid_samples(posterior_type=comp_type, num_samples=num_selected, rng=rng, **comp_params)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported component type in IID sampling: {comp_type}\")\n",
    "                \n",
    "        return iid_samples\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported posterior type: {posterior_type}\")\n",
    "\n",
    "\n",
    "def extract_means_from_components(component_params):\n",
    "    \"\"\"\n",
    "    Extracts central tendency (mu or loc) from each component's parameters.\n",
    "    \"\"\"\n",
    "    means = []\n",
    "    for params in component_params:\n",
    "        if \"mu\" in params:\n",
    "            means.append(params[\"mu\"])\n",
    "        elif \"loc\" in params:\n",
    "            means.append(params[\"loc\"])\n",
    "        else:\n",
    "            raise ValueError(\"Component missing a central tendency parameter (mu or loc).\")\n",
    "    return means\n",
    "\n",
    "\n",
    "def get_initvals(init_scheme, means, num_chains, rng=None):\n",
    "    \"\"\"Generates initialization values based on the chosen scheme.\"\"\"\n",
    "\n",
    "    if init_scheme == \"equal_per_mode\":\n",
    "        initvals = [{\"mixed_post_var\": means[i % len(means)]} for i in range(num_chains)]\n",
    "\n",
    "\n",
    "    elif init_scheme == \"all_in_middle\":\n",
    "        means_array = np.array(means)\n",
    "        middle_point = np.mean(means_array, axis=0)\n",
    "        initvals = [{\"mixed_post_var\": middle_point} for _ in range(num_chains)]\n",
    "\n",
    "    elif init_scheme == \"random\":\n",
    "        means_array = np.array(means)\n",
    "        if means_array.shape[0] < 2:\n",
    "            raise ValueError(\"random init_scheme requires at least 2 modes.\")\n",
    "            \n",
    "        # Compute bounding box across all dimensions\n",
    "        min_mode = np.min(means_array, axis=0)\n",
    "        max_mode = np.max(means_array, axis=0)\n",
    "        border = (max_mode - min_mode) / len(means)\n",
    "\n",
    "        low = min_mode - border\n",
    "        high = max_mode + border\n",
    "\n",
    "        initvals = [\n",
    "            {\"mixed_post_var\": rng.uniform(low, high)}\n",
    "            for _ in range(num_chains)\n",
    "        ]\n",
    "\n",
    "\n",
    "    elif init_scheme.startswith(\"all_near_mode_\"):\n",
    "        try:\n",
    "            mode_index = int(init_scheme.split(\"_\")[-1])\n",
    "            if mode_index >= len(means):\n",
    "                raise IndexError(f\"Mode index {mode_index} out of bounds for available means.\")\n",
    "            initvals = [{\"mixed_post_var\": means[mode_index]} for _ in range(num_chains)]\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Invalid mode index in init_scheme: '{init_scheme}'\")\n",
    "\n",
    "    print(f\"Initvals: {initvals}\")\n",
    "\n",
    "    return initvals\n",
    "\n",
    "\n",
    "def sliced_wasserstein_distance(X, Y, L=100):\n",
    "    \"\"\"\n",
    "    Computes the sliced Wasserstein distance (SWD_p) between two sets of samples.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: numpy array of shape (N, d) -> first sample set\n",
    "    - Y: numpy array of shape (N, d) -> second sample set\n",
    "    - L: int, number of random projections\n",
    "    - p: int, order of Wasserstein distance (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "    - SWD_p: float, the sliced Wasserstein distance\n",
    "    \"\"\"\n",
    "    \n",
    "    #X = X.reshape(-1, 1)\n",
    "    #Y = Y.reshape(-1, 1)\n",
    "    # Ensure X and Y are at least 2D\n",
    "\n",
    "    N, d = X.shape  # Assuming X and Y have the same shape\n",
    "    S = 0  # Accumulation variable\n",
    "\n",
    "    for _ in range(L):\n",
    "        # Sample a random unit vector (projection direction)\n",
    "        theta = np.random.randn(d)\n",
    "        theta /= np.linalg.norm(theta)  # Normalize to unit sphere\n",
    "\n",
    "        # Compute projections\n",
    "        alpha = X @ theta\n",
    "        beta = Y @ theta\n",
    "\n",
    "        # Compute 1D Wasserstein distance\n",
    "        W_i = sp.wasserstein_distance(alpha, beta)\n",
    "\n",
    "        # Accumulate\n",
    "        S += W_i\n",
    "\n",
    "    # Compute final SWD\n",
    "    SWD_p = (S / L) \n",
    "\n",
    "    return SWD_p\n",
    "\n",
    "\n",
    "class PosteriorExample:\n",
    "    \"\"\"Base class for different posterior types.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None  # Placeholder for the PyMC model\n",
    "    \n",
    "    def _define_posterior(self):\n",
    "        \"\"\"Subclasses should implement this method to define the posterior.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement _define_posterior()\")\n",
    "\n",
    "    def run_sampling(self, sampler_name, num_samples=2000, tune=1000, num_chains=2, initvals=None, init_scheme=None, run_random_seed=None):\n",
    "        \"\"\"Runs MCMC sampling using the chosen sampler.\"\"\"\n",
    "        \n",
    "        with self.model:\n",
    "\n",
    "            # Define which sampler to use\n",
    "            if sampler_name == \"Metro\":\n",
    "                sampler = pm.Metropolis()\n",
    "            elif sampler_name == \"HMC\":\n",
    "                sampler = pm.NUTS()\n",
    "            elif sampler_name == \"DEMetro\":\n",
    "                sampler = pm.DEMetropolis()\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown sampler: {sampler_name}\")\n",
    "           \n",
    "            if init_scheme != None:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler,initvals=initvals, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)    #initvals=initvals,\n",
    "            else:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)\n",
    "        \n",
    "        return trace\n",
    "\n",
    "\n",
    "class SinglePosterior(PosteriorExample):\n",
    "    def __init__(self, dist_name, dist_params):\n",
    "        \"\"\"\n",
    "        A flexible class for defining unimodal posteriors.\n",
    "\n",
    "        Parameters:\n",
    "        - dist_name: String specifying the name of the PyMC distribution (e.g., \"Normal\", \"StudentT\").\n",
    "        - dist_params: Dictionary containing the parameters for the distribution.\n",
    "        \"\"\"\n",
    "        self.dist_name = dist_name\n",
    "        self.dist_params = dist_params\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        \n",
    "        dist_class = getattr(pm, self.dist_name)   # Retrieve the distribution class from PyMC\n",
    "        \n",
    "        with pm.Model() as model:\n",
    "            posterior_var = dist_class(\"posterior_var\", **self.dist_params)\n",
    "        return model\n",
    "\n",
    "\n",
    "class MixturePosterior(PosteriorExample):\n",
    "    \n",
    "    def __init__(self, component_types, component_params, weights=None, varying_component=None): \n",
    "        \"\"\"\n",
    "        A flexible mixture posterior allowing any number of components and arbitrary distributions.\n",
    "\n",
    "        Parameters:\n",
    "        - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "        - component_params: List of dictionaries, where each dictionary contains the parameters for the corresponding distribution.\n",
    "        - weights: List of weights for the mixture components (defaults to uniform).\n",
    "        \"\"\"\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(component_types))  # Default: Equal weights\n",
    "\n",
    "        if len(weights) != len(component_types):\n",
    "            raise ValueError(\"Number of weights must match number of components.\")\n",
    "\n",
    "        self.component_types = component_types\n",
    "        self.component_params = component_params\n",
    "        self.weights = weights\n",
    "\n",
    "        # Normalize weights\n",
    "        self.weights = np.array(self.weights) / np.sum(self.weights)\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        \n",
    "        # Construct component distributions dynamically\n",
    "        components = []\n",
    "        for dist_type, params in zip(self.component_types, self.component_params):\n",
    "            try:\n",
    "                dist_class = getattr(pm, dist_type)  # Retrieve PyMC distribution dynamically\n",
    "                components.append(dist_class.dist(**params))  # Use `.dist()` to create distribution\n",
    "            except AttributeError:\n",
    "                raise ValueError(f\"Unsupported distribution type: {dist_type}\")\n",
    "            \n",
    "        # Define the mixture model    \n",
    "        with pm.Model() as model:\n",
    "            # Mixture model\n",
    "            mixed_post_var = pm.Mixture(\"mixed_post_var\", w=self.weights, comp_dists=components)\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "class CustomPosterior(PosteriorExample):\n",
    "    \"\"\"\n",
    "    A flexible class to define custom posteriors using a user-specified log-probability function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logp_func, param_names, initvals=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - logp_func: Callable function that defines the log-probability.\n",
    "                     Must accept PyMC symbolic variables.\n",
    "        - param_names: List of parameter names required by logp_func.\n",
    "        - initvals: Optional dictionary for initial values.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior(logp_func, param_names, initvals)\n",
    "\n",
    "    def _define_posterior(self, logp_func, param_names, initvals):\n",
    "        with pm.Model() as model:\n",
    "            # Define parameters as model variables\n",
    "            params = {name: pm.Normal(name, mu=0, sigma=1) for name in param_names}\n",
    "\n",
    "            # Define the custom distribution using pm.CustomDist\n",
    "            pm.CustomDist(\"custom_distribution\", logp=logp_func, **params)\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "def run_experiment(\n",
    "    experiment_settings,\n",
    "    posterior_type,\n",
    "    config_descr,\n",
    "    runs,\n",
    "    varying_attribute, \n",
    "    varying_values,      \n",
    "    num_samples,\n",
    "    num_chains,\n",
    "    init_scheme=None,\n",
    "    base_random_seed=None,\n",
    "    **posterior_kwargs\n",
    "):\n",
    "    print(f\"\\n===== Config {config_descr} started! =====\\n\")\n",
    "\n",
    "    # Initialize random number generator\n",
    "    rng = np.random.default_rng(base_random_seed)\n",
    "\n",
    "    # Define required parameters for each posterior type\n",
    "    required_parameters = {\n",
    "        \"Mixture\": [\"component_types\", \"component_params\", \"weights\"],\n",
    "        \"Cauchy\": [\"loc\", \"scale\"],\n",
    "        \"Beta\": [\"a\", \"b\"],\n",
    "        \"Normal\": [\"mu\", \"sigma\"],\n",
    "        \"StudentT\": [\"nu\", \"mu\", \"sigma\"],\n",
    "        \"SkewStudentT\": [\"a\", \"b\", \"mu\", \"sigma\"],\n",
    "        \"Laplace\": [\"mu\", \"b\"],\n",
    "        \"MvNormal\": [\"mu\", \"cov\"],\n",
    "    }\n",
    "\n",
    "    # Validate that required keys exist (except for varying attributes)\n",
    "    required_keys = [k for k in required_parameters.get(posterior_type) if k != varying_attribute]\n",
    "    if not all(k in posterior_kwargs for k in required_keys):\n",
    "        raise ValueError(f\"{posterior_type} posterior requires {required_keys}\")\n",
    "\n",
    "    # Create keyword arguments for IID sample generation\n",
    "    iid_kwargs = {key: posterior_kwargs.get(key, \"varies\") for key in required_parameters.get(posterior_type)}\n",
    "\n",
    "    print(f\"Using IID sample settings: {iid_kwargs}\")\n",
    "\n",
    "    # Create configuration and histogram folders inside the experiment root\n",
    "    config_folder = os.path.join(experiment_root_folder, f\"{config_descr}_with_{runs}_runs\")\n",
    "    iid_histogram_folder = os.path.join(config_folder, \"KDE and Histograms of IID Samples\")\n",
    "    create_directories(config_folder, iid_histogram_folder)\n",
    "\n",
    "    # === Handle Precomputed IID Samples for Varying Attributes ===\n",
    "    iid_samples_dict = {}\n",
    "\n",
    "    if posterior_type == \"Mixture\":\n",
    "        component_index = posterior_kwargs.get(\"varying_component\")  # Get the selected component\n",
    "        \n",
    "        if component_index is None and varying_attribute not in [\"num_samples\", \"num_chains\", \"init_scheme\"]:\n",
    "            raise ValueError(f\"`varying_component` must be specified when varying '{varying_attribute}' in a Mixture.\")\n",
    "\n",
    "        # Loop through all varying values for Mixture posterior\n",
    "        for value in varying_values:\n",
    "\n",
    "            iid_kwargs[\"component_params\"][component_index][varying_attribute] = value\n",
    "            print(f\"Updating component {component_index} with {varying_attribute} = {value}\")\n",
    "\n",
    "            iid_samples_dict[value] = generate_iid_samples(\n",
    "                posterior_type=posterior_type,\n",
    "                component_types=iid_kwargs[\"component_types\"],\n",
    "                component_params=iid_kwargs[\"component_params\"], \n",
    "                weights=iid_kwargs[\"weights\"],\n",
    "                num_samples=num_samples,\n",
    "                rng=rng\n",
    "            )\n",
    "\n",
    "            # Plot histogram and KDE for each varying value\n",
    "            plot_histogram(\n",
    "                samples=iid_samples_dict[value],\n",
    "                title=f\"IID Samples Histogram & KDE ({varying_attribute}={value})\",\n",
    "                save_path=os.path.join(iid_histogram_folder, f\"iid_hist_kde_{varying_attribute}_{value}.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "            )\n",
    "\n",
    "    # Single posterior case\n",
    "    elif varying_attribute in iid_kwargs or varying_attribute == \"num_samples\":\n",
    "        for value in varying_values:\n",
    "            if varying_attribute == \"num_samples\":\n",
    "                current_num_samples = value  \n",
    "            else:\n",
    "                iid_kwargs[varying_attribute] = value  \n",
    "                current_num_samples = num_samples  \n",
    "            \n",
    "            iid_samples_dict[value] = generate_iid_samples(\n",
    "                posterior_type=posterior_type,\n",
    "                **iid_kwargs,\n",
    "                num_samples=current_num_samples,\n",
    "                rng=rng\n",
    "            )\n",
    "\n",
    "            # Plot histogram and KDE for each varying value\n",
    "            plot_histogram(\n",
    "                samples=iid_samples_dict[value],\n",
    "                title=f\"IID Samples Histogram & KDE ({varying_attribute}={value})\",\n",
    "                save_path=os.path.join(iid_histogram_folder, f\"iid_hist_kde_{varying_attribute}_{value}.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "            )\n",
    "\n",
    "    # Fixed posterior case (no varying attributes)\n",
    "    else:\n",
    "        iid_samples = generate_iid_samples(\n",
    "            posterior_type=posterior_type,\n",
    "            **iid_kwargs,\n",
    "            num_samples=num_samples,\n",
    "            rng=rng\n",
    "        )\n",
    "\n",
    "        plot_histogram(\n",
    "            samples=iid_samples,\n",
    "            title=\"IID Samples Histogram & KDE (fixed posterior)\",\n",
    "            save_path=os.path.join(iid_histogram_folder, \"iid_hist_kde.pdf\"),\n",
    "            posterior_type=posterior_type\n",
    "        )\n",
    "\n",
    "\n",
    "    # === Experiment Setup ===\n",
    "    samples_per_chain = \"varies\" if varying_attribute in [\"num_samples\", \"num_chains\"] else num_samples // num_chains\n",
    "\n",
    "    experiment_metadata = {\n",
    "        \"config_descr\": config_descr,\n",
    "        \"runs\": runs,\n",
    "        \"posterior_type\": posterior_type,\n",
    "        \"varying_attribute\": varying_attribute,\n",
    "        \"varying_values\": varying_values,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"num_chains\": num_chains,\n",
    "        \"samples_per_chain\": samples_per_chain,\n",
    "        \"init_scheme\": init_scheme,\n",
    "        \"base_random_seed\": base_random_seed,\n",
    "        \"git_tag\": get_git_tag(),\n",
    "    }\n",
    "    experiment_metadata.update(iid_kwargs)  # Add posterior-specific parameters\n",
    "\n",
    "    # Save metadata\n",
    "    metadata_filename = os.path.join(config_folder, f\"metadata_config_{config_descr}.json\")\n",
    "    with open(metadata_filename, \"w\") as f:\n",
    "        json.dump(experiment_metadata, f, indent=4)\n",
    "\n",
    "    # Define fixed colors for each sampler\n",
    "    sampler_colors = {\n",
    "        \"Metro\": \"blue\",\n",
    "        \"HMC\": \"red\",\n",
    "        \"DEMetro\": \"green\"\n",
    "    }\n",
    "\n",
    "    # === Run the Experiment ===\n",
    "    for run_id in range(1, runs + 1):\n",
    "        print(f\"\\n===== Running {config_descr} - Run {run_id} =====\\n\")\n",
    "\n",
    "        run_random_seed = int(rng.integers(1_000_000))\n",
    "\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "        traces_folder = os.path.join(run_folder, \"traces_and_trace_plots\")\n",
    "        plots_folder = os.path.join(run_folder, \"plots_of_run\")\n",
    "        \n",
    "\n",
    "        create_directories(run_folder, results_folder, traces_folder, plots_folder)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for value in varying_values:\n",
    "\n",
    "            var_attr_folder = os.path.join(traces_folder, f\"{varying_attribute}_{value}\")\n",
    "            create_directories(var_attr_folder)\n",
    "\n",
    "            # Handle parameter changes for Mixture case\n",
    "            if posterior_type == \"Mixture\":\n",
    "                component_index = posterior_kwargs.get(\"varying_component\")\n",
    "                if component_index is None and varying_attribute not in [\"num_samples\", \"num_chains\", \"init_scheme\"]:\n",
    "                    raise ValueError(f\"`varying_component` must be specified when varying '{varying_attribute}' in a Mixture.\")\n",
    "\n",
    "                # Modify only the selected component\n",
    "                posterior_kwargs[\"component_params\"][component_index][varying_attribute] = value\n",
    "            \n",
    "            else:\n",
    "                if varying_attribute in iid_kwargs:\n",
    "                    posterior_kwargs[varying_attribute] = value\n",
    "            \n",
    "            if varying_attribute == \"num_samples\":\n",
    "                num_samples = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"num_chains\":\n",
    "                num_chains = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"init_scheme\":\n",
    "                init_scheme = value\n",
    "\n",
    "            if posterior_type == \"Mixture\":\n",
    "                model = MixturePosterior(**posterior_kwargs)\n",
    "            else:\n",
    "                model = SinglePosterior(dist_name=posterior_type, dist_params=posterior_kwargs)\n",
    "\n",
    "            # Generate initialization values\n",
    "            if posterior_type == \"Mixture\" and init_scheme is not None:\n",
    "                means = extract_means_from_components(posterior_kwargs[\"component_params\"])\n",
    "                initvals = get_initvals(init_scheme, means, num_chains, rng)\n",
    "            else:\n",
    "                initvals = None\n",
    "           \n",
    "            # Get IID samples for the current varying value\n",
    "            if varying_attribute != \"init_scheme\" and varying_attribute != \"num_chains\":\n",
    "                iid_samples = iid_samples_dict[value] \n",
    "\n",
    "            # Run sampling for all samplers\n",
    "            for sampler_name in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "                \n",
    "                if posterior_type == \"Mixture\":\n",
    "                    print(f\"Running {sampler_name} with {varying_attribute} = {value} (Component {component_index})\")\n",
    "                else:\n",
    "                    print(f\"Running {sampler_name} with {varying_attribute} = {value}\")\n",
    "\n",
    "                # **Measure Computation Time**\n",
    "                start_time = time.time()\n",
    "                trace = model.run_sampling(\n",
    "                    sampler_name, num_samples=samples_per_chain, num_chains=num_chains, init_scheme=init_scheme,\n",
    "                    initvals = initvals, run_random_seed=run_random_seed\n",
    "                )\n",
    "                end_time = time.time()\n",
    "                runtime = end_time - start_time\n",
    "\n",
    "                # Plot trace plots in notebook if requested\n",
    "                if experiment_settings.get(\"plot_traces_in_notebook\", False):\n",
    "                    az.plot_trace(trace, compact=True)\n",
    "                    plt.title(f\"Trace Plot ({sampler_name}, {varying_attribute} = {value})\")\n",
    "                    plt.show()\n",
    "                \n",
    "\n",
    "                # Save trace to NetCDF file if requested\n",
    "                if experiment_settings.get(\"save_traces\", False):\n",
    "                    trace_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace.nc\")\n",
    "                    az.to_netcdf(trace, trace_filename)\n",
    "\n",
    "\n",
    "                trace_plot_mode = experiment_settings.get(\"trace_plots\", \"none\")\n",
    "\n",
    "                # Save trace plots to PDF if requested\n",
    "                if trace_plot_mode == \"all\" or (trace_plot_mode == \"first_run_only\" and run_id == 1):\n",
    "                    trace_plot_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace_plot.pdf\")\n",
    "                    az.plot_trace(trace, compact=True)\n",
    "                    plt.savefig(trace_plot_filename, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "\n",
    "                # Select correct posterior variable name\n",
    "                if posterior_type == \"Mixture\":\n",
    "                    post_var_name = \"mixed_post_var\"\n",
    "                else:\n",
    "                    post_var_name = \"posterior_var\"\n",
    "\n",
    "                posterior_samples = trace.posterior[post_var_name].values\n",
    "        \n",
    "                # Ensure posterior_samples always has shape (N, dims)\n",
    "                if posterior_samples.ndim == 2:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, 1) \n",
    "                else:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, posterior_samples.shape[-1])\n",
    "\n",
    "                # Ensure iid_samples always has shape (N, dims)\n",
    "                if iid_samples.ndim == 1:\n",
    "                    iid_samples = iid_samples[:, np.newaxis]\n",
    "                else:\n",
    "                    iid_samples = iid_samples.reshape(-1, iid_samples.shape[-1])\n",
    "                \n",
    "                ws_distance = sliced_wasserstein_distance(posterior_samples, iid_samples, L=5)\n",
    " \n",
    "                # Compute R-hat and ESS\n",
    "                r_hat = az.rhat(trace)[post_var_name].max().item()\n",
    "                ess = az.ess(trace)[post_var_name].min().item()\n",
    "\n",
    "                results.append({\n",
    "                    varying_attribute: value,\n",
    "                    \"sampler\": sampler_name,\n",
    "                    \"wasserstein_distance\": ws_distance,\n",
    "                    \"r_hat\": r_hat,\n",
    "                    \"ess\": ess,\n",
    "                    \"runtime\": runtime\n",
    "                })\n",
    "\n",
    "        # Convert results to DataFrame and save\n",
    "        df_results = pd.DataFrame(results)\n",
    "\n",
    "        # Handle tuple-based attributes consistently\n",
    "        if isinstance(df_results[varying_attribute].iloc[0], tuple):\n",
    "            if varying_attribute == \"mode_means\":\n",
    "                df_results[\"mode_distance\"] = df_results[varying_attribute].apply(lambda x: abs(x[1] - x[0]))\n",
    "                varying_attribute_for_plot = \"mode_distance\"\n",
    "            else:\n",
    "                df_results[varying_attribute] = df_results[varying_attribute].apply(str)\n",
    "                varying_attribute_for_plot = varying_attribute\n",
    "        else:\n",
    "            varying_attribute_for_plot = varying_attribute\n",
    "\n",
    "        # Sort the DataFrame by the final chosen attribute\n",
    "        df_results = df_results.sort_values(varying_attribute_for_plot, ascending=True)\n",
    "\n",
    "\n",
    "        plot_and_save_all_metrics(\n",
    "            df_results=df_results,\n",
    "            sampler_colors=sampler_colors,\n",
    "            varying_attribute=varying_attribute,\n",
    "            varying_attribute_for_plot=varying_attribute_for_plot,\n",
    "            results_folder=results_folder,\n",
    "            plots_folder=plots_folder,\n",
    "            run_id=run_id,\n",
    "            config_descr=config_descr\n",
    "        )\n",
    "\n",
    "    print(\"\\n===== All Runs Completed Successfully! =====\\n\")\n",
    "\n",
    "    # ===== GLOBAL RESULTS FOLDER =====\n",
    "    global_folder = os.path.join(config_folder, \"global_results\")\n",
    "    global_results_folder = os.path.join(global_folder, \"results\")\n",
    "    global_plots_folder = os.path.join(global_folder, \"plots\")\n",
    "    create_directories(global_folder, global_results_folder, global_plots_folder)\n",
    "\n",
    "    # Collect all results from all runs\n",
    "    df_all_runs = []\n",
    "\n",
    "    for run_id in range(1, runs + 1):\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "\n",
    "        for sampler in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "            csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "            df_run = pd.read_csv(csv_filename)\n",
    "            df_run[\"run_id\"] = run_id \n",
    "            df_run[\"sampler\"] = sampler  \n",
    "            df_all_runs.append(df_run)\n",
    "\n",
    "\n",
    "    # Combine all results into a single data frame \n",
    "    df_all_runs = pd.concat(df_all_runs, ignore_index=True)\n",
    "\n",
    "    compute_and_save_global_metrics(\n",
    "        df_all_runs=df_all_runs,\n",
    "        sampler_colors=sampler_colors,\n",
    "        varying_attribute=varying_attribute,\n",
    "        runs=runs,\n",
    "        config_descr=config_descr,\n",
    "        global_results_folder=global_results_folder,\n",
    "        global_plots_folder=global_plots_folder\n",
    "    )\n",
    "\n",
    "    print(f\"\\n===== Config {config_descr} Completed Successfully! =====\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def validate_config(config):\n",
    "    \"\"\"Checks if the config correctly defines one varying attribute and all other attributes are fixed.\"\"\"\n",
    "    \n",
    "    REQUIRED_ATTRIBUTES = {\n",
    "    \"config_descr\",\n",
    "    \"posterior_type\",\n",
    "    \"runs\",\n",
    "    \"num_samples\",\n",
    "    \"num_chains\",\n",
    "    \"varying_attribute\",\n",
    "    \"varying_values\",\n",
    "    }\n",
    "\n",
    "    # Posterior-specific required attributes\n",
    "    POSTERIOR_ATTRIBUTES = {\n",
    "        \"Cauchy\": {\"loc\", \"scale\"},\n",
    "        \"Beta\": {\"a\", \"b\"},\n",
    "        \"Normal\": {\"mu\", \"sigma\"},\n",
    "        \"StudentT\": {\"nu\", \"mu\", \"sigma\"},\n",
    "        \"Laplace\": {\"mu\", \"b\"},\n",
    "        \"SkewStudentT\": {\"a\", \"b\", \"mu\", \"sigma\"},\n",
    "        \"Mixture\": {\"component_types\", \"component_params\", \"weights\"},\n",
    "        \"MvNormal\": {\"mu\", \"cov\"}\n",
    "    }\n",
    "\n",
    "    OPTIONAL_ATTRIBUTES = {\"base_random_seed\", \"init_scheme\", \"varying_component\"}\n",
    "\n",
    "    if \"config_descr\" not in config:\n",
    "        raise ValueError(\"Config is missing 'config_descr'.\")\n",
    "    \n",
    "    config_descr = config[\"config_descr\"]\n",
    "\n",
    "    if \"varying_attribute\" not in config:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing 'varying_attribute'.\")\n",
    "    \n",
    "    varying_attr = config[\"varying_attribute\"]\n",
    "\n",
    "    # Ensure all required attributes are present\n",
    "    missing_attrs = REQUIRED_ATTRIBUTES - config.keys() - {varying_attr}\n",
    "\n",
    "    if missing_attrs:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing required attributes: {missing_attrs}.\")\n",
    "    \n",
    "    posterior_type = config[\"posterior_type\"]\n",
    "\n",
    "    if posterior_type not in POSTERIOR_ATTRIBUTES:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'posterior_type': '{posterior_type}'.\")\n",
    "\n",
    "    # Ensure varying_attribute is a recognized attribute\n",
    "    all_valid_attributes = REQUIRED_ATTRIBUTES.union(POSTERIOR_ATTRIBUTES[posterior_type], OPTIONAL_ATTRIBUTES)\n",
    "\n",
    "    if varying_attr not in all_valid_attributes:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'varying_attribute': '{varying_attr}'.\")\n",
    "    \n",
    "    # Ensure all fixed attributes are present\n",
    "    for attr in all_valid_attributes - OPTIONAL_ATTRIBUTES - {varying_attr}:\n",
    "          if attr not in config:\n",
    "            raise ValueError(f\"Config '{config_descr}' is missing required fixed attribute '{attr}'.\")\n",
    "\n",
    "# to do: if init_schme is present, check that it is a valid init scheme\n",
    "\n",
    "\n",
    "\n",
    "# posterior_type = \"Cauchy\", \"Beta\", \"Normal\", \"StudentT\", \"Laplace\", \"SkewstudentT\"\n",
    "# varying_attribute = \"num_samples\", \"num_chains\", \"init_scheme\" or posterior specific attribute\n",
    "# bimmodal specific attributes = \"mode_means\", \"std_of_modes\", \"weights\"\n",
    "# cauchy specific attributes = \"loc\", \"scale\"\n",
    "# beta specific attributes = \"a\", \"b\"\n",
    "# normal specific attributes = \"mu\", \"sigma\"\n",
    "# student_t specific attributes = \"nu\", \"mu\", \"sigma\"\n",
    "# laplace specific attributes = \"mu\", \"b\"\n",
    "# skewed_student_t specific attributes = \"a\", \"b\", \"mu\", \"sigma\"\n",
    "# all but the varying attribute must be fixed and present in the config\n",
    "\n",
    "#def my_custom_logp_function(x):\n",
    "#    w1, w2 = 0.4, 0.6\n",
    "#    mu1, mu2 = -2, 2\n",
    "#    sigma1, sigma2 = 1, 1\n",
    "\n",
    "    #log_like1 = pm.logp(pm.Normal.dist(mu=mu1, sigma=sigma1), x)\n",
    "    #log_like2 = pm.logp(pm.Normal.dist(mu=mu2, sigma=sigma2), x)\n",
    "\n",
    "    #return pm.math.logsumexp([np.log(w1) + log_like1, np.log(w2) + log_like2])\n",
    "\n",
    "# default attributes\n",
    "default_num_samples = 20000\n",
    "default_num_chains = 20\n",
    "default_base_random_seed = 42\n",
    "default_runs = 50\n",
    "\n",
    "unimodal = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Normal\",\n",
    "        \"posterior_type\": \"Normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 2, 5, 10],\n",
    "        \"sigma\": 1\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Student_t\",\n",
    "        \"posterior_type\": \"StudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\":  default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 3, 5, 30],\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Laplace_test\",\n",
    "        \"posterior_type\": \"Laplace\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"b\",\n",
    "        \"varying_values\": [0.5, 1, 2, 5],\n",
    "        \"mu\": 0,\n",
    "    },\n",
    "]\n",
    "\n",
    "high_dim_and_correlated = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_3d_high_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (-5, 0, 5),\n",
    "            (0, 0, 0),\n",
    "            (-10, 20, -30),\n",
    "            (50, -50, 100)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.9, 0.85], \n",
    "              [0.9, 1, 0.88], \n",
    "              [0.85, 0.88, 1]]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_2d_low_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (0, 0),\n",
    "            (-10, 10),\n",
    "            (20, -20),\n",
    "            (50, -50)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.1], [0.1, 1]]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_2d_high_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (0, 0),\n",
    "            (-10, 10),\n",
    "            (20, -20),\n",
    "            (50, -50)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.95], [0.95, 1]] \n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_3d_low_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (-5, 0, 5),\n",
    "            (0, 0, 0),\n",
    "            (-10, 20, -30),\n",
    "            (50, -50, 100)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.2, 0.1], \n",
    "                [0.2, 1, 0.15], \n",
    "                [0.1, 0.15, 1]]  \n",
    "    }\n",
    "]\n",
    "\n",
    "multimodal = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(5, 5), (10, -10), (20, 20), (50, -50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.3, 0.4, 0.3]\n",
    "    },\n",
    "    {   \n",
    "        \"config_descr\": \"Normal_and_student_t\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"StudentT\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 5, 10],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"nu\": 3, \"mu\": 10, \"sigma\": 2}],\n",
    "        \"weights\": [0.6, 0.4]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "difficult_geometries = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"SkewStudentT\",\n",
    "        \"posterior_type\": \"SkewStudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [1, 2, 3, 5],\n",
    "        \"b\": 1,\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_of_SkewStudentT\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 3, 6, 10],\n",
    "        \"varying_component\": 0,\n",
    "        \"component_types\": [\"SkewStudentT\", \"SkewStudentT\"],\n",
    "        \"component_params\": [\n",
    "            {\"a\": 3, \"b\": 1, \"sigma\": 1},\n",
    "            {\"a\": 9, \"b\": 3, \"mu\": 3, \"sigma\": 4}\n",
    "        ],\n",
    "        \"weights\": [0.5, 0.5]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "asymmetric_weights_mixture = [\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3),(5, 5), (10, 10), (20, 20), (50, 50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.2, 0.2, 0.6]\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "symmetric_weights_mixture = [\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3),(5, 5), (10, 10), (20, 20), (50, 50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.3, 0.3, 0.4]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "Mixture_test_init_scheme = [\n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_init_scheme_and_asymmetric_weights (pro DEMetro)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.1, 0.9],\n",
    "        \"init_scheme\": \"equal_per_mode\"\n",
    "\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_asymmetric_weights (only weights)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.1, 0.9]\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_init_scheme (only init_scheme)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.5, 0.5],\n",
    "        \"init_scheme\": \"equal_per_mode\"\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_def_init_scheme_and_equal_weights (fair case)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.5, 0.5]\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_asymmetric_weights_and_random_init (only weights + random init)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.1, 0.9],\n",
    "        \"init_scheme\": \"random\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_random_init_scheme_and_equal_weights (random init + fair case)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.5, 0.5],\n",
    "        \"init_scheme\": \"random\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Config Mixture_with_init_scheme_and_asymmetric_weights (pro DEMetro) started! =====\n",
      "\n",
      "Using IID sample settings: {'component_types': ['Normal', 'Normal'], 'component_params': [{'mu': 0, 'sigma': 1}, {'mu': 5, 'sigma': 1}], 'weights': [0.1, 0.9]}\n",
      "Updating component 1 with mu = 5\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 5, 'sigma': 1}\n",
      "Updating component 1 with mu = 6\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 6, 'sigma': 1}\n",
      "Updating component 1 with mu = 7\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 7, 'sigma': 1}\n",
      "Updating component 1 with mu = 8\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 8, 'sigma': 1}\n",
      "Updating component 1 with mu = 9\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 9, 'sigma': 1}\n",
      "Updating component 1 with mu = 10\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 10, 'sigma': 1}\n",
      "Updating component 1 with mu = 11\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 11, 'sigma': 1}\n",
      "Updating component 1 with mu = 12\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 12, 'sigma': 1}\n",
      "Updating component 1 with mu = 13\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 13, 'sigma': 1}\n",
      "Updating component 1 with mu = 14\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 14, 'sigma': 1}\n",
      "Updating component 1 with mu = 15\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 15, 'sigma': 1}\n",
      "Updating component 1 with mu = 16\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 16, 'sigma': 1}\n",
      "Updating component 1 with mu = 17\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 17, 'sigma': 1}\n",
      "Updating component 1 with mu = 18\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 18, 'sigma': 1}\n",
      "Updating component 1 with mu = 19\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 19, 'sigma': 1}\n",
      "Updating component 1 with mu = 20\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 20, 'sigma': 1}\n",
      "\n",
      "===== Running Mixture_with_init_scheme_and_asymmetric_weights (pro DEMetro) - Run 1 =====\n",
      "\n",
      "Initvals: [{'mixed_post_var': 0}, {'mixed_post_var': 5}, {'mixed_post_var': 0}, {'mixed_post_var': 5}, {'mixed_post_var': 0}, {'mixed_post_var': 5}, {'mixed_post_var': 0}, {'mixed_post_var': 5}, {'mixed_post_var': 0}, {'mixed_post_var': 5}, {'mixed_post_var': 0}, {'mixed_post_var': 5}, {'mixed_post_var': 0}, {'mixed_post_var': 5}, {'mixed_post_var': 0}, {'mixed_post_var': 5}, {'mixed_post_var': 0}, {'mixed_post_var': 5}, {'mixed_post_var': 0}, {'mixed_post_var': 5}]\n",
      "Running Metro with mu = 5 (Component 1)\n",
      "Running HMC with mu = 5 (Component 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with mu = 5 (Component 1)\n",
      "Initvals: [{'mixed_post_var': 0}, {'mixed_post_var': 6}, {'mixed_post_var': 0}, {'mixed_post_var': 6}, {'mixed_post_var': 0}, {'mixed_post_var': 6}, {'mixed_post_var': 0}, {'mixed_post_var': 6}, {'mixed_post_var': 0}, {'mixed_post_var': 6}, {'mixed_post_var': 0}, {'mixed_post_var': 6}, {'mixed_post_var': 0}, {'mixed_post_var': 6}, {'mixed_post_var': 0}, {'mixed_post_var': 6}, {'mixed_post_var': 0}, {'mixed_post_var': 6}, {'mixed_post_var': 0}, {'mixed_post_var': 6}]\n",
      "Running Metro with mu = 6 (Component 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with mu = 6 (Component 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 386 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with mu = 6 (Component 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m category:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m         \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexperiment_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposterior_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposterior_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_descr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_descr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m            \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvarying_attribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvarying_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit_scheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_random_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_random_seed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_descr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_random_seed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposterior_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass remaining keys as posterior_kwargs\u001b[39;49;00m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in config \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_descr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 786\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(experiment_settings, posterior_type, config_descr, runs, varying_attribute, varying_values, num_samples, num_chains, init_scheme, base_random_seed, **posterior_kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# **Measure Computation Time**\u001b[39;00m\n\u001b[1;32m    785\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 786\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_sampling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples_per_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_scheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_scheme\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_random_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_random_seed\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    791\u001b[0m runtime \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[2], line 457\u001b[0m, in \u001b[0;36mPosteriorExample.run_sampling\u001b[0;34m(self, sampler_name, num_samples, tune, num_chains, initvals, init_scheme, run_random_seed)\u001b[0m\n\u001b[1;32m    455\u001b[0m     sampler \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNUTS()\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampler_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEMetro\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     sampler \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEMetropolis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown sampler: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampler_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/step_methods/metropolis.py:808\u001b[0m, in \u001b[0;36mDEMetropolis.__init__\u001b[0;34m(self, vars, S, proposal_dist, lamb, scaling, tune, tune_interval, model, mode, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m    807\u001b[0m shared \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mmake_shared_replacements(initial_values, \u001b[38;5;28mvars\u001b[39m, model)\n\u001b[0;32m--> 808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelta_logp \u001b[38;5;241m=\u001b[39m delta_logp(initial_values, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mvars\u001b[39m, shared)\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mvars\u001b[39m, shared)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/model/core.py:742\u001b[0m, in \u001b[0;36mModel.logp\u001b[0;34m(self, vars, jacobian, sum)\u001b[0m\n\u001b[1;32m    740\u001b[0m rv_logps: \u001b[38;5;28mlist\u001b[39m[TensorVariable] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rvs:\n\u001b[0;32m--> 742\u001b[0m     rv_logps \u001b[38;5;241m=\u001b[39m \u001b[43mtransformed_conditional_logp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrvs_to_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs_to_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrvs_to_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs_to_transforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjacobian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rv_logps, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# Replace random variables by their value variables in potential terms\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/logprob/basic.py:611\u001b[0m, in \u001b[0;36mtransformed_conditional_logp\u001b[0;34m(rvs, rvs_to_values, rvs_to_transforms, jacobian, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m     transform_rewrite \u001b[38;5;241m=\u001b[39m TransformValuesRewrite(values_to_transforms)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    610\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn_rvs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 611\u001b[0m temp_logp_terms \u001b[38;5;241m=\u001b[39m \u001b[43mconditional_logp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrvs_to_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_rewrites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_rewrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_jacobian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# The function returns the logp for every single value term we provided to it.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# This includes the extra values we plugged in above, so we filter those we\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# actually wanted in the same order they were given in.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m logp_terms \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/logprob/basic.py:541\u001b[0m, in \u001b[0;36mconditional_logp\u001b[0;34m(rv_values, warn_rvs, ir_rewriter, extra_rewrites, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m q_values \u001b[38;5;241m=\u001b[39m remapped_vars[: \u001b[38;5;28mlen\u001b[39m(q_values)]\n\u001b[1;32m    539\u001b[0m q_rv_inputs \u001b[38;5;241m=\u001b[39m remapped_vars[\u001b[38;5;28mlen\u001b[39m(q_values) :]\n\u001b[0;32m--> 541\u001b[0m q_logprob_vars \u001b[38;5;241m=\u001b[39m \u001b[43m_logprob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mq_rv_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(q_logprob_vars, \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    549\u001b[0m     q_logprob_vars \u001b[38;5;241m=\u001b[39m [q_logprob_vars]\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/functools.py:907\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    905\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/distributions/mixture.py:354\u001b[0m, in \u001b[0;36mmarginal_mixture_logprob\u001b[0;34m(op, values, rng, weights, *components, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     components_logp \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    350\u001b[0m         [logp(component, value) \u001b[38;5;28;01mfor\u001b[39;00m component \u001b[38;5;129;01min\u001b[39;00m components],\n\u001b[1;32m    351\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    352\u001b[0m     )\n\u001b[0;32m--> 354\u001b[0m mix_logp \u001b[38;5;241m=\u001b[39m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogsumexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcomponents_logp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m mix_logp \u001b[38;5;241m=\u001b[39m check_parameters(\n\u001b[1;32m    357\u001b[0m     mix_logp,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m weights,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0 <= weights <= 1, sum(weights) == 1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    362\u001b[0m )\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mix_logp\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/tensor/math.py:2740\u001b[0m, in \u001b[0;36mlogsumexp\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m   2715\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogsumexp\u001b[39m(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2716\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the log of the sum of exponentials of input elements.\u001b[39;00m\n\u001b[1;32m   2717\u001b[0m \n\u001b[1;32m   2718\u001b[0m \u001b[38;5;124;03m    See ``scipy.special.logsumexp``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2737\u001b[0m \n\u001b[1;32m   2738\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log(\u001b[38;5;28msum\u001b[39m(\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims))\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/graph/op.py:293\u001b[0m, in \u001b[0;36mOp.__call__\u001b[0;34m(self, name, return_list, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    251\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[Variable]:\n\u001b[1;32m    252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Construct an `Apply` node using :meth:`Op.make_node` and return its outputs.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    This method is just a wrapper around :meth:`Op.make_node`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "categories = [unimodal, high_dim_and_correlated, multimodal, difficult_geometries, asymmetric_weights_mixture, symmetric_weights_mixture]\n",
    "\n",
    "category = Mixture_test_init_scheme\n",
    "\n",
    "experiment_name = \"4_Demetro_cases_and_2_random\"\n",
    "\n",
    "# Define the root directory for all experiments\n",
    "experiment_root_folder = f\"exp_{experiment_name}\"\n",
    "\n",
    "# Check if the folder already exists\n",
    "if os.path.exists(experiment_root_folder):\n",
    "    user_input = input(\n",
    "        f\"Folder '{experiment_root_folder}' already exists and will be overwritten.\\n\"\n",
    "        \"Do you want to continue? (yes/no): \"\n",
    "    ).strip().lower()\n",
    "\n",
    "    if user_input not in [\"yes\", \"y\"]:\n",
    "        print(\"Operation aborted. No files were deleted.\")\n",
    "        exit()\n",
    "    \n",
    "    shutil.rmtree(experiment_root_folder)\n",
    "\n",
    "create_directories(experiment_root_folder)\n",
    "\n",
    "# important for produced file size\n",
    "# It's about the individual traces, the global traces and traces per run are always saved\n",
    "experiment_settings = {\n",
    "    \"save_traces\": False,                 # if True, save traces to NetCDF files\n",
    "    \"trace_plots\": \"all\",                # \"none\", \"first_run_only\", \"all\" \n",
    "    \"plot_traces_in_notebook\": False       # if True, plot traces in the notebook\n",
    "}\n",
    "\n",
    "failed_configs = []\n",
    "start_time = time.time()\n",
    "start_dt = datetime.now()\n",
    "\n",
    "# need to adapt validation of config\n",
    "#for config in experiment:\n",
    "#    validate_config(config)\n",
    "\n",
    "#print(\"All configurations are valid. Starting experiments...\")\n",
    "\n",
    "for config in category:\n",
    "    try:\n",
    "        run_experiment(\n",
    "            experiment_settings,\n",
    "            posterior_type=config[\"posterior_type\"],\n",
    "            config_descr=config[\"config_descr\"],\n",
    "            runs=config[\"runs\"],\n",
    "            varying_attribute=config[\"varying_attribute\"],\n",
    "            varying_values=config[\"varying_values\"],\n",
    "            init_scheme=\"varies\" if config[\"varying_attribute\"] == \"init_scheme\" else config.get(\"init_scheme\", None),\n",
    "            num_samples=\"varies\" if config[\"varying_attribute\"] == \"num_samples\" else config[\"num_samples\"],\n",
    "            num_chains=\"varies\" if config[\"varying_attribute\"] == \"num_chains\" else config[\"num_chains\"],\n",
    "            base_random_seed=config.get(\"base_random_seed\", None),\n",
    "            **{k: v for k, v in config.items() if k not in [\n",
    "                \"config_descr\", \"runs\", \"varying_attribute\", \"varying_values\", \n",
    "                \"num_samples\", \"num_chains\", \"init_scheme\", \n",
    "                \"base_random_seed\", \"posterior_type\"\n",
    "            ]}  # Pass remaining keys as posterior_kwargs\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in config '{config['config_descr']}': {e}\")\n",
    "        failed_configs.append((config['config_descr'], str(e)))\n",
    "\n",
    "end_time = time.time()\n",
    "end_dt = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "def get_folder_size(path='.'):\n",
    "    \"\"\"Compute total size of all files in directory.\"\"\"\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total += os.path.getsize(fp)\n",
    "    return total\n",
    "\n",
    "\n",
    "# Prepare the summary text\n",
    "size_bytes = get_folder_size(experiment_root_folder)\n",
    "#total_configs = sum(len(category) for category in categories)\n",
    "total_configs = len(category)\n",
    "\n",
    "\n",
    "summary_lines = [\n",
    "    \"\\n============================\",\n",
    "    \"Experiment Summary\",\n",
    "    \"============================\",\n",
    "    f\"Started at:               {start_dt.strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"Finished at:              {end_dt.strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"Total duration:           {round(duration / 60, 2)} minutes ({round(duration, 1)} seconds)\",\n",
    "    f\"Output folder:            {experiment_root_folder}\",\n",
    "    f\"Output folder size:       {humanize.naturalsize(size_bytes)}\",\n",
    "    f\"Total configurations:     {total_configs}\",\n",
    "    f\"Successful runs:          {total_configs - len(failed_configs)}\",\n",
    "    f\"Failed configurations:    {len(failed_configs)}\"\n",
    "]\n",
    "\n",
    "if failed_configs:\n",
    "    summary_lines.append(\"\\n Failed Configurations:\")\n",
    "    for cfg, msg in failed_configs:\n",
    "        summary_lines.append(f\" - {cfg}: {msg}\")\n",
    "\n",
    "# Print to console\n",
    "print(\"\\n\".join(summary_lines))\n",
    "\n",
    "# Also save to summary.txt\n",
    "summary_path = os.path.join(experiment_root_folder, \"summary.txt\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(summary_lines))\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_all_inference_attr = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Samples_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",    \n",
    "        \"varying_values\": [100, 200, 300],\n",
    "        \"mode_means\": (3,-3),\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1)\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"config_descr\": \"Chains_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_chains\",    \n",
    "        \"varying_values\": [4,6,8],\n",
    "        \"mode_means\": (3,-3),\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1)\n",
    "    }\n",
    "    #add init scheme test\n",
    "\n",
    "    #add burn in as well?\n",
    "    ]\n",
    "\n",
    "\n",
    "# Can select any of the posterior_type kwargs to vary, e.g., for a normal distribution, mu or sigma can be varied\n",
    "Test_all_posterior_types = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Normal_test\",\n",
    "        \"posterior_type\": \"normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 1, 2],\n",
    "        \"sigma\": 1\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Beta_test\",\n",
    "        \"posterior_type\": \"beta\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [0.5,5,1],\n",
    "        \"b\": 3,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Cauchy_test\",\n",
    "        \"posterior_type\": \"cauchy\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"loc\",\n",
    "        \"varying_values\": [0, -2, 5],\n",
    "        \"scale\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Laplace_test\",\n",
    "        \"posterior_type\": \"laplace\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"b\",\n",
    "        \"varying_values\": [1, 2, 3, 20],\n",
    "        \"mu\": 0,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Student_t_test\",\n",
    "        \"posterior_type\": \"student_t\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\":  default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 3],\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Skewed_student_t_test\",\n",
    "        \"posterior_type\": \"skewed_student_t\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [0.5, 1, 2],\n",
    "        \"b\": 1,\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Bimodal_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mode_means\",\n",
    "        \"varying_values\": [(0,0), (1,1), (2,2)],\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1),\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "test_triple_normal = [\n",
    "    \n",
    "    {\n",
    "        \"config_descr\": \"Mixture_test\",\n",
    "        \"posterior_type\": \"mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000, 2000, 8000],\n",
    "        \"component_types\": [\"normal\", \"normal\", \"normal\"],\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 10, \"sigma\": 1}, {\"mu\": -40, \"sigma\": 1}],\n",
    "        \"weights\": [0.3, 0.5, 0.2]  # Uneven weighting\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "test_normal_and_student_t = [\n",
    "    \n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_test\",\n",
    "        \"posterior_type\": \"mixture\",\n",
    "        \"component_types\": [\"normal\", \"student_t\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [10000],\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"nu\": 3, \"mu\": 5, \"sigma\": 2}],\n",
    "        \"weights\": [0.6, 0.4]\n",
    "        }\n",
    "]\n",
    "\n",
    "test_mvnormal_2d_mixture = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"MVNormal_mixture\",\n",
    "        \"posterior_type\": \"mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"component_types\": [\"mv_normal\", \"mv_normal\", \"mv_normal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},   # First component\n",
    "                {\"mu\": [10, 10], \"cov\": [[2, 0.3], [0.3, 2]]},  # Second component\n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  # Third component\n",
    "        ],\n",
    "        \"weights\": [0.3, 0.4, 0.3]\n",
    "    }\n",
    "        \n",
    "]\n",
    "\n",
    "test_mvnormal = [\n",
    "    {\n",
    "        \"config_descr\": \"MVNormal_test\",\n",
    "        \"posterior_type\": \"mv_normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"mu\": [10, -20],\n",
    "        #\"cov\": [[1, 0.5], [0.5, 1]]\n",
    "        \"cov\": [[1, 0.95], [0.95, 1]]  # Very strong correlation,\n",
    "    }\n",
    "]\n",
    "\n",
    "test_3d_normal = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"MVNormal_test\",\n",
    "        \"posterior_type\": \"mv_normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"mu\":  [-50, 0, 50],\n",
    "        \"cov\":  [[1, 0.8, 0.3], [0.8, 1, 0.4], [0.3, 0.4, 1]]  # Works (3D Normal)\n",
    "\n",
    "    }   \n",
    "\n",
    "]\n",
    "\n",
    "#Test_custom = [\n",
    "#    {\n",
    "#        \"config_descr\": \"custom_gaussian_mixture\",\n",
    "#        \"posterior_type\": \"custom\",\n",
    "#        \"runs\": 5,\n",
    "#        \"num_samples\": default_num_samples,\n",
    "#        \"num_chains\": default_num_chains,\n",
    "#        \"base_random_seed\": 42,\n",
    "#        #\"logp_func\": my_custom_logp_function,  # Custom function\n",
    "#        #\"priors\": {\"x\": pm.Uniform.dist(lower=-10, upper=10)}\n",
    "#    }\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3318593455.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[103], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# old boilerplate code\n",
    "# initialize plots for all samplers\n",
    "        fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\n",
    "        fig_rhat, ax_rhat = plt.subplots(figsize=(10, 6))\n",
    "        fig_ess, ax_ess = plt.subplots(figsize=(10, 6))\n",
    "        fig_time, ax_time = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "        for sampler in df_results[\"sampler\"].unique():\n",
    "            df_sampler = df_results[df_results[\"sampler\"] == sampler]\n",
    "            csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "            df_sampler.to_csv(csv_filename, index=False)\n",
    "\n",
    "            # Plot Wasserstein Distance\n",
    "            ax_ws.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"wasserstein_distance\"], \n",
    "                marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "            # Plot R-hat values\n",
    "            ax_rhat.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"r_hat\"], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "            \n",
    "            # Plot ESS values\n",
    "            ax_ess.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"ess\"], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "            # **Plot Computation Time**\n",
    "            ax_time.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"runtime\"], \n",
    "                        marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                        color=sampler_colors.get(sampler, \"black\"))\n",
    "            \n",
    "        \n",
    "        # Set dynamic axis labels and titles\n",
    "        attribute_label = \"Mode Distance\" if varying_attribute == \"mode_means\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "        \n",
    "        # ===== Finalize and Save Wasserstein Plot =====\n",
    "        ax_ws.set_xlabel(attribute_label)\n",
    "        ax_ws.set_ylabel(\"Wasserstein Distance\")\n",
    "        ax_ws.set_title(f\"Wasserstein Distance for Samplers (config =_{config_descr})\")\n",
    "        ax_ws.legend(title=\"Sampler\")\n",
    "        ax_ws.grid(True)\n",
    "        plot_filename = os.path.join(plots_folder, f\"Wasserstein_run_{run_id}.pdf\")\n",
    "        fig_ws.savefig(plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_ws)\n",
    "\n",
    "        # ===== Finalize and Save R-hat Plot =====\n",
    "        ax_rhat.set_xlabel(attribute_label)\n",
    "        ax_rhat.set_ylabel(\"R-hat\")\n",
    "        ax_rhat.set_title(f\"R-hat for Samplers (config =_{config_descr})\")\n",
    "        ax_rhat.legend(title=\"Sampler\")\n",
    "        ax_rhat.grid(True)\n",
    "        rhat_plot_filename = os.path.join(plots_folder, f\"R-hat_run_{run_id}.pdf\")\n",
    "        fig_rhat.savefig(rhat_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_rhat)\n",
    "\n",
    "        # ===== Finalize and Save ESS Plot =====\n",
    "        ax_ess.set_xlabel(attribute_label)\n",
    "        ax_ess.set_ylabel(\"ESS\")\n",
    "        ax_ess.set_title(f\"ESS for Samplers (config =_{config_descr})\")\n",
    "        ax_ess.legend(title=\"Sampler\")\n",
    "        ax_ess.grid(True)\n",
    "        ess_plot_filename = os.path.join(plots_folder, f\"ESS_run_{run_id}.pdf\")\n",
    "        fig_ess.savefig(ess_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_ess)\n",
    "\n",
    "        # ===== Finalize and Save Time Plot =====\n",
    "        ax_time.set_xlabel(attribute_label)\n",
    "        ax_time.set_ylabel(\"Computation Time (seconds)\")\n",
    "        ax_time.set_title(f\"Computation Time for Samplers (config =_{config_descr})\")\n",
    "        ax_time.legend(title=\"Sampler\")\n",
    "        ax_time.grid(True)\n",
    "        time_plot_filename = os.path.join(plots_folder, f\"ComputationTime_run_{run_id}.pdf\")\n",
    "        fig_time.savefig(time_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old boilerplate code for global metrics\n",
    "\n",
    "if varying_attribute == \"mode_means\":\n",
    "        df_all_runs[\"mode_distance\"] = df_all_runs[varying_attribute].apply(lambda x: abs(eval(x)[1] - eval(x)[0]))\n",
    "        df_all_runs = df_all_runs.sort_values(\"mode_distance\", ascending=True)\n",
    "        varying_attribute_for_global_plot = \"mode_distance\"\n",
    "    else:\n",
    "        df_all_runs = df_all_runs.sort_values(varying_attribute, ascending=True)\n",
    "        varying_attribute_for_global_plot = varying_attribute\n",
    "\n",
    "\n",
    "    # Initialize global plots\n",
    "    fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\n",
    "    fig_rhat, ax_rhat = plt.subplots(figsize=(10, 6))\n",
    "    fig_ess, ax_ess = plt.subplots(figsize=(10, 6))\n",
    "    fig_time, ax_time = plt.subplots(figsize=(10, 6)) \n",
    "\n",
    "    for sampler in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "        df_sampler = df_all_runs[df_all_runs[\"sampler\"] == sampler]\n",
    "        color = sampler_colors.get(sampler, \"black\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Pivot tables: rows = varying attribute, columns = run_id, values = metrics\n",
    "        df_ws = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"wasserstein_distance\")\n",
    "        df_rhat = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"r_hat\")\n",
    "        df_ess = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"ess\")\n",
    "        df_time = df_sampler.pivot_table(index=varying_attribute, columns=\"run_id\", values=\"runtime\")\n",
    "    \n",
    "        # Compute mean and standard deviation for error bars\n",
    "        ws_mean, ws_std = df_ws.mean(axis=1), df_ws.std(axis=1)\n",
    "        rhat_mean, rhat_std = df_rhat.mean(axis=1), df_rhat.std(axis=1)\n",
    "        ess_mean, ess_std = df_ess.mean(axis=1), df_ess.std(axis=1)\n",
    "        time_mean, time_std = df_time.mean(axis=1), df_time.std(axis=1)\n",
    "\n",
    "        # Plot with error bars\n",
    "        ax_ws.errorbar(ws_mean.index, ws_mean, yerr=ws_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_rhat.errorbar(rhat_mean.index, rhat_mean, yerr=rhat_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_ess.errorbar(ess_mean.index, ess_mean, yerr=ess_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_time.errorbar(time_mean.index, time_mean, yerr=time_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "\n",
    "        # Save global averages \n",
    "        df_global_avg = pd.DataFrame({\n",
    "            varying_attribute: ws_mean.index,\n",
    "            \"global_avg_ws\": ws_mean.values,\n",
    "            \"global_avg_ws_std\": ws_std.values,\n",
    "            \"global_avg_rhat\": rhat_mean.values,\n",
    "            \"global_avg_rhat_std\": rhat_std.values,\n",
    "            \"global_avg_ess\": ess_mean.values,\n",
    "            \"global_avg_ess_std\": ess_std.values,\n",
    "            \"global_avg_time\": time_mean.values,\n",
    "            \"global_avg_time_std\": time_std.values\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        sampler_csv_filename = os.path.join(global_results_folder, f\"Global_results_{sampler}.csv\")\n",
    "        df_global_avg.to_csv(sampler_csv_filename, index=False)\n",
    "\n",
    "\n",
    "    # ===== Save Global Wasserstein Plot =====\n",
    "    ax_ws.set_xlabel(attribute_label)\n",
    "    ax_ws.set_ylabel(\"Average Wasserstein Distance\")\n",
    "    ax_ws.set_title(f\"Averaged Wasserstein Distance ({runs} Runs, config = {config_descr})\")\n",
    "    ax_ws.legend(title=\"Sampler\")\n",
    "    ax_ws.grid(True)\n",
    "    fig_ws.savefig(os.path.join(global_plots_folder, \"Wasserstein_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_ws)\n",
    "\n",
    "    # ===== Save Global R-hat Plot =====\n",
    "    ax_rhat.set_xlabel(attribute_label)\n",
    "    ax_rhat.set_ylabel(\"Average R-hat\")\n",
    "    ax_rhat.set_title(f\"Averaged R-hat Values ({runs} Runs, config = {config_descr})\")\n",
    "    ax_rhat.legend(title=\"Sampler\")\n",
    "    ax_rhat.grid(True)\n",
    "    fig_rhat.savefig(os.path.join(global_plots_folder, \"Rhat_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_rhat)\n",
    "\n",
    "    # ===== Save Global ESS Plot =====\n",
    "    ax_ess.set_xlabel(attribute_label)\n",
    "    ax_ess.set_ylabel(\"Average ESS\")\n",
    "    ax_ess.set_title(f\"Averaged ESS ({runs} Runs,  config = {config_descr})\")\n",
    "    ax_ess.legend(title=\"Sampler\")\n",
    "    ax_ess.grid(True)\n",
    "    fig_ess.savefig(os.path.join(global_plots_folder, \"ESS_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_ess)\n",
    "\n",
    "    # ===== Save Global Time Plot =====\n",
    "    ax_time.set_xlabel(attribute_label)\n",
    "    ax_time.set_ylabel(\"Average Computation Time (seconds)\")\n",
    "    ax_time.set_title(f\"Averaged Computation Time ({runs} Runs, config = {config_descr})\")\n",
    "    ax_time.legend(title=\"Sampler\")\n",
    "    ax_time.grid(True)\n",
    "    fig_time.savefig(os.path.join(global_plots_folder, \"Time_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_immo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
