{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "import shutil \n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "import humanize \n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "logger = logging.getLogger(\"pymc\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# Function to get the current git tag\n",
    "def get_git_tag():\n",
    "        try:\n",
    "            tag = subprocess.check_output([\"git\", \"describe\", \"--tags\"], stderr=subprocess.DEVNULL).strip().decode()\n",
    "            return tag\n",
    "        except subprocess.CalledProcessError:\n",
    "            return \"No tag found\"\n",
    "\n",
    "def create_directories(*paths):\n",
    "    \"\"\"Creates multiple directories if they don't exist.\"\"\"\n",
    "    for path in paths:\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def plot_and_save_all_metrics(df_results, sampler_colors, varying_attribute, varying_attribute_for_plot, results_folder, plots_folder, run_id, config_descr):\n",
    "    \"\"\"\n",
    "    Generates and saves multiple metric plots for different samplers.\n",
    "\n",
    "    Parameters:\n",
    "    - df_results: DataFrame containing experiment results.\n",
    "    - sampler_colors: Dictionary mapping sampler names to colors.\n",
    "    - varying_attribute: The attribute that varies.\n",
    "    - varying_attribute_for_plot: The attribute used for plotting.\n",
    "    - plots_folder: Folder where plots should be saved.\n",
    "    - run_id: ID of the current run.\n",
    "    - config_descr: Description of the configuration.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define metric labels\n",
    "    metrics = [\"wasserstein_distance\", \"r_hat\", \"ess\", \"runtime\"]\n",
    "\n",
    "    # Initialize plots for all metrics\n",
    "    fig_ax_pairs = {key: plt.subplots(figsize=(10, 6)) for key in metrics}\n",
    "\n",
    "    # Iterate over samplers and plot all metrics\n",
    "    for sampler in df_results[\"sampler\"].unique():\n",
    "        df_sampler = df_results[df_results[\"sampler\"] == sampler]\n",
    "        csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "        df_sampler.to_csv(csv_filename, index=False)\n",
    "\n",
    "        for metric in metrics:\n",
    "            fig, ax = fig_ax_pairs[metric]\n",
    "            ax.plot(df_sampler[varying_attribute_for_plot], df_sampler[metric], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "    # Set dynamic axis labels and save plots\n",
    "    attribute_label = \"Mode Distance\" if varying_attribute == \"mode_means\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "\n",
    "    for metric in metrics:\n",
    "        fig, ax = fig_ax_pairs[metric]\n",
    "        finalize_and_save_plot(fig,ax, attribute_label, metric, \n",
    "                               f\"{metric} for Samplers (config =_{config_descr})\",\n",
    "                               os.path.join(plots_folder, f\"{metric}_run_{run_id}.pdf\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_and_save_global_metrics(df_all_runs, sampler_colors, varying_attribute, runs, config_descr, global_results_folder, global_plots_folder):\n",
    "    \"\"\"\n",
    "    Computes and saves global metric plots (averaged across runs) for different samplers.\n",
    "\n",
    "    Parameters:\n",
    "    - df_all_runs: DataFrame containing results from all runs.\n",
    "    - sampler_colors: Dictionary mapping sampler names to colors.\n",
    "    - varying_attribute: The attribute that varies.\n",
    "    - runs: Number of experiment runs.\n",
    "    - config_descr: Configuration description.\n",
    "    - global_results_folder: Folder to save CSVs.\n",
    "    - global_plots_folder: Folder to save plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle varying attributes for plotting\n",
    "    if varying_attribute == \"mode_means\":\n",
    "        df_all_runs[\"mode_distance\"] = df_all_runs[varying_attribute].apply(lambda x: abs(eval(x)[1] - eval(x)[0]))\n",
    "        df_all_runs = df_all_runs.sort_values(\"mode_distance\", ascending=True)\n",
    "        varying_attribute_for_plot = \"mode_distance\"\n",
    "    else:\n",
    "        df_all_runs = df_all_runs.sort_values(varying_attribute, ascending=True)\n",
    "        varying_attribute_for_plot = varying_attribute\n",
    "\n",
    "    # Define metrics for aggregation\n",
    "    metrics = [\"wasserstein_distance\", \"r_hat\", \"ess\", \"runtime\"]\n",
    "\n",
    "    # Initialize global plots\n",
    "    fig_ax_pairs = {metric: plt.subplots(figsize=(10, 6)) for metric in metrics}\n",
    "\n",
    "    for sampler in df_all_runs[\"sampler\"].unique():\n",
    "        df_sampler = df_all_runs[df_all_runs[\"sampler\"] == sampler]\n",
    "        color = sampler_colors.get(sampler, \"black\")\n",
    "\n",
    "\n",
    "        # Pivot tables: rows = varying attribute, columns = run_id, values = metric\n",
    "        df_pivot = {metric: df_sampler.pivot_table(index=varying_attribute_for_plot, columns=\"run_id\", values=metric)\n",
    "                    for metric in metrics}\n",
    "\n",
    "        # Compute mean and standard deviation\n",
    "        metric_stats = {metric: (df_pivot[metric].mean(axis=1), df_pivot[metric].std(axis=1))\n",
    "                        for metric in metrics}\n",
    "\n",
    "        for metric, (mean, std) in metric_stats.items():\n",
    "            fig, ax = fig_ax_pairs[metric]\n",
    "            ax.errorbar(mean.index, mean, yerr=std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "\n",
    "        # Save global averages CSV\n",
    "        df_global_avg = pd.DataFrame({\n",
    "            varying_attribute: metric_stats[\"wasserstein_distance\"][0].index,\n",
    "            **{f\"global_avg_{metric}\": metric_stats[metric][0].values for metric in metrics},\n",
    "            **{f\"global_avg_{metric}_std\": metric_stats[metric][1].values for metric in metrics},\n",
    "        })\n",
    "\n",
    "\n",
    "        csv_filename = os.path.join(global_results_folder, f\"Global_results_{sampler}.csv\")\n",
    "        df_global_avg.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Save plots\n",
    "    attribute_label = \"Mode Distance\" if varying_attribute == \"mode_means\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "    for metric in metrics:\n",
    "        fig, ax = fig_ax_pairs[metric]\n",
    "        finalize_and_save_plot(fig, ax, attribute_label, metric,\n",
    "                               f\"Averaged {metric.replace('_', ' ').title()} ({runs} Runs, config = {config_descr})\",\n",
    "                               os.path.join(global_plots_folder, f\"{metric}_global_plot.pdf\"))\n",
    "\n",
    "\n",
    "\n",
    "def finalize_and_save_plot(fig, ax, xlabel, ylabel, title, save_path):\n",
    "    \"\"\"\n",
    "    Finalizes the plot with labels, grid, and saves it to a file.\n",
    "    \n",
    "    Parameters:\n",
    "    - fig: Matplotlib figure\n",
    "    - ax: Matplotlib axis\n",
    "    - xlabel: Label for x-axis\n",
    "    - ylabel: Label for y-axis\n",
    "    - title: Title of the plot\n",
    "    - save_path: Path to save the figure.\n",
    "    \"\"\"\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(title=\"Sampler\")\n",
    "    ax.grid(True)\n",
    "    fig.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram(samples, title, save_path=None, posterior_type=None):\n",
    "    \"\"\"\n",
    "    Plots a histogram and KDE of the given samples.\n",
    "\n",
    "    Parameters:\n",
    "    - samples: 1D or 2D array of samples.\n",
    "    - title: Title of the plot.\n",
    "    - save_path: If provided, saves the figure to this path.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if samples.ndim == 2:\n",
    "        # Handle multivariate case\n",
    "        if samples.shape[1] == 2:\n",
    "            plt.scatter(samples[:, 0], samples[:, 1], alpha=0.3, label=\"2D Samples\")\n",
    "            plt.xlabel(\"Dimension 1\")\n",
    "            plt.ylabel(\"Dimension 2\")\n",
    "            plt.title(title)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "        elif posterior_type == \"MvNormal\" and samples.shape[1] > 2:\n",
    "            print(f\"Skipping plotting: Multivariate Normal with dimension {samples.shape[1]}.\")\n",
    "            return\n",
    "        \n",
    "    else:\n",
    "        # Standard 1D histogram + KDE\n",
    "        plt.hist(samples, bins=50, alpha=0.5, density=True, color='blue', edgecolor='black', label=\"Histogram\")\n",
    "        sns.kdeplot(samples, color='red', lw=2, label=\"KDE\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Sample Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def generate_iid_samples(posterior_type = None, num_samples=2000, rng=None,**params):\n",
    "    \"\"\"\n",
    "    Generate IID samples from a mixture distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "    - component_params: List of dictionaries with parameters for each component.\n",
    "    - num_samples: Number of samples to generate.\n",
    "    - weights: List of weights for the components.\n",
    "    - rng: Random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - iid_samples: Array of generated IID samples.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = rng or np.random.default_rng()\n",
    "\n",
    "    # Mapping from string names to scipy sampling functions\n",
    "    scipy_distributions = {\n",
    "        \"Normal\": lambda p: sp.norm.rvs(loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"StudentT\": lambda p: sp.t.rvs(df=p[\"nu\"], loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"Beta\": lambda p: sp.beta.rvs(a=p[\"a\"], b=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"Cauchy\": lambda p: sp.cauchy.rvs(loc=p[\"loc\"], scale=p[\"scale\"], size=num_samples, random_state=rng),\n",
    "        \"Laplace\": lambda p: sp.laplace.rvs(loc=p[\"mu\"], scale=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"MvNormal\": lambda p: rng.multivariate_normal(mean=np.array(p[\"mu\"]), cov=np.array(p[\"cov\"]), size=num_samples),\n",
    "    }\n",
    "\n",
    "    # Handle Skewed Student-T (which needs PyMC)\n",
    "    if posterior_type == \"SkewStudentT\":\n",
    "        with pm.Model():\n",
    "            skewed_t = pm.SkewStudentT.dist(a=params[\"a\"], b=params[\"b\"], mu=params[\"mu\"], sigma=params[\"sigma\"])\n",
    "            return pm.draw(skewed_t, draws=num_samples, random_seed=rng)\n",
    "\n",
    "    # Handle single distributions\n",
    "    if posterior_type in scipy_distributions:\n",
    "        print(f\"Generating {posterior_type} samples...\", params)\n",
    "        return scipy_distributions[posterior_type](params)\n",
    "\n",
    "    elif posterior_type == \"Mixture\":\n",
    "        component_types = params[\"component_types\"]\n",
    "        component_params = params[\"component_params\"]\n",
    "        weights = params[\"weights\"]\n",
    "\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        # normalize weights\n",
    "        weights = np.array(weights) / np.sum(weights)\n",
    "\n",
    "        # Choose which component each sample belongs to based on weights\n",
    "        chosen_components = rng.choice(len(component_types), size=num_samples, p=weights)\n",
    "\n",
    "        posterior_dim = None  \n",
    "\n",
    "        # Check if all components have the same dimension\n",
    "        for comp_params in component_params:\n",
    "            first_param = next(iter(comp_params))  # Get first parameter of current component\n",
    "            first_value = comp_params[first_param]  # Get its value\n",
    "            comp_dim = len(first_value) if isinstance(first_value, (np.ndarray, list)) else 1 # Get dimensionality of the first parameter\n",
    "\n",
    "            if posterior_dim is None:\n",
    "                posterior_dim = comp_dim  # Set the posterior dimension based on the first component\n",
    "               \n",
    "            elif comp_dim != posterior_dim:\n",
    "                raise ValueError(\"All mixture components must have the same dimensionality.\")\n",
    "\n",
    "        if posterior_dim > 1:\n",
    "            iid_samples = np.empty((num_samples, posterior_dim))  # Multivariate case\n",
    "        else:\n",
    "            iid_samples = np.empty(num_samples)\n",
    "\n",
    "        for i, (comp_type, comp_params) in enumerate(zip(component_types, component_params)):\n",
    "            mask = chosen_components == i  # Select samples for this component\n",
    "            num_selected = mask.sum()\n",
    "            if num_selected > 0:\n",
    "                if comp_type in scipy_distributions or comp_type == \"SkewStudentT\":\n",
    "                    iid_samples[mask] = generate_iid_samples(posterior_type=comp_type, num_samples=num_selected, rng=rng, **comp_params)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported component type in IID sampling: {comp_type}\")\n",
    "                \n",
    "        return iid_samples\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported posterior type: {posterior_type}\")\n",
    "\n",
    "\n",
    "# needs to be adapted \n",
    "def get_initvals(init_scheme, means, num_chains, rng=None):\n",
    "    \"\"\"Generates initialization values based on the chosen scheme.\"\"\"\n",
    "\n",
    "    middle_point = sum(means) / 2\n",
    "\n",
    "    if init_scheme == \"half_per_mode\":\n",
    "        # Half the chains start near the first mode, half near the second mode\n",
    "        if init_scheme == \"half_per_mode\":\n",
    "            # Dynamically assign half the chains to means[0] and the other half to means[1]\n",
    "            initvals = [{\"w\": 0.5, \"mixed_normal\": means[i < num_chains // 2]} for i in range(num_chains)]\n",
    "\n",
    "           # initvals = [\n",
    "            #{\"mixed_normal\": 0},  # Chain 1\n",
    "            #{\"mixed_normal\": 0},  # Chain 2\n",
    "            #{\"mixed_normal\": 20},  # Chain 3\n",
    "            #{\"mixed_normal\": 20}   # Chain 4\n",
    "        #]\n",
    "\n",
    "    elif init_scheme == \"one_third_first_mode\":\n",
    "        # ðŸ”¹ 1/3 of chains start in first mode, 2/3 in second mode\n",
    "        num_first_mode = num_chains // 3  # 1/3 of chains\n",
    "        num_second_mode = num_chains - num_first_mode  # Remaining 2/3\n",
    "\n",
    "        initvals = (\n",
    "            [{\"mixed_normal\": means[0]} for _ in range(num_first_mode)] +\n",
    "            [{\"mixed_normal\": means[1]} for _ in range(num_second_mode)]\n",
    "        )\n",
    "\n",
    "    elif init_scheme == \"all_in_middle\":\n",
    "        # All chains start in the middle between the two modes\n",
    "        initvals = [{\"mixed_normal\": middle_point} for _ in range(num_chains)]\n",
    "\n",
    "    elif init_scheme == \"random\":\n",
    "        # Chains are initialized randomly between the modes\n",
    "        initvals = [\n",
    "            {\"mixed_normal\": rng.uniform(means[0], means[1])}\n",
    "            for _ in range(num_chains)\n",
    "        ]\n",
    "\n",
    "    elif init_scheme == \"all_near_first_mode\":\n",
    "        # All chains start near the first mode\n",
    "        initvals = [{\"mixed_normal\": means[0]} for _ in range(num_chains)]\n",
    "\n",
    "    elif init_scheme == \"all_near_second_mode\":\n",
    "        # All chains start near the second mode\n",
    "        initvals = [{\"mixed_normal\": means[1]} for _ in range(num_chains)]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown initialization scheme: {init_scheme}\")\n",
    "\n",
    "    print(f\"Initvals: {initvals}\")\n",
    "\n",
    "    return initvals\n",
    "\n",
    "\n",
    "def sliced_wasserstein_distance(X, Y, L=100):\n",
    "    \"\"\"\n",
    "    Computes the sliced Wasserstein distance (SWD_p) between two sets of samples.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: numpy array of shape (N, d) -> first sample set\n",
    "    - Y: numpy array of shape (N, d) -> second sample set\n",
    "    - L: int, number of random projections\n",
    "    - p: int, order of Wasserstein distance (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "    - SWD_p: float, the sliced Wasserstein distance\n",
    "    \"\"\"\n",
    "    \n",
    "    #X = X.reshape(-1, 1)\n",
    "    #Y = Y.reshape(-1, 1)\n",
    "    # Ensure X and Y are at least 2D\n",
    "\n",
    "    N, d = X.shape  # Assuming X and Y have the same shape\n",
    "    S = 0  # Accumulation variable\n",
    "\n",
    "    for _ in range(L):\n",
    "        # Sample a random unit vector (projection direction)\n",
    "        theta = np.random.randn(d)\n",
    "        theta /= np.linalg.norm(theta)  # Normalize to unit sphere\n",
    "\n",
    "        # Compute projections\n",
    "        alpha = X @ theta\n",
    "        beta = Y @ theta\n",
    "\n",
    "        # Compute 1D Wasserstein distance\n",
    "        W_i = sp.wasserstein_distance(alpha, beta)\n",
    "\n",
    "        # Accumulate\n",
    "        S += W_i\n",
    "\n",
    "    # Compute final SWD\n",
    "    SWD_p = (S / L) \n",
    "\n",
    "    return SWD_p\n",
    "\n",
    "\n",
    "class PosteriorExample:\n",
    "    \"\"\"Base class for different posterior types.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None  # Placeholder for the PyMC model\n",
    "    \n",
    "    def _define_posterior(self):\n",
    "        \"\"\"Subclasses should implement this method to define the posterior.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement _define_posterior()\")\n",
    "\n",
    "    def run_sampling(self, sampler_name, num_samples=2000, tune=1000, num_chains=2, initvals=None, init_scheme=None, run_random_seed=None):\n",
    "        \"\"\"Runs MCMC sampling using the chosen sampler.\"\"\"\n",
    "        \n",
    "        with self.model:\n",
    "\n",
    "            # Define which sampler to use\n",
    "            if sampler_name == \"Metro\":\n",
    "                sampler = pm.Metropolis()\n",
    "            elif sampler_name == \"HMC\":\n",
    "                sampler = pm.NUTS()\n",
    "            elif sampler_name == \"DEMetro\":\n",
    "                sampler = pm.DEMetropolis()\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown sampler: {sampler_name}\")\n",
    "           \n",
    "            if init_scheme != None:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler,initvals=initvals, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)    #initvals=initvals,\n",
    "            else:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)\n",
    "        \n",
    "        return trace\n",
    "\n",
    "\n",
    "class SinglePosterior(PosteriorExample):\n",
    "    def __init__(self, dist_name, dist_params):\n",
    "        \"\"\"\n",
    "        A flexible class for defining unimodal posteriors.\n",
    "\n",
    "        Parameters:\n",
    "        - dist_name: String specifying the name of the PyMC distribution (e.g., \"Normal\", \"StudentT\").\n",
    "        - dist_params: Dictionary containing the parameters for the distribution.\n",
    "        \"\"\"\n",
    "        self.dist_name = dist_name\n",
    "        self.dist_params = dist_params\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        \n",
    "        dist_class = getattr(pm, self.dist_name)   # Retrieve the distribution class from PyMC\n",
    "        \n",
    "        with pm.Model() as model:\n",
    "            posterior_var = dist_class(\"posterior_var\", **self.dist_params)\n",
    "        return model\n",
    "\n",
    "\n",
    "class MixturePosterior(PosteriorExample):\n",
    "    \n",
    "    def __init__(self, component_types, component_params, weights=None, varying_component=None): \n",
    "        \"\"\"\n",
    "        A flexible mixture posterior allowing any number of components and arbitrary distributions.\n",
    "\n",
    "        Parameters:\n",
    "        - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "        - component_params: List of dictionaries, where each dictionary contains the parameters for the corresponding distribution.\n",
    "        - weights: List of weights for the mixture components (defaults to uniform).\n",
    "        \"\"\"\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(component_types))  # Default: Equal weights\n",
    "\n",
    "        if len(weights) != len(component_types):\n",
    "            raise ValueError(\"Number of weights must match number of components.\")\n",
    "\n",
    "        self.component_types = component_types\n",
    "        self.component_params = component_params\n",
    "        self.weights = weights\n",
    "\n",
    "        # Normalize weights\n",
    "        self.weights = np.array(self.weights) / np.sum(self.weights)\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        \n",
    "        # Construct component distributions dynamically\n",
    "        components = []\n",
    "        for dist_type, params in zip(self.component_types, self.component_params):\n",
    "            try:\n",
    "                dist_class = getattr(pm, dist_type)  # Retrieve PyMC distribution dynamically\n",
    "                components.append(dist_class.dist(**params))  # Use `.dist()` to create distribution\n",
    "            except AttributeError:\n",
    "                raise ValueError(f\"Unsupported distribution type: {dist_type}\")\n",
    "            \n",
    "        # Define the mixture model    \n",
    "        with pm.Model() as model:\n",
    "            # Mixture model\n",
    "            mixed_post_var = pm.Mixture(\"mixed_post_var\", w=self.weights, comp_dists=components)\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "class CustomPosterior(PosteriorExample):\n",
    "    \"\"\"\n",
    "    A flexible class to define custom posteriors using a user-specified log-probability function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logp_func, param_names, initvals=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - logp_func: Callable function that defines the log-probability.\n",
    "                     Must accept PyMC symbolic variables.\n",
    "        - param_names: List of parameter names required by logp_func.\n",
    "        - initvals: Optional dictionary for initial values.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior(logp_func, param_names, initvals)\n",
    "\n",
    "    def _define_posterior(self, logp_func, param_names, initvals):\n",
    "        with pm.Model() as model:\n",
    "            # Define parameters as model variables\n",
    "            params = {name: pm.Normal(name, mu=0, sigma=1) for name in param_names}\n",
    "\n",
    "            # Define the custom distribution using pm.CustomDist\n",
    "            pm.CustomDist(\"custom_distribution\", logp=logp_func, **params)\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "def run_experiment(\n",
    "    experiment_settings,\n",
    "    posterior_type,\n",
    "    config_descr,\n",
    "    runs,\n",
    "    varying_attribute, \n",
    "    varying_values,      \n",
    "    num_samples,\n",
    "    num_chains,\n",
    "    init_scheme=None,\n",
    "    base_random_seed=None,\n",
    "    **posterior_kwargs\n",
    "):\n",
    "    print(f\"\\n===== Config {config_descr} started! =====\\n\")\n",
    "\n",
    "    # Initialize random number generator\n",
    "    rng = np.random.default_rng(base_random_seed)\n",
    "\n",
    "    # Define required parameters for each posterior type\n",
    "    required_parameters = {\n",
    "        \"Mixture\": [\"component_types\", \"component_params\", \"weights\"],\n",
    "        \"Cauchy\": [\"loc\", \"scale\"],\n",
    "        \"Beta\": [\"a\", \"b\"],\n",
    "        \"Normal\": [\"mu\", \"sigma\"],\n",
    "        \"StudentT\": [\"nu\", \"mu\", \"sigma\"],\n",
    "        \"SkewStudentT\": [\"a\", \"b\", \"mu\", \"sigma\"],\n",
    "        \"Laplace\": [\"mu\", \"b\"],\n",
    "        \"MvNormal\": [\"mu\", \"cov\"],\n",
    "    }\n",
    "\n",
    "    # Validate that required keys exist (except for varying attributes)\n",
    "    required_keys = [k for k in required_parameters.get(posterior_type) if k != varying_attribute]\n",
    "    if not all(k in posterior_kwargs for k in required_keys):\n",
    "        raise ValueError(f\"{posterior_type} posterior requires {required_keys}\")\n",
    "\n",
    "    # Create keyword arguments for IID sample generation\n",
    "    iid_kwargs = {key: posterior_kwargs.get(key, \"varies\") for key in required_parameters.get(posterior_type)}\n",
    "\n",
    "    print(f\"Using IID sample settings: {iid_kwargs}\")\n",
    "\n",
    "    # Create configuration and histogram folders inside the experiment root\n",
    "    config_folder = os.path.join(experiment_root_folder, f\"{config_descr}_with_{runs}_runs\")\n",
    "    iid_histogram_folder = os.path.join(config_folder, \"KDE and Histograms of IID Samples\")\n",
    "    create_directories(config_folder, iid_histogram_folder)\n",
    "\n",
    "    # === Handle Precomputed IID Samples for Varying Attributes ===\n",
    "    iid_samples_dict = {}\n",
    "\n",
    "    if posterior_type == \"Mixture\":\n",
    "        component_index = posterior_kwargs.get(\"varying_component\")  # Get the selected component\n",
    "        \n",
    "        if component_index is None and varying_attribute not in [\"num_samples\", \"num_chains\", \"init_scheme\"]:\n",
    "            raise ValueError(f\"`varying_component` must be specified when varying '{varying_attribute}' in a Mixture.\")\n",
    "\n",
    "        # Loop through all varying values for Mixture posterior\n",
    "        for value in varying_values:\n",
    "\n",
    "            iid_kwargs[\"component_params\"][component_index][varying_attribute] = value\n",
    "            print(f\"Updating component {component_index} with {varying_attribute} = {value}\")\n",
    "\n",
    "            iid_samples_dict[value] = generate_iid_samples(\n",
    "                posterior_type=posterior_type,\n",
    "                component_types=iid_kwargs[\"component_types\"],\n",
    "                component_params=iid_kwargs[\"component_params\"], \n",
    "                weights=iid_kwargs[\"weights\"],\n",
    "                num_samples=num_samples,\n",
    "                rng=rng\n",
    "            )\n",
    "\n",
    "            # Plot histogram and KDE for each varying value\n",
    "            plot_histogram(\n",
    "                samples=iid_samples_dict[value],\n",
    "                title=f\"IID Samples Histogram & KDE ({varying_attribute}={value})\",\n",
    "                save_path=os.path.join(iid_histogram_folder, f\"iid_hist_kde_{varying_attribute}_{value}.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "            )\n",
    "\n",
    "    # Single posterior case\n",
    "    elif varying_attribute in iid_kwargs or varying_attribute == \"num_samples\":\n",
    "        for value in varying_values:\n",
    "            if varying_attribute == \"num_samples\":\n",
    "                current_num_samples = value  \n",
    "            else:\n",
    "                iid_kwargs[varying_attribute] = value  \n",
    "                current_num_samples = num_samples  \n",
    "            \n",
    "            iid_samples_dict[value] = generate_iid_samples(\n",
    "                posterior_type=posterior_type,\n",
    "                **iid_kwargs,\n",
    "                num_samples=current_num_samples,\n",
    "                rng=rng\n",
    "            )\n",
    "\n",
    "            # Plot histogram and KDE for each varying value\n",
    "            plot_histogram(\n",
    "                samples=iid_samples_dict[value],\n",
    "                title=f\"IID Samples Histogram & KDE ({varying_attribute}={value})\",\n",
    "                save_path=os.path.join(iid_histogram_folder, f\"iid_hist_kde_{varying_attribute}_{value}.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "            )\n",
    "\n",
    "    # Fixed posterior case (no varying attributes)\n",
    "    else:\n",
    "        iid_samples = generate_iid_samples(\n",
    "            posterior_type=posterior_type,\n",
    "            **iid_kwargs,\n",
    "            num_samples=num_samples,\n",
    "            rng=rng\n",
    "        )\n",
    "\n",
    "        plot_histogram(\n",
    "            samples=iid_samples,\n",
    "            title=\"IID Samples Histogram & KDE (fixed posterior)\",\n",
    "            save_path=os.path.join(iid_histogram_folder, \"iid_hist_kde.pdf\"),\n",
    "            posterior_type=posterior_type\n",
    "        )\n",
    "\n",
    "\n",
    "    # === Experiment Setup ===\n",
    "    samples_per_chain = \"varies\" if varying_attribute in [\"num_samples\", \"num_chains\"] else num_samples // num_chains\n",
    "\n",
    "    experiment_metadata = {\n",
    "        \"config_descr\": config_descr,\n",
    "        \"runs\": runs,\n",
    "        \"posterior_type\": posterior_type,\n",
    "        \"varying_attribute\": varying_attribute,\n",
    "        \"varying_values\": varying_values,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"num_chains\": num_chains,\n",
    "        \"samples_per_chain\": samples_per_chain,\n",
    "        \"init_scheme\": init_scheme,\n",
    "        \"base_random_seed\": base_random_seed,\n",
    "        \"git_tag\": get_git_tag(),\n",
    "    }\n",
    "    experiment_metadata.update(iid_kwargs)  # Add posterior-specific parameters\n",
    "\n",
    "    # Save metadata\n",
    "    metadata_filename = os.path.join(config_folder, f\"metadata_config_{config_descr}.json\")\n",
    "    with open(metadata_filename, \"w\") as f:\n",
    "        json.dump(experiment_metadata, f, indent=4)\n",
    "\n",
    "    # Define fixed colors for each sampler\n",
    "    sampler_colors = {\n",
    "        \"Metro\": \"blue\",\n",
    "        \"HMC\": \"red\",\n",
    "        \"DEMetro\": \"green\"\n",
    "    }\n",
    "\n",
    "    # === Run the Experiment ===\n",
    "    for run_id in range(1, runs + 1):\n",
    "        print(f\"\\n===== Running {config_descr} - Run {run_id} =====\\n\")\n",
    "\n",
    "        run_random_seed = int(rng.integers(1_000_000))\n",
    "\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "        traces_folder = os.path.join(run_folder, \"traces_and_trace_plots\")\n",
    "        plots_folder = os.path.join(run_folder, \"plots_of_run\")\n",
    "        \n",
    "\n",
    "        create_directories(run_folder, results_folder, traces_folder, plots_folder)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for value in varying_values:\n",
    "\n",
    "            var_attr_folder = os.path.join(traces_folder, f\"{varying_attribute}_{value}\")\n",
    "            create_directories(var_attr_folder)\n",
    "\n",
    "            # Handle parameter changes for Mixture case\n",
    "            if posterior_type == \"Mixture\":\n",
    "                component_index = posterior_kwargs.get(\"varying_component\")\n",
    "                if component_index is None and varying_attribute not in [\"num_samples\", \"num_chains\", \"init_scheme\"]:\n",
    "                    raise ValueError(f\"`varying_component` must be specified when varying '{varying_attribute}' in a Mixture.\")\n",
    "\n",
    "                # Modify only the selected component\n",
    "                posterior_kwargs[\"component_params\"][component_index][varying_attribute] = value\n",
    "            \n",
    "            else:\n",
    "                if varying_attribute in iid_kwargs:\n",
    "                    posterior_kwargs[varying_attribute] = value\n",
    "            \n",
    "            if varying_attribute == \"num_samples\":\n",
    "                num_samples = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"num_chains\":\n",
    "                num_chains = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"init_scheme\":\n",
    "                init_scheme = value\n",
    "\n",
    "            if posterior_type == \"Mixture\":\n",
    "                model = MixturePosterior(**posterior_kwargs)\n",
    "            else:\n",
    "                model = SinglePosterior(dist_name=posterior_type, dist_params=posterior_kwargs)\n",
    "\n",
    "            # Generate initialization values\n",
    "            if init_scheme != None:\n",
    "                initvals = get_initvals(init_scheme, posterior_kwargs.get(\"mu\"), num_chains, rng)\n",
    "            else:\n",
    "                initvals = None\n",
    "           \n",
    "            # Get IID samples for the current varying value\n",
    "            if varying_attribute != \"init_scheme\" and varying_attribute != \"num_chains\":\n",
    "                iid_samples = iid_samples_dict[value] \n",
    "\n",
    "            # Run sampling for all samplers\n",
    "            for sampler_name in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "                \n",
    "                if posterior_type == \"Mixture\":\n",
    "                    print(f\"Running {sampler_name} with {varying_attribute} = {value} (Component {component_index})\")\n",
    "                else:\n",
    "                    print(f\"Running {sampler_name} with {varying_attribute} = {value}\")\n",
    "\n",
    "                # **Measure Computation Time**\n",
    "                start_time = time.time()\n",
    "                trace = model.run_sampling(\n",
    "                    sampler_name, num_samples=samples_per_chain, num_chains=num_chains, init_scheme=init_scheme,\n",
    "                    initvals = initvals, run_random_seed=run_random_seed\n",
    "                )\n",
    "                end_time = time.time()\n",
    "                runtime = end_time - start_time\n",
    "\n",
    "                # Plot trace plots in notebook if requested\n",
    "                if experiment_settings.get(\"plot_traces_in_notebook\", False):\n",
    "                    az.plot_trace(trace, compact=True)\n",
    "                    plt.title(f\"Trace Plot ({sampler_name}, {varying_attribute} = {value})\")\n",
    "                    plt.show()\n",
    "                \n",
    "\n",
    "                # Save trace to NetCDF file if requested\n",
    "                if experiment_settings.get(\"save_traces\", False):\n",
    "                    trace_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace.nc\")\n",
    "                    az.to_netcdf(trace, trace_filename)\n",
    "\n",
    "\n",
    "                trace_plot_mode = experiment_settings.get(\"trace_plots\", \"none\")\n",
    "\n",
    "                # Save trace plots to PDF if requested\n",
    "                if trace_plot_mode == \"all\" or (trace_plot_mode == \"first_run_only\" and run_id == 1):\n",
    "                    trace_plot_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace_plot.pdf\")\n",
    "                    az.plot_trace(trace, compact=True)\n",
    "                    plt.savefig(trace_plot_filename, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "\n",
    "                # Select correct posterior variable name\n",
    "                if posterior_type == \"Mixture\":\n",
    "                    post_var_name = \"mixed_post_var\"\n",
    "                else:\n",
    "                    post_var_name = \"posterior_var\"\n",
    "\n",
    "                posterior_samples = trace.posterior[post_var_name].values\n",
    "        \n",
    "                # Ensure posterior_samples always has shape (N, dims)\n",
    "                if posterior_samples.ndim == 2:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, 1) \n",
    "                else:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, posterior_samples.shape[-1])\n",
    "\n",
    "                # Ensure iid_samples always has shape (N, dims)\n",
    "                if iid_samples.ndim == 1:\n",
    "                    iid_samples = iid_samples[:, np.newaxis]\n",
    "                else:\n",
    "                    iid_samples = iid_samples.reshape(-1, iid_samples.shape[-1])\n",
    "                \n",
    "                ws_distance = sliced_wasserstein_distance(posterior_samples, iid_samples, L=5)\n",
    " \n",
    "                # Compute R-hat and ESS\n",
    "                r_hat = az.rhat(trace)[post_var_name].max().item()\n",
    "                ess = az.ess(trace)[post_var_name].min().item()\n",
    "\n",
    "                results.append({\n",
    "                    varying_attribute: value,\n",
    "                    \"sampler\": sampler_name,\n",
    "                    \"wasserstein_distance\": ws_distance,\n",
    "                    \"r_hat\": r_hat,\n",
    "                    \"ess\": ess,\n",
    "                    \"runtime\": runtime\n",
    "                })\n",
    "\n",
    "        # Convert results to DataFrame and save\n",
    "        df_results = pd.DataFrame(results)\n",
    "\n",
    "        # Handle tuple-based attributes consistently\n",
    "        if isinstance(df_results[varying_attribute].iloc[0], tuple):\n",
    "            if varying_attribute == \"mode_means\":\n",
    "                df_results[\"mode_distance\"] = df_results[varying_attribute].apply(lambda x: abs(x[1] - x[0]))\n",
    "                varying_attribute_for_plot = \"mode_distance\"\n",
    "            else:\n",
    "                df_results[varying_attribute] = df_results[varying_attribute].apply(str)\n",
    "                varying_attribute_for_plot = varying_attribute\n",
    "        else:\n",
    "            varying_attribute_for_plot = varying_attribute\n",
    "\n",
    "        # Sort the DataFrame by the final chosen attribute\n",
    "        df_results = df_results.sort_values(varying_attribute_for_plot, ascending=True)\n",
    "\n",
    "\n",
    "        plot_and_save_all_metrics(\n",
    "            df_results=df_results,\n",
    "            sampler_colors=sampler_colors,\n",
    "            varying_attribute=varying_attribute,\n",
    "            varying_attribute_for_plot=varying_attribute_for_plot,\n",
    "            results_folder=results_folder,\n",
    "            plots_folder=plots_folder,\n",
    "            run_id=run_id,\n",
    "            config_descr=config_descr\n",
    "        )\n",
    "\n",
    "    print(\"\\n===== All Runs Completed Successfully! =====\\n\")\n",
    "\n",
    "    # ===== GLOBAL RESULTS FOLDER =====\n",
    "    global_folder = os.path.join(config_folder, \"global_results\")\n",
    "    global_results_folder = os.path.join(global_folder, \"results\")\n",
    "    global_plots_folder = os.path.join(global_folder, \"plots\")\n",
    "    create_directories(global_folder, global_results_folder, global_plots_folder)\n",
    "\n",
    "    # Collect all results from all runs\n",
    "    df_all_runs = []\n",
    "\n",
    "    for run_id in range(1, runs + 1):\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "\n",
    "        for sampler in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "            csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "            df_run = pd.read_csv(csv_filename)\n",
    "            df_run[\"run_id\"] = run_id \n",
    "            df_run[\"sampler\"] = sampler  \n",
    "            df_all_runs.append(df_run)\n",
    "\n",
    "\n",
    "    # Combine all results into a single data frame \n",
    "    df_all_runs = pd.concat(df_all_runs, ignore_index=True)\n",
    "\n",
    "    compute_and_save_global_metrics(\n",
    "        df_all_runs=df_all_runs,\n",
    "        sampler_colors=sampler_colors,\n",
    "        varying_attribute=varying_attribute,\n",
    "        runs=runs,\n",
    "        config_descr=config_descr,\n",
    "        global_results_folder=global_results_folder,\n",
    "        global_plots_folder=global_plots_folder\n",
    "    )\n",
    "\n",
    "    print(f\"\\n===== Config {config_descr} Completed Successfully! =====\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def validate_config(config):\n",
    "    \"\"\"Checks if the config correctly defines one varying attribute and all other attributes are fixed.\"\"\"\n",
    "    \n",
    "    REQUIRED_ATTRIBUTES = {\n",
    "    \"config_descr\",\n",
    "    \"posterior_type\",\n",
    "    \"runs\",\n",
    "    \"num_samples\",\n",
    "    \"num_chains\",\n",
    "    \"varying_attribute\",\n",
    "    \"varying_values\",\n",
    "    }\n",
    "\n",
    "    # Posterior-specific required attributes\n",
    "    POSTERIOR_ATTRIBUTES = {\n",
    "        \"Cauchy\": {\"loc\", \"scale\"},\n",
    "        \"Beta\": {\"a\", \"b\"},\n",
    "        \"Normal\": {\"mu\", \"sigma\"},\n",
    "        \"StudentT\": {\"nu\", \"mu\", \"sigma\"},\n",
    "        \"Laplace\": {\"mu\", \"b\"},\n",
    "        \"SkewStudentT\": {\"a\", \"b\", \"mu\", \"sigma\"},\n",
    "        \"Mixture\": {\"component_types\", \"component_params\", \"weights\"},\n",
    "        \"MvNormal\": {\"mu\", \"cov\"}\n",
    "    }\n",
    "\n",
    "    OPTIONAL_ATTRIBUTES = {\"base_random_seed\", \"init_scheme\", \"varying_component\"}\n",
    "\n",
    "    if \"config_descr\" not in config:\n",
    "        raise ValueError(\"Config is missing 'config_descr'.\")\n",
    "    \n",
    "    config_descr = config[\"config_descr\"]\n",
    "\n",
    "    if \"varying_attribute\" not in config:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing 'varying_attribute'.\")\n",
    "    \n",
    "    varying_attr = config[\"varying_attribute\"]\n",
    "\n",
    "    # Ensure all required attributes are present\n",
    "    missing_attrs = REQUIRED_ATTRIBUTES - config.keys() - {varying_attr}\n",
    "\n",
    "    if missing_attrs:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing required attributes: {missing_attrs}.\")\n",
    "    \n",
    "    posterior_type = config[\"posterior_type\"]\n",
    "\n",
    "    if posterior_type not in POSTERIOR_ATTRIBUTES:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'posterior_type': '{posterior_type}'.\")\n",
    "\n",
    "    # Ensure varying_attribute is a recognized attribute\n",
    "    all_valid_attributes = REQUIRED_ATTRIBUTES.union(POSTERIOR_ATTRIBUTES[posterior_type], OPTIONAL_ATTRIBUTES)\n",
    "\n",
    "    if varying_attr not in all_valid_attributes:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'varying_attribute': '{varying_attr}'.\")\n",
    "    \n",
    "    if varying_attr in config:\n",
    "        raise ValueError(f\"Config '{config['config_descr']}' incorrectly defines '{varying_attr}' as both fixed and varying.\")\n",
    "\n",
    "    # Ensure all fixed attributes are present\n",
    "    for attr in all_valid_attributes - OPTIONAL_ATTRIBUTES - {varying_attr}:\n",
    "          if attr not in config:\n",
    "            raise ValueError(f\"Config '{config_descr}' is missing required fixed attribute '{attr}'.\")\n",
    "\n",
    "# to do: if init_schme is present, check that it is a valid init scheme\n",
    "\n",
    "\n",
    "\n",
    "# posterior_type = \"Cauchy\", \"Beta\", \"Normal\", \"StudentT\", \"Laplace\", \"SkewstudentT\"\n",
    "# varying_attribute = \"num_samples\", \"num_chains\", \"init_scheme\" or posterior specific attribute\n",
    "# bimmodal specific attributes = \"mode_means\", \"std_of_modes\", \"weights\"\n",
    "# cauchy specific attributes = \"loc\", \"scale\"\n",
    "# beta specific attributes = \"a\", \"b\"\n",
    "# normal specific attributes = \"mu\", \"sigma\"\n",
    "# student_t specific attributes = \"nu\", \"mu\", \"sigma\"\n",
    "# laplace specific attributes = \"mu\", \"b\"\n",
    "# skewed_student_t specific attributes = \"a\", \"b\", \"mu\", \"sigma\"\n",
    "# all but the varying attribute must be fixed and present in the config\n",
    "\n",
    "#def my_custom_logp_function(x):\n",
    "#    w1, w2 = 0.4, 0.6\n",
    "#    mu1, mu2 = -2, 2\n",
    "#    sigma1, sigma2 = 1, 1\n",
    "\n",
    "    #log_like1 = pm.logp(pm.Normal.dist(mu=mu1, sigma=sigma1), x)\n",
    "    #log_like2 = pm.logp(pm.Normal.dist(mu=mu2, sigma=sigma2), x)\n",
    "\n",
    "    #return pm.math.logsumexp([np.log(w1) + log_like1, np.log(w2) + log_like2])\n",
    "\n",
    "# default attributes\n",
    "default_num_samples = 4000\n",
    "default_num_chains = 4\n",
    "default_base_random_seed = 42\n",
    "default_runs = 1\n",
    "\n",
    "unimodal = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Normal\",\n",
    "        \"posterior_type\": \"Normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 2, 5, 10],\n",
    "        \"sigma\": 1\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Student_t\",\n",
    "        \"posterior_type\": \"StudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\":  default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 3, 5, 30],\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Laplace_test\",\n",
    "        \"posterior_type\": \"Laplace\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"b\",\n",
    "        \"varying_values\": [0.5, 1, 2, 5],\n",
    "        \"mu\": 0,\n",
    "    },\n",
    "]\n",
    "\n",
    "high_dim_and_correlated = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_3d_high_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (-5, 0, 5),\n",
    "            (0, 0, 0),\n",
    "            (-10, 20, -30),\n",
    "            (50, -50, 100)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.9, 0.85], \n",
    "              [0.9, 1, 0.88], \n",
    "              [0.85, 0.88, 1]]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_2d_low_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (0, 0),\n",
    "            (-10, 10),\n",
    "            (20, -20),\n",
    "            (50, -50)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.1], [0.1, 1]]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_2d_high_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (0, 0),\n",
    "            (-10, 10),\n",
    "            (20, -20),\n",
    "            (50, -50)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.95], [0.95, 1]] \n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_3d_low_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (-5, 0, 5),\n",
    "            (0, 0, 0),\n",
    "            (-10, 20, -30),\n",
    "            (50, -50, 100)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.2, 0.1], \n",
    "                [0.2, 1, 0.15], \n",
    "                [0.1, 0.15, 1]]  \n",
    "    }\n",
    "]\n",
    "\n",
    "multimodal = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(5, 5), (10, -10), (20, 20), (50, -50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.3, 0.4, 0.3]\n",
    "    },\n",
    "    {   \n",
    "        \"config_descr\": \"Normal_and_student_t\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"StudentT\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 5, 10],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"nu\": 3, \"mu\": 10, \"sigma\": 2}],\n",
    "        \"weights\": [0.6, 0.4]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "difficult_geometries = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"SkewStudentT\",\n",
    "        \"posterior_type\": \"SkewStudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [1, 2, 3, 5],\n",
    "        \"b\": 1,\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_of_SkewStudentT\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 3, 6, 10],\n",
    "        \"varying_component\": 0,\n",
    "        \"component_types\": [\"SkewStudentT\", \"SkewStudentT\"],\n",
    "        \"component_params\": [\n",
    "            {\"a\": 3, \"b\": 1, \"sigma\": 1},\n",
    "            {\"a\": 9, \"b\": 3, \"mu\": 3, \"sigma\": 4}\n",
    "        ],\n",
    "        \"weights\": [0.5, 0.5]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "asymmetric_weights_mixture = [\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3),(5, 5), (10, 10), (20, 20), (50, 50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.2, 0.2, 0.6]\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "symmetric_weights_mixture = [\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3),(5, 5), (10, 10), (20, 20), (50, 50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.3, 0.3, 0.4]\n",
    "    },\n",
    "\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Config Normal started! =====\n",
      "\n",
      "Using IID sample settings: {'mu': 'varies', 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 0, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 2, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 5, 'sigma': 1}\n",
      "Generating Normal samples... {'mu': 10, 'sigma': 1}\n",
      "\n",
      "===== Running Normal - Run 1 =====\n",
      "\n",
      "Running Metro with mu = 0\n",
      "Running HMC with mu = 0\n",
      "Running DEMetro with mu = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m category:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexperiment_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposterior_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposterior_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_descr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_descr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvarying_attribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvarying_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit_scheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_random_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_random_seed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_descr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_random_seed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposterior_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass remaining keys as posterior_kwargs\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in config \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_descr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 747\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(experiment_settings, posterior_type, config_descr, runs, varying_attribute, varying_values, num_samples, num_chains, init_scheme, base_random_seed, **posterior_kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# **Measure Computation Time**\u001b[39;00m\n\u001b[1;32m    746\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 747\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_sampling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples_per_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_scheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_scheme\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_random_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_random_seed\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    752\u001b[0m runtime \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[13], line 426\u001b[0m, in \u001b[0;36mPosteriorExample.run_sampling\u001b[0;34m(self, sampler_name, num_samples, tune, num_chains, initvals, init_scheme, run_random_seed)\u001b[0m\n\u001b[1;32m    424\u001b[0m         trace \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample(num_samples, tune\u001b[38;5;241m=\u001b[39mtune, step\u001b[38;5;241m=\u001b[39msampler,initvals\u001b[38;5;241m=\u001b[39minitvals, chains\u001b[38;5;241m=\u001b[39mnum_chains, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, progressbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_seed\u001b[38;5;241m=\u001b[39mrun_random_seed)    \u001b[38;5;66;03m#initvals=initvals,\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 426\u001b[0m         trace \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_random_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trace\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/sampling/mcmc.py:862\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m     _print_step_hierarchy(step)\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m joined_blas_limiter():\n\u001b[0;32m--> 862\u001b[0m         \u001b[43m_sample_population\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallelize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample_args\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential sampling (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchains\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chains in 1 job)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/sampling/population.py:105\u001b[0m, in \u001b[0;36m_sample_population\u001b[0;34m(initial_points, draws, start, random_seed, step, tune, model, progressbar, parallelize, traces, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m CustomProgress(disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m progressbar) \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[1;32m    104\u001b[0m     task \u001b[38;5;241m=\u001b[39m progress\u001b[38;5;241m.\u001b[39madd_task(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[red]Sampling...\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mdraws)\n\u001b[0;32m--> 105\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/sampling/population.py:429\u001b[0m, in \u001b[0;36m_iter_population\u001b[0;34m(draws, tune, popstep, steppers, traces, points)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m popstep:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;66;03m# iterate draws of all chains\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(draws):\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;66;03m# this call steps all chains and returns a list of (point, stats)\u001b[39;00m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;66;03m# the `popstep` may interact with subprocesses internally\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m         updates \u001b[38;5;241m=\u001b[39m \u001b[43mpopstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;66;03m# apply the update to the points and record to the traces\u001b[39;00m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c, strace \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(traces):\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/sampling/population.py:300\u001b[0m, in \u001b[0;36mPopulationStepper.step\u001b[0;34m(self, tune_stop, population)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_parallelized:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnchains):\n\u001b[0;32m--> 300\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_primary_ends\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtune_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# Blockingly get the step outcomes\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnchains):\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/multiprocessing/connection.py:206\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/multiprocessing/connection.py:427\u001b[0m, in \u001b[0;36mConnection._send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send(buf)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# Issue #20540: concatenate before sending, to avoid delays due\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# to Nagle's algorithm on a TCP socket.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;66;03m# Also note we want to avoid sending a 0-length buffer separately,\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;66;03m# to avoid \"broken pipe\" errors if the other end closed the pipe.\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._send\u001b[0;34m(self, buf, write)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(buf)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     remaining \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "categories = [unimodal, high_dim_and_correlated, multimodal, difficult_geometries, asymmetric_weights_mixture, symmetric_weights_mixture]\n",
    "\n",
    "category = categories[0]\n",
    "\n",
    "experiment_name = \"g++ test\"\n",
    "\n",
    "# Define the root directory for all experiments\n",
    "experiment_root_folder = f\"exp_{experiment_name}\"\n",
    "\n",
    "# Check if the folder already exists\n",
    "if os.path.exists(experiment_root_folder):\n",
    "    user_input = input(\n",
    "        f\"Folder '{experiment_root_folder}' already exists and will be overwritten.\\n\"\n",
    "        \"Do you want to continue? (yes/no): \"\n",
    "    ).strip().lower()\n",
    "\n",
    "    if user_input not in [\"yes\", \"y\"]:\n",
    "        print(\"Operation aborted. No files were deleted.\")\n",
    "        exit()  # Stop execution\n",
    "    \n",
    "    shutil.rmtree(experiment_root_folder)\n",
    "\n",
    "create_directories(experiment_root_folder)\n",
    "\n",
    "# important for produced file size\n",
    "# It's about the individual traces, the global traces and traces per run are always saved\n",
    "experiment_settings = {\n",
    "    \"save_traces\": False,                 # if True, save traces to NetCDF files\n",
    "    \"trace_plots\": \"none\",                # \"none\", \"first_run_only\", \"all\" \n",
    "    \"plot_traces_in_notebook\": False       # if True, plot traces in the notebook\n",
    "}\n",
    "\n",
    "failed_configs = []\n",
    "start_time = time.time()\n",
    "start_dt = datetime.now()\n",
    "\n",
    "# need to adapt validation of config\n",
    "#for config in experiment:\n",
    "#    validate_config(config)\n",
    "\n",
    "#print(\"All configurations are valid. Starting experiments...\")\n",
    "\n",
    "for config in category:\n",
    "    try:\n",
    "        run_experiment(\n",
    "            experiment_settings,\n",
    "            posterior_type=config[\"posterior_type\"],\n",
    "            config_descr=config[\"config_descr\"],\n",
    "            runs=config[\"runs\"],\n",
    "            varying_attribute=config[\"varying_attribute\"],\n",
    "            varying_values=config[\"varying_values\"],\n",
    "            init_scheme=\"varies\" if config[\"varying_attribute\"] == \"init_scheme\" else config.get(\"init_scheme\", None),\n",
    "            num_samples=\"varies\" if config[\"varying_attribute\"] == \"num_samples\" else config[\"num_samples\"],\n",
    "            num_chains=\"varies\" if config[\"varying_attribute\"] == \"num_chains\" else config[\"num_chains\"],\n",
    "            base_random_seed=config.get(\"base_random_seed\", None),\n",
    "            **{k: v for k, v in config.items() if k not in [\n",
    "                \"config_descr\", \"runs\", \"varying_attribute\", \"varying_values\", \n",
    "                \"num_samples\", \"num_chains\", \"init_scheme\", \n",
    "                \"base_random_seed\", \"posterior_type\"\n",
    "            ]}  # Pass remaining keys as posterior_kwargs\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in config '{config['config_descr']}': {e}\")\n",
    "        failed_configs.append((config['config_descr'], str(e)))\n",
    "\n",
    "end_time = time.time()\n",
    "end_dt = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "def get_folder_size(path='.'):\n",
    "    \"\"\"Compute total size of all files in directory.\"\"\"\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total += os.path.getsize(fp)\n",
    "    return total\n",
    "\n",
    "\n",
    "# Prepare the summary text\n",
    "size_bytes = get_folder_size(experiment_root_folder)\n",
    "total_configs = sum(len(category) for category in categories)\n",
    "\n",
    "\n",
    "summary_lines = [\n",
    "    \"\\n============================\",\n",
    "    \"Experiment Summary\",\n",
    "    \"============================\",\n",
    "    f\"Started at:               {start_dt.strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"Finished at:              {end_dt.strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"Total duration:           {round(duration / 60, 2)} minutes ({round(duration, 1)} seconds)\",\n",
    "    f\"Output folder:            {experiment_root_folder}\",\n",
    "    f\"Output folder size:       {humanize.naturalsize(size_bytes)}\",\n",
    "    f\"Total configurations:     {total_configs}\",\n",
    "    f\"Successful runs:          {total_configs - len(failed_configs)}\",\n",
    "    f\"Failed configurations:    {len(failed_configs)}\"\n",
    "]\n",
    "\n",
    "if failed_configs:\n",
    "    summary_lines.append(\"\\n Failed Configurations:\")\n",
    "    for cfg, msg in failed_configs:\n",
    "        summary_lines.append(f\" - {cfg}: {msg}\")\n",
    "\n",
    "# Print to console\n",
    "print(\"\\n\".join(summary_lines))\n",
    "\n",
    "# Also save to summary.txt\n",
    "summary_path = os.path.join(experiment_root_folder, \"summary.txt\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(summary_lines))\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_all_inference_attr = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Samples_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",    \n",
    "        \"varying_values\": [100, 200, 300],\n",
    "        \"mode_means\": (3,-3),\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1)\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"config_descr\": \"Chains_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_chains\",    \n",
    "        \"varying_values\": [4,6,8],\n",
    "        \"mode_means\": (3,-3),\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1)\n",
    "    }\n",
    "    #add init scheme test\n",
    "\n",
    "    #add burn in as well?\n",
    "    ]\n",
    "\n",
    "\n",
    "# Can select any of the posterior_type kwargs to vary, e.g., for a normal distribution, mu or sigma can be varied\n",
    "Test_all_posterior_types = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Normal_test\",\n",
    "        \"posterior_type\": \"normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 1, 2],\n",
    "        \"sigma\": 1\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Beta_test\",\n",
    "        \"posterior_type\": \"beta\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [0.5,5,1],\n",
    "        \"b\": 3,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Cauchy_test\",\n",
    "        \"posterior_type\": \"cauchy\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"loc\",\n",
    "        \"varying_values\": [0, -2, 5],\n",
    "        \"scale\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Laplace_test\",\n",
    "        \"posterior_type\": \"laplace\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"b\",\n",
    "        \"varying_values\": [1, 2, 3, 20],\n",
    "        \"mu\": 0,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Student_t_test\",\n",
    "        \"posterior_type\": \"student_t\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\":  default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 3],\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Skewed_student_t_test\",\n",
    "        \"posterior_type\": \"skewed_student_t\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [0.5, 1, 2],\n",
    "        \"b\": 1,\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Bimodal_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mode_means\",\n",
    "        \"varying_values\": [(0,0), (1,1), (2,2)],\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1),\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "test_triple_normal = [\n",
    "    \n",
    "    {\n",
    "        \"config_descr\": \"Mixture_test\",\n",
    "        \"posterior_type\": \"mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000, 2000, 8000],\n",
    "        \"component_types\": [\"normal\", \"normal\", \"normal\"],\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 10, \"sigma\": 1}, {\"mu\": -40, \"sigma\": 1}],\n",
    "        \"weights\": [0.3, 0.5, 0.2]  # Uneven weighting\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "test_normal_and_student_t = [\n",
    "    \n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_test\",\n",
    "        \"posterior_type\": \"mixture\",\n",
    "        \"component_types\": [\"normal\", \"student_t\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [10000],\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"nu\": 3, \"mu\": 5, \"sigma\": 2}],\n",
    "        \"weights\": [0.6, 0.4]\n",
    "        }\n",
    "]\n",
    "\n",
    "test_mvnormal_2d_mixture = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"MVNormal_mixture\",\n",
    "        \"posterior_type\": \"mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"component_types\": [\"mv_normal\", \"mv_normal\", \"mv_normal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},   # First component\n",
    "                {\"mu\": [10, 10], \"cov\": [[2, 0.3], [0.3, 2]]},  # Second component\n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  # Third component\n",
    "        ],\n",
    "        \"weights\": [0.3, 0.4, 0.3]\n",
    "    }\n",
    "        \n",
    "]\n",
    "\n",
    "test_mvnormal = [\n",
    "    {\n",
    "        \"config_descr\": \"MVNormal_test\",\n",
    "        \"posterior_type\": \"mv_normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"mu\": [10, -20],\n",
    "        #\"cov\": [[1, 0.5], [0.5, 1]]\n",
    "        \"cov\": [[1, 0.95], [0.95, 1]]  # Very strong correlation,\n",
    "    }\n",
    "]\n",
    "\n",
    "test_3d_normal = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"MVNormal_test\",\n",
    "        \"posterior_type\": \"mv_normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"num_samples\",\n",
    "        \"varying_values\": [1000],\n",
    "        \"mu\":  [-50, 0, 50],\n",
    "        \"cov\":  [[1, 0.8, 0.3], [0.8, 1, 0.4], [0.3, 0.4, 1]]  # Works (3D Normal)\n",
    "\n",
    "    }   \n",
    "\n",
    "]\n",
    "\n",
    "#Test_custom = [\n",
    "#    {\n",
    "#        \"config_descr\": \"custom_gaussian_mixture\",\n",
    "#        \"posterior_type\": \"custom\",\n",
    "#        \"runs\": 5,\n",
    "#        \"num_samples\": default_num_samples,\n",
    "#        \"num_chains\": default_num_chains,\n",
    "#        \"base_random_seed\": 42,\n",
    "#        #\"logp_func\": my_custom_logp_function,  # Custom function\n",
    "#        #\"priors\": {\"x\": pm.Uniform.dist(lower=-10, upper=10)}\n",
    "#    }\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3318593455.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[103], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# old boilerplate code\n",
    "# initialize plots for all samplers\n",
    "        fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\n",
    "        fig_rhat, ax_rhat = plt.subplots(figsize=(10, 6))\n",
    "        fig_ess, ax_ess = plt.subplots(figsize=(10, 6))\n",
    "        fig_time, ax_time = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "        for sampler in df_results[\"sampler\"].unique():\n",
    "            df_sampler = df_results[df_results[\"sampler\"] == sampler]\n",
    "            csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "            df_sampler.to_csv(csv_filename, index=False)\n",
    "\n",
    "            # Plot Wasserstein Distance\n",
    "            ax_ws.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"wasserstein_distance\"], \n",
    "                marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "            # Plot R-hat values\n",
    "            ax_rhat.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"r_hat\"], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "            \n",
    "            # Plot ESS values\n",
    "            ax_ess.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"ess\"], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "            # **Plot Computation Time**\n",
    "            ax_time.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"runtime\"], \n",
    "                        marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                        color=sampler_colors.get(sampler, \"black\"))\n",
    "            \n",
    "        \n",
    "        # Set dynamic axis labels and titles\n",
    "        attribute_label = \"Mode Distance\" if varying_attribute == \"mode_means\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "        \n",
    "        # ===== Finalize and Save Wasserstein Plot =====\n",
    "        ax_ws.set_xlabel(attribute_label)\n",
    "        ax_ws.set_ylabel(\"Wasserstein Distance\")\n",
    "        ax_ws.set_title(f\"Wasserstein Distance for Samplers (config =_{config_descr})\")\n",
    "        ax_ws.legend(title=\"Sampler\")\n",
    "        ax_ws.grid(True)\n",
    "        plot_filename = os.path.join(plots_folder, f\"Wasserstein_run_{run_id}.pdf\")\n",
    "        fig_ws.savefig(plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_ws)\n",
    "\n",
    "        # ===== Finalize and Save R-hat Plot =====\n",
    "        ax_rhat.set_xlabel(attribute_label)\n",
    "        ax_rhat.set_ylabel(\"R-hat\")\n",
    "        ax_rhat.set_title(f\"R-hat for Samplers (config =_{config_descr})\")\n",
    "        ax_rhat.legend(title=\"Sampler\")\n",
    "        ax_rhat.grid(True)\n",
    "        rhat_plot_filename = os.path.join(plots_folder, f\"R-hat_run_{run_id}.pdf\")\n",
    "        fig_rhat.savefig(rhat_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_rhat)\n",
    "\n",
    "        # ===== Finalize and Save ESS Plot =====\n",
    "        ax_ess.set_xlabel(attribute_label)\n",
    "        ax_ess.set_ylabel(\"ESS\")\n",
    "        ax_ess.set_title(f\"ESS for Samplers (config =_{config_descr})\")\n",
    "        ax_ess.legend(title=\"Sampler\")\n",
    "        ax_ess.grid(True)\n",
    "        ess_plot_filename = os.path.join(plots_folder, f\"ESS_run_{run_id}.pdf\")\n",
    "        fig_ess.savefig(ess_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_ess)\n",
    "\n",
    "        # ===== Finalize and Save Time Plot =====\n",
    "        ax_time.set_xlabel(attribute_label)\n",
    "        ax_time.set_ylabel(\"Computation Time (seconds)\")\n",
    "        ax_time.set_title(f\"Computation Time for Samplers (config =_{config_descr})\")\n",
    "        ax_time.legend(title=\"Sampler\")\n",
    "        ax_time.grid(True)\n",
    "        time_plot_filename = os.path.join(plots_folder, f\"ComputationTime_run_{run_id}.pdf\")\n",
    "        fig_time.savefig(time_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old boilerplate code for global metrics\n",
    "\n",
    "if varying_attribute == \"mode_means\":\n",
    "        df_all_runs[\"mode_distance\"] = df_all_runs[varying_attribute].apply(lambda x: abs(eval(x)[1] - eval(x)[0]))\n",
    "        df_all_runs = df_all_runs.sort_values(\"mode_distance\", ascending=True)\n",
    "        varying_attribute_for_global_plot = \"mode_distance\"\n",
    "    else:\n",
    "        df_all_runs = df_all_runs.sort_values(varying_attribute, ascending=True)\n",
    "        varying_attribute_for_global_plot = varying_attribute\n",
    "\n",
    "\n",
    "    # Initialize global plots\n",
    "    fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\n",
    "    fig_rhat, ax_rhat = plt.subplots(figsize=(10, 6))\n",
    "    fig_ess, ax_ess = plt.subplots(figsize=(10, 6))\n",
    "    fig_time, ax_time = plt.subplots(figsize=(10, 6)) \n",
    "\n",
    "    for sampler in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "        df_sampler = df_all_runs[df_all_runs[\"sampler\"] == sampler]\n",
    "        color = sampler_colors.get(sampler, \"black\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Pivot tables: rows = varying attribute, columns = run_id, values = metrics\n",
    "        df_ws = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"wasserstein_distance\")\n",
    "        df_rhat = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"r_hat\")\n",
    "        df_ess = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"ess\")\n",
    "        df_time = df_sampler.pivot_table(index=varying_attribute, columns=\"run_id\", values=\"runtime\")\n",
    "    \n",
    "        # Compute mean and standard deviation for error bars\n",
    "        ws_mean, ws_std = df_ws.mean(axis=1), df_ws.std(axis=1)\n",
    "        rhat_mean, rhat_std = df_rhat.mean(axis=1), df_rhat.std(axis=1)\n",
    "        ess_mean, ess_std = df_ess.mean(axis=1), df_ess.std(axis=1)\n",
    "        time_mean, time_std = df_time.mean(axis=1), df_time.std(axis=1)\n",
    "\n",
    "        # Plot with error bars\n",
    "        ax_ws.errorbar(ws_mean.index, ws_mean, yerr=ws_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_rhat.errorbar(rhat_mean.index, rhat_mean, yerr=rhat_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_ess.errorbar(ess_mean.index, ess_mean, yerr=ess_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_time.errorbar(time_mean.index, time_mean, yerr=time_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "\n",
    "        # Save global averages \n",
    "        df_global_avg = pd.DataFrame({\n",
    "            varying_attribute: ws_mean.index,\n",
    "            \"global_avg_ws\": ws_mean.values,\n",
    "            \"global_avg_ws_std\": ws_std.values,\n",
    "            \"global_avg_rhat\": rhat_mean.values,\n",
    "            \"global_avg_rhat_std\": rhat_std.values,\n",
    "            \"global_avg_ess\": ess_mean.values,\n",
    "            \"global_avg_ess_std\": ess_std.values,\n",
    "            \"global_avg_time\": time_mean.values,\n",
    "            \"global_avg_time_std\": time_std.values\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        sampler_csv_filename = os.path.join(global_results_folder, f\"Global_results_{sampler}.csv\")\n",
    "        df_global_avg.to_csv(sampler_csv_filename, index=False)\n",
    "\n",
    "\n",
    "    # ===== Save Global Wasserstein Plot =====\n",
    "    ax_ws.set_xlabel(attribute_label)\n",
    "    ax_ws.set_ylabel(\"Average Wasserstein Distance\")\n",
    "    ax_ws.set_title(f\"Averaged Wasserstein Distance ({runs} Runs, config = {config_descr})\")\n",
    "    ax_ws.legend(title=\"Sampler\")\n",
    "    ax_ws.grid(True)\n",
    "    fig_ws.savefig(os.path.join(global_plots_folder, \"Wasserstein_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_ws)\n",
    "\n",
    "    # ===== Save Global R-hat Plot =====\n",
    "    ax_rhat.set_xlabel(attribute_label)\n",
    "    ax_rhat.set_ylabel(\"Average R-hat\")\n",
    "    ax_rhat.set_title(f\"Averaged R-hat Values ({runs} Runs, config = {config_descr})\")\n",
    "    ax_rhat.legend(title=\"Sampler\")\n",
    "    ax_rhat.grid(True)\n",
    "    fig_rhat.savefig(os.path.join(global_plots_folder, \"Rhat_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_rhat)\n",
    "\n",
    "    # ===== Save Global ESS Plot =====\n",
    "    ax_ess.set_xlabel(attribute_label)\n",
    "    ax_ess.set_ylabel(\"Average ESS\")\n",
    "    ax_ess.set_title(f\"Averaged ESS ({runs} Runs,  config = {config_descr})\")\n",
    "    ax_ess.legend(title=\"Sampler\")\n",
    "    ax_ess.grid(True)\n",
    "    fig_ess.savefig(os.path.join(global_plots_folder, \"ESS_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_ess)\n",
    "\n",
    "    # ===== Save Global Time Plot =====\n",
    "    ax_time.set_xlabel(attribute_label)\n",
    "    ax_time.set_ylabel(\"Average Computation Time (seconds)\")\n",
    "    ax_time.set_title(f\"Averaged Computation Time ({runs} Runs, config = {config_descr})\")\n",
    "    ax_time.legend(title=\"Sampler\")\n",
    "    ax_time.grid(True)\n",
    "    fig_time.savefig(os.path.join(global_plots_folder, \"Time_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_immo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
