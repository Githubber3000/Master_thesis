{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pytensor.tensor as pt\n",
    "import json\n",
    "import yaml\n",
    "import logging\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import shutil \n",
    "import subprocess\n",
    "import traceback\n",
    "import time\n",
    "from datetime import datetime\n",
    "import humanize \n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "logging.getLogger(\"arviz\").setLevel(logging.CRITICAL)\n",
    "\n",
    "logger = logging.getLogger(\"pymc\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def set_logging_level(level_name):\n",
    "    level = getattr(logging, level_name.upper(), logging.INFO)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    # remove all existing handlers to avoid duplicate logs\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    handler= logging.StreamHandler(sys.stdout)\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "    handler.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "\n",
    "# Function to get the current git tag\n",
    "def get_git_tag():\n",
    "        try:\n",
    "            tag = subprocess.check_output([\"git\", \"describe\", \"--tags\"], stderr=subprocess.DEVNULL).strip().decode()\n",
    "            return tag\n",
    "        except subprocess.CalledProcessError:\n",
    "            return \"No tag found\"\n",
    "        \n",
    "\n",
    "def create_directories(*paths):\n",
    "    \"\"\"Creates multiple directories if they don't exist.\"\"\"\n",
    "    for path in paths:\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_config_file(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    group_name = data[\"group_name\"]\n",
    "    configs = data[\"configs\"]\n",
    "\n",
    "    for cfg in configs:\n",
    "         if \"varying_values\" in cfg:\n",
    "            cfg[\"varying_values\"] = [\n",
    "                tuple(v) if isinstance(v, list) else v\n",
    "                for v in cfg[\"varying_values\"]\n",
    "            ]\n",
    "\n",
    "    return group_name, configs\n",
    "\n",
    "\n",
    "def load_experiment_settings(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def load_default_values(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)[\"defaults\"]\n",
    "\n",
    "def get_experiment_paths(group_names, base_dir=\"current_exp_config/configs\"):\n",
    "    return [os.path.join(base_dir, f\"{name}.yaml\") for name in group_names]\n",
    "\n",
    "\n",
    "def apply_defaults_to_config(config, defaults):\n",
    "    for key, value in defaults.items():\n",
    "        if key not in config:\n",
    "            config[key] = value\n",
    "    return config\n",
    "\n",
    "def safe_json_dump(obj, path):\n",
    "    def convert_numpy(o):\n",
    "        if isinstance(o, np.ndarray):\n",
    "            return o.tolist()\n",
    "        elif isinstance(o, np.generic):\n",
    "            return o.item()\n",
    "        return o\n",
    "\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=4, default=convert_numpy)\n",
    "\n",
    "\n",
    "def ensure_2d(arr):\n",
    "    \"\"\"Ensures array shape is (N, d), even if 1D.\"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 1:\n",
    "        return arr[:, np.newaxis]\n",
    "    else:\n",
    "        return arr.reshape(-1, arr.shape[-1])\n",
    "    \n",
    "def get_scalar_rhat_and_ess(trace):\n",
    "    posterior_vars = [v for v in trace.posterior.data_vars if v.startswith(\"posterior\")]\n",
    "    if not posterior_vars:\n",
    "        raise ValueError(\"No posterior variables found.\")\n",
    "    return (\n",
    "        az.rhat(trace, var_names=posterior_vars).to_array().max().item(),\n",
    "        az.ess(trace, var_names=posterior_vars).to_array().min().item()\n",
    "    )\n",
    "\n",
    "def get_posterior_dim(posterior_type, params):\n",
    "    \"\"\"\n",
    "    Robustly determines the dimensionality of a posterior from its parameters.\n",
    "    \"\"\"\n",
    "    if posterior_type == \"Mixture\":\n",
    "        # Check only the first component (assuming all have same dimension)\n",
    "        comp_type = params[\"component_types\"][0]\n",
    "        comp_params = params[\"component_params\"][0]\n",
    "        return get_posterior_dim(comp_type, comp_params)\n",
    "\n",
    "    if \"mu\" in params:\n",
    "        mu = np.array(params[\"mu\"])\n",
    "        return mu.shape[0] if mu.ndim > 0 else 1\n",
    "    elif \"loc\" in params:\n",
    "        loc = np.array(params[\"loc\"])\n",
    "        return loc.shape[0] if loc.ndim > 0 else 1\n",
    "    elif posterior_type == \"Cauchy\" and \"alpha\" in params:\n",
    "        alpha = np.array(params[\"alpha\"])\n",
    "        return alpha.shape[0] if alpha.ndim > 0 else 1\n",
    "    elif posterior_type == \"Beta\":\n",
    "        a = np.array(params[\"a\"])\n",
    "        return a.shape[0] if a.ndim > 0 else 1\n",
    "    elif posterior_type == \"MvNormal\" and \"mu\" in params:\n",
    "        return len(params[\"mu\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot determine dimensionality for posterior type '{posterior_type}' with parameters: {params}\")\n",
    "\n",
    "\n",
    "def plot_and_save_all_metrics(df_results, sampler_colors, varying_attribute, varying_attribute_for_plot, csv_folder, plots_folder, run_id, config_descr):\n",
    "    \"\"\"\n",
    "    Generates and saves multiple metric plots for different samplers.\n",
    "\n",
    "    Parameters:\n",
    "    - df_results: DataFrame containing experiment results.\n",
    "    - sampler_colors: Dictionary mapping sampler names to colors.\n",
    "    - varying_attribute: The attribute that varies.\n",
    "    - varying_attribute_for_plot: The attribute used for plotting.\n",
    "    - plots_folder: Folder where plots should be saved.\n",
    "    - run_id: ID of the current run.\n",
    "    - config_descr: Description of the configuration.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define metric labels\n",
    "    metrics = [\"wasserstein_distance\" , \"swd_zscore\",\"r_hat\", \"ess\", \"runtime\"]\n",
    "\n",
    "    # Initialize plots for all metrics\n",
    "    fig_ax_pairs = {key: plt.subplots(figsize=(10, 6)) for key in metrics}\n",
    "\n",
    "    # Iterate over samplers and plot all metrics\n",
    "    for sampler in df_results[\"sampler\"].unique():\n",
    "        df_sampler = df_results[df_results[\"sampler\"] == sampler]\n",
    "        csv_filename = os.path.join(csv_folder, f\"{sampler}_results.csv\")\n",
    "        df_sampler.to_csv(csv_filename, index=False)\n",
    "\n",
    "        for metric in metrics:\n",
    "            fig, ax = fig_ax_pairs[metric]\n",
    "            ax.plot(df_sampler[varying_attribute_for_plot], df_sampler[metric], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "    # Set dynamic axis labels and save plots\n",
    "    attribute_label = varying_attribute.replace(\"_\", \" \").title()\n",
    "\n",
    "    for metric in metrics:\n",
    "        fig, ax = fig_ax_pairs[metric]\n",
    "        finalize_and_save_plot(fig,ax, attribute_label, metric, \n",
    "                               f\"{metric} for Samplers (config =_{config_descr})\",\n",
    "                               os.path.join(plots_folder, f\"{metric}_run_{run_id}.pdf\"))\n",
    "        \n",
    "\n",
    "def compute_and_save_global_metrics(df_all_runs, sampler_colors, varying_attribute, varying_values, runs, config_descr, global_results_folder, global_plots_folder, iid_ref_stats_dict):\n",
    "    \"\"\"\n",
    "    Computes and saves global metric plots (averaged across runs) for different samplers.\n",
    "\n",
    "    Parameters:\n",
    "    - df_all_runs: DataFrame containing results from all runs.\n",
    "    - sampler_colors: Dictionary mapping sampler names to colors.\n",
    "    - varying_attribute: The attribute that varies.\n",
    "    - runs: Number of experiment runs.\n",
    "    - config_descr: Configuration description.\n",
    "    - global_results_folder: Folder to save CSVs.\n",
    "    - global_plots_folder: Folder to save plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define metrics for aggregation\n",
    "    metrics = [\"wasserstein_distance\", \"mmd_rff\", \"swd_zscore\",\"r_hat\", \"ess\", \"runtime\"]\n",
    "\n",
    "    # New figure set (line + fill)\n",
    "    fig_ax_pairs_shaded = {metric: plt.subplots(figsize=(10, 6)) for metric in metrics}\n",
    "    fig_g, ax_g = plt.subplots(figsize=(10, 6))  # Glass delta for wasserstein_distance\n",
    "    fig_g_mmd, ax_g_mmd = plt.subplots(figsize=(10, 6))  # Glass delta for mmd\n",
    "\n",
    "    global_avg_dfs = {}\n",
    "\n",
    "    # Load IID reference statistics\n",
    "    iid_means_dict_swd = {}\n",
    "    iid_stds_dict_swd = {}\n",
    "    iid_means_dict_mmd = {}\n",
    "    iid_stds_dict_mmd = {}\n",
    "\n",
    "    for key in df_all_runs[varying_attribute].unique():\n",
    "        k = tuple(key) if isinstance(key, np.ndarray) else key\n",
    "        iid_entry = iid_ref_stats_dict.get(k)\n",
    "        if iid_entry is None:\n",
    "            raise KeyError(f\"Missing IID reference stats for varying attribute value: {k}\")\n",
    "        iid_means_dict_swd[k] = iid_entry[\"mean_swd\"]\n",
    "        iid_stds_dict_swd[k] = iid_entry[\"std_swd\"]\n",
    "        iid_means_dict_mmd[k] = iid_entry[\"mean_mmd\"]\n",
    "        iid_stds_dict_mmd[k] = iid_entry[\"std_mmd\"]\n",
    "\n",
    "\n",
    "    for metric in metrics:\n",
    "        fig_shaded, ax_shaded = fig_ax_pairs_shaded[metric]\n",
    "\n",
    "        # For each sampler, plot its line for this metric\n",
    "        for sampler in df_all_runs[\"sampler\"].unique():\n",
    "            df_sampler = df_all_runs[df_all_runs[\"sampler\"] == sampler]\n",
    "            color = sampler_colors.get(sampler, \"black\")\n",
    "\n",
    "            # Pivot: rows = varying_attribute, columns = run_id, values = metric\n",
    "            df_pivot = df_sampler.pivot_table(\n",
    "                index=varying_attribute, columns=\"run_id\", values=metric\n",
    "            )\n",
    "\n",
    "            if metric == \"r_hat\":\n",
    "                if (df_pivot > 1000).any().any():                    \n",
    "                    ax_shaded.annotate(\"⚠️ 'DEMetropolis' r-hat skipped due to >1000\", \n",
    "                       xy=(0.98, 0.02), xycoords='axes fraction',\n",
    "                       ha=\"right\", va=\"bottom\", fontsize=9, color=\"red\")\n",
    "                    continue\n",
    "                \n",
    "            # Compute mean and standard deviation across runs\n",
    "            means = df_pivot.mean(axis=1)\n",
    "            stds = df_pivot.std(axis=1)\n",
    "\n",
    "            # Custom ordering based on config (only if needed)\n",
    "            if isinstance(means.index[0], str): \n",
    "                custom_order = [str(t) for t in varying_values]\n",
    "                means = means.reindex(custom_order)\n",
    "                stds = stds.reindex(custom_order)\n",
    "\n",
    "        \n",
    "            # Plot mean line\n",
    "            ax_shaded.plot(means.index, means, \"o-\", label=sampler, color=color)\n",
    "\n",
    "            # Plot uncertainty: shaded std\n",
    "            if len(means.index) > 1:\n",
    "                ax_shaded.fill_between(means.index, means - stds, means + stds, color=color, alpha=0.2)\n",
    "            else:\n",
    "                ax_shaded.errorbar(means.index, means, yerr=stds, fmt=\"o\", color=color, capsize=5)\n",
    "\n",
    "            # Save global avg for CSV\n",
    "            if sampler not in global_avg_dfs:\n",
    "                global_avg_dfs[sampler] = {}\n",
    "            global_avg_dfs[sampler][metric] = (means, stds)\n",
    "\n",
    "            # Compute glass delta for wasserstein_distance only\n",
    "            if metric == \"wasserstein_distance\":\n",
    "                # Get IID mean and std for this varying attribute value\n",
    "                iid_means_swd = np.array([iid_means_dict_swd[k] for k in means.index])\n",
    "                iid_stds_swd = np.array([iid_stds_dict_swd[k] for k in means.index])\n",
    "            \n",
    "                # Avoid zero in denominator\n",
    "                iid_stds_safe = np.where(iid_stds_swd == 0, np.nan, iid_stds_swd)\n",
    "\n",
    "                # Compute glass delta\n",
    "                glass_delta = (means.values - iid_means_swd) / iid_stds_safe\n",
    "        \n",
    "                global_avg_dfs[sampler][\"ws_dist_glass_delta\"] = glass_delta\n",
    "\n",
    "                # Plot glass delta for this sampler\n",
    "                ax_g.plot(means.index, glass_delta, \"o-\", label=sampler, color=color)\n",
    "            \n",
    "            elif metric == \"mmd_rff\":\n",
    "                # Get IID mean and std for this varying attribute value\n",
    "                iid_means_mmd = np.array([iid_means_dict_mmd[k] for k in means.index])\n",
    "                iid_stds_mmd = np.array([iid_stds_dict_mmd[k] for k in means.index])\n",
    "\n",
    "                # Avoid zero in denominator\n",
    "                iid_stds_safe = np.where(iid_stds_mmd == 0, np.nan, iid_stds_mmd)\n",
    "\n",
    "                # Compute glass delta\n",
    "                glass_delta_mmd = (means.values - iid_means_mmd) / iid_stds_safe\n",
    "\n",
    "                global_avg_dfs[sampler][\"mmd_rff_glass_delta\"] = glass_delta_mmd\n",
    "\n",
    "                # Plot glass delta for this sampler\n",
    "                ax_g_mmd.plot(means.index, glass_delta_mmd, \"o-\", label=sampler, color=color)\n",
    "\n",
    "\n",
    "        # Only for wasserstein_distance: Plot IID baseline once\n",
    "        if metric == \"wasserstein_distance\":\n",
    "            \n",
    "            iid_means = np.array([iid_means_dict_swd[k] for k in means.index])\n",
    "            iid_stds = np.array([iid_stds_dict_swd[k] for k in means.index])\n",
    "\n",
    "            ax_shaded.plot(means.index, iid_means, \"o--\", label=\"IID Reference\", color=\"black\")\n",
    "            ax_shaded.fill_between(\n",
    "                means.index,\n",
    "                iid_means - iid_stds,\n",
    "                iid_means + iid_stds,\n",
    "                color=\"black\",\n",
    "                alpha=0.1,\n",
    "            )\n",
    "\n",
    "        elif metric == \"mmd_rff\":\n",
    "\n",
    "            iid_means = np.array([iid_means_dict_mmd[k] for k in means.index])\n",
    "            iid_stds = np.array([iid_stds_dict_mmd[k] for k in means.index])\n",
    "\n",
    "            ax_shaded.plot(means.index, iid_means, \"o--\", label=\"IID Reference\", color=\"black\")\n",
    "            ax_shaded.fill_between(\n",
    "                means.index,\n",
    "                iid_means - iid_stds,\n",
    "                iid_means + iid_stds,\n",
    "                color=\"black\",\n",
    "                alpha=0.1,\n",
    "            )\n",
    "\n",
    "    # Save Global Averages per Sampler to CSV\n",
    "    for sampler, metrics_dict in global_avg_dfs.items():\n",
    "        # Fill missing metrics with NaNs so CSV is complete\n",
    "        for m in metrics:\n",
    "            if m not in metrics_dict:\n",
    "                nan_series = pd.Series(np.nan, index=metrics_dict[\"wasserstein_distance\"][0].index)\n",
    "                metrics_dict[m] = (nan_series, nan_series)\n",
    "                \n",
    "        df_global_avg = pd.DataFrame({\n",
    "            varying_attribute: metrics_dict[\"wasserstein_distance\"][0].index,\n",
    "            **{f\"global_avg_{metric}\": metrics_dict[metric][0].values for metric in metrics},\n",
    "            **{f\"global_avg_{metric}_std\": metrics_dict[metric][1].values for metric in metrics},\n",
    "        })\n",
    "\n",
    "        if \"ws_dist_glass_delta\" in metrics_dict:\n",
    "            df_global_avg[\"ws_dist_glass_delta\"] = metrics_dict[\"ws_dist_glass_delta\"]\n",
    "        if \"mmd_rff_glass_delta\" in metrics_dict:\n",
    "            df_global_avg[\"mmd_rff_glass_delta\"] = metrics_dict[\"mmd_rff_glass_delta\"]\n",
    "\n",
    "        csv_filename = os.path.join(global_results_folder, f\"Global_results_{sampler}.csv\")\n",
    "        df_global_avg.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Save plots\n",
    "    attribute_label = varying_attribute.replace(\"_\", \" \").title()\n",
    "    for metric in metrics:\n",
    "      \n",
    "        fig_shaded, ax_shaded = fig_ax_pairs_shaded[metric]\n",
    "\n",
    "        finalize_and_save_plot(fig_shaded, ax_shaded, attribute_label, metric,\n",
    "                               f\"Averaged {metric.replace('_', ' ').title()} ({runs} Runs, config = {config_descr})\",\n",
    "                               os.path.join(global_plots_folder, f\"{metric}_global_plot_shaded.pdf\"))\n",
    "        \n",
    "\n",
    "    # Plot Glass's Δ for wasserstein_distance\n",
    "    finalize_and_save_plot(fig_g, ax_g, xlabel=attribute_label, ylabel=\"Glass's Δ\", title=f\"Glass's Δ for Wasserstein Distance ({runs} Runs, config = {config_descr})\",\n",
    "    save_path=os.path.join(global_plots_folder, \"glass_delta_ws_dist.pdf\"))\n",
    "\n",
    "    # Plot Glass's Δ for MMD\n",
    "    finalize_and_save_plot(fig_g_mmd, ax_g_mmd, xlabel=attribute_label, ylabel=\"Glass's Δ\", title=f\"Glass's Δ for MMD-RFF ({runs} Runs, config = {config_descr})\",save_path=os.path.join(global_plots_folder, \"glass_delta_mmd.pdf\"))\n",
    "\n",
    "\n",
    "\n",
    "def finalize_and_save_plot(fig, ax, xlabel, ylabel, title, save_path):\n",
    "    \"\"\"\n",
    "    Finalizes the plot with labels, grid, and saves it to a file.\n",
    "    \n",
    "    Parameters:\n",
    "    - fig: Matplotlib figure\n",
    "    - ax: Matplotlib axis\n",
    "    - xlabel: Label for x-axis\n",
    "    - ylabel: Label for y-axis\n",
    "    - title: Title of the plot\n",
    "    - save_path: Path to save the figure.\n",
    "    \"\"\"\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(title=\"Sampler\")\n",
    "    ax.grid(True)\n",
    "    fig.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram(samples, title, save_path=None, posterior_type=None):\n",
    "    \"\"\"\n",
    "    Plots a histogram and KDE of the given samples.\n",
    "\n",
    "    Parameters:\n",
    "    - samples: 1D or 2D array of samples.\n",
    "    - title: Title of the plot.\n",
    "    - save_path: If provided, saves the figure to this path.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if samples.ndim == 2:\n",
    "        # Handle multivariate case\n",
    "        if samples.shape[1] == 2:\n",
    "            plt.scatter(samples[:, 0], samples[:, 1], alpha=0.3, label=\"2D Samples\")\n",
    "            plt.xlabel(\"Dimension 1\")\n",
    "            plt.ylabel(\"Dimension 2\")\n",
    "            plt.title(title)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "        elif posterior_type == \"MvNormal\" and samples.shape[1] > 2:\n",
    "            logger.info(f\"Skipping plotting: Multivariate Normal with dimension {samples.shape[1]}.\")\n",
    "            return\n",
    "        \n",
    "    else:\n",
    "        # Standard 1D histogram + KDE\n",
    "        plt.hist(samples, bins=50, alpha=0.5, density=True, color='blue', edgecolor='black', label=\"Histogram\")\n",
    "        sns.kdeplot(samples, color='red', lw=2, label=\"KDE\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Sample Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def handle_trace_plots(trace, sampler_name, varying_attribute, value, save_path=None, show=False, save_individual=False):\n",
    "    \"\"\"\n",
    "    Handles both displaying and saving trace plots.\n",
    "\n",
    "    Parameters:\n",
    "    - trace: the ArviZ InferenceData object\n",
    "    - sampler_name: name of the sampler (e.g. \"HMC\")\n",
    "    - varying_attribute: the name of the varying parameter (e.g. \"mu\")\n",
    "    - value: the current value of the varying parameter\n",
    "    - save_path: path to save the full trace plot (if any)\n",
    "    - show: if True, show plot in notebook\n",
    "    - save_individual: if True and dim > 1, save individual dim plots\n",
    "    \"\"\"\n",
    "    posterior_array = trace.posterior[\"posterior\"]\n",
    "    dim = posterior_array.shape[-1] if posterior_array.ndim == 3 else 1\n",
    "\n",
    "    if posterior_array.ndim == 3 and dim > 1:\n",
    "        # Plot combined\n",
    "        fig = az.plot_trace(trace, compact=True)\n",
    "        if show:\n",
    "            plt.suptitle(f\"Trace Plot ({sampler_name}, {varying_attribute} = {value})\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "\n",
    "        # Plot per dimension\n",
    "        if save_individual or show:\n",
    "            for i in range(dim):\n",
    "                dim_i = posterior_array[..., i]\n",
    "                fig = az.plot_trace({f\"posterior_{i}\": dim_i})\n",
    "                title = f\"Trace Plot of posterior[{i}] ({sampler_name}, {varying_attribute} = {value})\"\n",
    "                if show:\n",
    "                    plt.suptitle(title)\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                if save_path and save_individual:\n",
    "                    filename = save_path.replace(\".pdf\", f\"_dim_{i}.pdf\")\n",
    "                    plt.suptitle(title)\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(filename, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "\n",
    "    else:\n",
    "        fig = az.plot_trace(trace, compact=True)\n",
    "        if show:\n",
    "            plt.suptitle(f\"Trace Plot ({sampler_name}, {varying_attribute} = {value})\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        if save_path:\n",
    "            plt.suptitle(f\"Trace Plot ({sampler_name}, {varying_attribute} = {value})\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "def extract_means_from_posterior(posterior_type, posterior_kwargs):\n",
    "    \"\"\"\n",
    "    Generalized function to extract central tendency (mean/loc) for initialization.\n",
    "    - For Mixture: returns list of all component means.\n",
    "    - For single-posteriors: returns list with one mean value or vector.\n",
    "    \"\"\"\n",
    "    if posterior_type == \"Mixture\":\n",
    "        return extract_means_from_components(posterior_type, posterior_kwargs[\"component_params\"])\n",
    "\n",
    "    elif \"mu\" in posterior_kwargs:\n",
    "        return [posterior_kwargs[\"mu\"]]\n",
    "\n",
    "    elif \"loc\" in posterior_kwargs:\n",
    "        return [posterior_kwargs[\"loc\"]]\n",
    "\n",
    "    elif posterior_type == \"Cauchy\" and \"alpha\" in posterior_kwargs:\n",
    "        return [posterior_kwargs[\"alpha\"]] \n",
    "\n",
    "    elif posterior_type == \"Beta\":\n",
    "        a = posterior_kwargs[\"a\"]\n",
    "        b = posterior_kwargs[\"b\"]\n",
    "        return [a / (a + b)]  # Expected value\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot extract central location (mu or loc) for posterior type '{posterior_type}'.\")\n",
    "\n",
    "\n",
    "def extract_means_from_components(posterior_type, component_params):\n",
    "    \"\"\"\n",
    "    Extracts central tendency (mu or loc) from each component's parameters.\n",
    "    \"\"\"\n",
    "    means = []\n",
    "    for params in component_params:\n",
    "        if \"mu\" in params:\n",
    "            means.append(params[\"mu\"])\n",
    "        elif \"loc\" in params:\n",
    "            means.append(params[\"loc\"])\n",
    "\n",
    "        elif posterior_type == \"Cauchy\" and \"alpha\" in params:\n",
    "            means.append(params[\"alpha\"])\n",
    "            \n",
    "        elif posterior_type == \"Beta\":\n",
    "            a = params[\"a\"]\n",
    "            b = params[\"b\"]\n",
    "            means.append([a / (a + b)])  # Expected value\n",
    "        else:\n",
    "            raise ValueError(\"Component missing a central tendency parameter (mu or loc).\")\n",
    "    return means\n",
    "\n",
    "\n",
    "def get_initvals(init_scheme, means, num_chains, rng=None, run_id=None, init_folder=None, value=None):\n",
    "    \"\"\"Generates initialization values based on the chosen scheme.\"\"\" \n",
    "\n",
    "    rng = rng or np.random.default_rng()\n",
    "    if np.isscalar(means[0]):\n",
    "        dim = 1\n",
    "        means_array = np.array(means)[:, None]  # shape (n_modes, 1)\n",
    "    else:\n",
    "        means_array = np.array(means)\n",
    "        dim = means_array.shape[1]\n",
    "\n",
    "\n",
    "    if init_scheme == \"thesis_scheme\":\n",
    "        # If multimodal posterior, use the means of the components, else spawn them randomly around the mean\n",
    "        if len(means_array) >= 2:\n",
    "            # Multimodal case\n",
    "            # Compute bounding box across all dimensions\n",
    "            min_mode = np.min(means_array, axis=0)\n",
    "            max_mode = np.max(means_array, axis=0)\n",
    "            border = 0.25 * (max_mode - min_mode)\n",
    "\n",
    "            low = min_mode - border\n",
    "            high = max_mode + border\n",
    "\n",
    "            initvals = [{\"posterior\": rng.uniform(low, high).item() if dim == 1 else rng.uniform(low, high)} for _ in range(num_chains)]\n",
    "\n",
    "            if run_id == 1:\n",
    "                init_info = {\n",
    "                    \"run_id\": run_id,\n",
    "                    \"case\": \"multimodal\",\n",
    "                    \"dim\": dim,\n",
    "                    \"means_array\": means_array.tolist(),\n",
    "                    \"min_mode\": min_mode,\n",
    "                    \"max_mode\": max_mode,\n",
    "                    \"border\": border,\n",
    "                    \"low\": low,\n",
    "                    \"high\": high,\n",
    "                    \"samples\": [{k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in d.items()} for d in initvals],\n",
    "                }  \n",
    "        else:\n",
    "            # Unimodal case\n",
    "            center = means_array[0]\n",
    "            center = center.item() if dim == 1 else center\n",
    "            noise = 5\n",
    "            # samples have 1D shape\n",
    "            if np.isscalar(center):\n",
    "                initvals = [{\"posterior\": center + rng.normal(scale=noise)} for _ in range(num_chains)]\n",
    "            else:\n",
    "                initvals = [{\"posterior\": center + rng.normal(scale=noise, size=center.shape)} for _ in range(num_chains)]\n",
    "\n",
    "            if run_id == 1:          \n",
    "                init_info = {\n",
    "                    \"run_id\": run_id,\n",
    "                    \"case\": \"unimodal\",\n",
    "                    \"dim\": dim,\n",
    "                    \"means_array\": means_array.tolist(),\n",
    "                    \"center\": center.tolist() if hasattr(center, \"tolist\") else center,\n",
    "                    \"noise\": noise,\n",
    "                    \"samples\": [{k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in d.items()} for d in initvals],\n",
    "                }\n",
    "\n",
    "    elif init_scheme == \"equal_per_mode\":\n",
    "        noise = 0.5\n",
    "        initvals =[]\n",
    "        for i in range(num_chains):\n",
    "            mean = means_array[i % len(means_array)]\n",
    "            center = mean + rng.normal(scale=noise)\n",
    "            if dim == 1:\n",
    "                center = center.item()\n",
    "            initvals.append({\"posterior\": center})\n",
    "\n",
    "        if run_id == 1:\n",
    "            init_info = {\n",
    "                \"run_id\": run_id,\n",
    "                \"case\": \"equal_per_mode\",\n",
    "                \"dim\": dim,\n",
    "                \"means_array\": means_array.tolist(),\n",
    "                \"samples\": [{k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in d.items()} for d in initvals],\n",
    "            }\n",
    "\n",
    "    elif init_scheme == \"all_in_middle\":\n",
    "        middle_point = np.mean(means_array, axis=0)\n",
    "        middle_point = middle_point.item() if dim == 1 else middle_point\n",
    "        noise = 0.5\n",
    "        initvals = [{\"posterior\": middle_point + rng.normal(scale=noise)} for _ in range(num_chains)]\n",
    "\n",
    "        if run_id == 1:\n",
    "            init_info = {\n",
    "                \"run_id\": run_id,\n",
    "                \"case\": \"all_in_middle\",\n",
    "                \"dim\": dim,\n",
    "                \"means_array\": means_array.tolist(),\n",
    "                \"middle_point\": middle_point.tolist() if hasattr(middle_point, \"tolist\") else middle_point,\n",
    "                \"samples\": [{k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in d.items()} for d in initvals],\n",
    "            }\n",
    "\n",
    "    elif init_scheme.startswith(\"all_near_mode_\"):\n",
    "\n",
    "        mode_index = int(init_scheme.split(\"_\")[-1])\n",
    "        if mode_index >= len(means):\n",
    "            raise IndexError(f\"Mode index {mode_index} out of bounds for available means.\")\n",
    "        \n",
    "        target_mode = means_array[mode_index]\n",
    "        target_mode = target_mode.item() if dim == 1 else target_mode\n",
    "        noise = 0.5\n",
    "        initvals = [{\"posterior\": target_mode + rng.normal(scale=noise)} for _ in range(num_chains)]\n",
    "\n",
    "        if run_id == 1:\n",
    "            init_info = {\n",
    "                \"run_id\": run_id,\n",
    "                \"case\": f\"all_near_mode{mode_index}\",\n",
    "                \"dim\": dim,\n",
    "                \"means_array\": means_array.tolist(),\n",
    "                \"mode_index\": mode_index,\n",
    "                \"samples\": [{k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in d.items()} for d in initvals],\n",
    "            }\n",
    "\n",
    "    if run_id == 1:\n",
    "        parent_folder= os.path.join(init_folder, \"chain initvals\")\n",
    "        create_directories(parent_folder)\n",
    "        chain_info_path = os.path.join(parent_folder, f\"init_{value}.json\")\n",
    "        chain_info_plot_path = os.path.join(parent_folder, f\"init_{value}.pdf\")\n",
    "        save_sample_info(sample_info=init_info, json_path=chain_info_path, plot_path=chain_info_plot_path, label=\"Init Values\")\n",
    "\n",
    "    logger.debug(f\"Generated initvals: {initvals}\")\n",
    "    return initvals\n",
    "\n",
    "\n",
    "def save_sample_info(sample_info, json_path, plot_path, label=\"Samples\", case=None):\n",
    "    \"\"\"\n",
    "    General utility to save sample info (e.g., init values, warmup samples) as JSON and plot if dim ≤ 2.\n",
    "    \n",
    "    Parameters:\n",
    "    - sample_info: dict containing\n",
    "        - \"samples\": list of dicts like [{\"posterior\": ...}, ...]\n",
    "        - \"means_array\": list of means (e.g. from init or components)\n",
    "        - \"dim\": int, dimensionality\n",
    "        - optionally: \"low\", \"high\", \"case\"\n",
    "    - json_path: path to save JSON info\n",
    "    - plot_path: path to save the plot\n",
    "    - label: label for sample points (e.g., \"Init Values\", \"Warmup Samples\")\n",
    "    - case: override case type (for optional bounding box display)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Save JSON safely ---\n",
    "    safe_json_dump(sample_info, json_path)\n",
    "\n",
    "    # --- Extract data ---\n",
    "    dim = sample_info[\"dim\"]\n",
    "    means_array = np.array(sample_info.get(\"means_array\", []))\n",
    "\n",
    "    if label == \"Init Values\":\n",
    "        samples = np.array([list(v.values())[0] for v in sample_info[\"samples\"]])\n",
    "    elif label == \"Samples\":\n",
    "        samples = np.array(sample_info[\"samples\"])\n",
    "\n",
    "    # --- Skip plotting for dim > 2 ---\n",
    "    if dim > 2:\n",
    "        return\n",
    "\n",
    "    # --- Start plot ---\n",
    "    fig, ax = plt.subplots(figsize=(8, 2) if dim == 1 else (8, 6))\n",
    "\n",
    "    # 1D case\n",
    "    if dim == 1:\n",
    "        samples_flat = samples.flatten()\n",
    "        ax.scatter(samples_flat, np.zeros_like(samples_flat), color='blue', label=label, alpha=0.7)\n",
    "        means_flat = means_array.flatten()\n",
    "        ax.scatter(means_flat, np.zeros_like(means_flat), color='red', marker='x', s=100, label='Means')\n",
    "\n",
    "        if sample_info.get(\"case\") == \"multimodal\":\n",
    "            # Handle scalar or list storage\n",
    "            low = sample_info[\"low\"]\n",
    "            high = sample_info[\"high\"]\n",
    "\n",
    "            ax.axvline(low, color=\"black\", linestyle=\"--\", label=\"Init Box\")\n",
    "            ax.axvline(high, color=\"black\", linestyle=\"--\")\n",
    "                    \n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel(\"Value\")\n",
    "\n",
    "\n",
    "    # 2D case\n",
    "    elif dim == 2:\n",
    "        ax.scatter(samples[:, 0], samples[:, 1], color='blue', label=label, alpha=0.7)\n",
    "        ax.scatter(means_array[:, 0], means_array[:, 1], color='red', marker='x', s=100, label='Means')\n",
    "\n",
    "        if sample_info.get(\"case\") == \"multimodal\":\n",
    "            low = np.array(sample_info[\"low\"])\n",
    "            high = np.array(sample_info[\"high\"])\n",
    "\n",
    "            rect = plt.Rectangle(low, *(high - low), linewidth=1, edgecolor='black',\n",
    "                                 facecolor='none', linestyle='--', label='Init Box')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        ax.set_xlabel(\"Dim 1\")\n",
    "        ax.set_ylabel(\"Dim 2\")\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "    # --- Finalize ---\n",
    "    if label == \"Init Values\":\n",
    "        ax.set_title(f\"{label} and Means\")\n",
    "    elif label == \"Samples\":\n",
    "        sampler = sample_info.get(\"sampler\", \"Unknown\")\n",
    "        case = sample_info.get(\"case\", \"Unknown\")\n",
    "        ax.set_title(f\"First {case} from {sampler}\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    if dim == 1:\n",
    "        ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "        fig.subplots_adjust(right=0.75)  \n",
    "    else:\n",
    "        ax.legend()  \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def sliced_wasserstein_distance(X, Y, L=100):\n",
    "    \"\"\"\n",
    "    Computes the sliced Wasserstein distance (SWD_p) between two sets of samples.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: numpy array of shape (N, d) -> first sample set\n",
    "    - Y: numpy array of shape (N, d) -> second sample set\n",
    "    - L: int, number of random projections\n",
    "    - p: int, order of Wasserstein distance (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "    - SWD_p: float, the sliced Wasserstein distance\n",
    "    \"\"\"\n",
    "\n",
    "    N, d = X.shape  # Assuming X and Y have the same shape\n",
    "    S = 0  # Accumulation variable\n",
    "\n",
    "    for _ in range(L):\n",
    "        # Sample a random unit vector (projection direction)\n",
    "        theta = np.random.randn(d)\n",
    "        theta /= np.linalg.norm(theta)  # Normalize to unit sphere\n",
    "\n",
    "        # Compute projections\n",
    "        alpha = X @ theta\n",
    "        beta = Y @ theta\n",
    "\n",
    "        # Compute 1D Wasserstein distance\n",
    "        W_i = sp.wasserstein_distance(alpha, beta)\n",
    "\n",
    "        # Accumulate\n",
    "        S += W_i\n",
    "\n",
    "    # Compute final SWD\n",
    "    SWD_p = (S / L) \n",
    "\n",
    "    return SWD_p\n",
    "\n",
    "def compute_mmd_rff(X, Y, D=500, sigma=1.0, seed=None):\n",
    "    \"\"\"\n",
    "    Computes the approximate Maximum Mean Discrepancy (MMD) using Random Fourier Features (RFF)\n",
    "    between two sample sets X and Y.\n",
    "\n",
    "    Parameters:\n",
    "    - X: np.ndarray of shape (n, d) – sample set from distribution p(x)\n",
    "    - Y: np.ndarray of shape (m, d) – sample set from distribution q(x)\n",
    "    - D: int – number of random Fourier features\n",
    "    - sigma: float – bandwidth of the Gaussian kernel\n",
    "    - seed: int or None – random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - mmd_rff: float – approximate MMD value\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    n, d = X.shape\n",
    "    m, _ = Y.shape\n",
    "\n",
    "    # Step 1: Generate random frequencies and offsets\n",
    "    omega = rng.normal(loc=0.0, scale=1.0 / sigma, size=(D, d))\n",
    "    b = rng.uniform(0, 2 * np.pi, size=D)\n",
    "\n",
    "    # Step 2: Compute random Fourier features\n",
    "    def z(x):\n",
    "        projection = np.dot(x, omega.T) + b\n",
    "        return np.sqrt(2.0 / D) * np.cos(projection)\n",
    "\n",
    "    Z_X = z(X)  # shape (n, D)\n",
    "    Z_Y = z(Y)  # shape (m, D)\n",
    "\n",
    "    # Step 3: Calculate mean embeddings\n",
    "    mu_p = Z_X.mean(axis=0)\n",
    "    mu_q = Z_Y.mean(axis=0)\n",
    "\n",
    "    # Step 4: Calculate MMD^2 (Euclidean distance between embeddings)\n",
    "    mmd_rff = np.linalg.norm(mu_p - mu_q)\n",
    "\n",
    "    return mmd_rff\n",
    "\n",
    "\n",
    "def generate_iid_samples(posterior_type = None, num_samples=2000, rng=None,**params):\n",
    "    \"\"\"\n",
    "    Generate IID samples from a mixture distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "    - component_params: List of dictionaries with parameters for each component.\n",
    "    - num_samples: Number of samples to generate.\n",
    "    - weights: List of weights for the components.\n",
    "    - rng: Random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - iid_samples: Array of generated IID samples.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = rng or np.random.default_rng()\n",
    "\n",
    "    # Mapping from string names to scipy sampling functions\n",
    "    scipy_distributions = {\n",
    "        \"Normal\": lambda p: sp.norm.rvs(loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"StudentT\": lambda p: sp.t.rvs(df=p[\"nu\"], loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"Beta\": lambda p: sp.beta.rvs(a=p[\"a\"], b=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"Cauchy\": lambda p: sp.cauchy.rvs(loc=p[\"alpha\"], scale=p[\"beta\"], size=num_samples, random_state=rng),\n",
    "        \"Laplace\": lambda p: sp.laplace.rvs(loc=p[\"mu\"], scale=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"MvNormal\": lambda p: rng.multivariate_normal(mean=np.array(p[\"mu\"]), cov=np.array(p[\"cov\"]), size=num_samples),\n",
    "    }\n",
    "\n",
    "    # Handle Skewed Student-T (which needs PyMC)\n",
    "    if posterior_type == \"SkewStudentT\":\n",
    "        with pm.Model():\n",
    "            skewed_t = pm.SkewStudentT.dist(a=params[\"a\"], b=params[\"b\"], mu=params[\"mu\"], sigma=params[\"sigma\"])\n",
    "            return pm.draw(skewed_t, draws=num_samples, random_seed=rng)\n",
    "\n",
    "    # Handle single distributions\n",
    "    if posterior_type in scipy_distributions:\n",
    "        logger.debug(f\"Generating {posterior_type} samples with parameters: {params}\")\n",
    "        return scipy_distributions[posterior_type](params)\n",
    "\n",
    "    elif posterior_type == \"Mixture\":\n",
    "        component_types = params[\"component_types\"]\n",
    "        component_params = params[\"component_params\"]\n",
    "        weights = params[\"weights\"]\n",
    "\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        # normalize weights\n",
    "        weights = np.array(weights) / np.sum(weights)\n",
    "\n",
    "        # Choose which component each sample belongs to based on weights\n",
    "        chosen_components = rng.choice(len(component_types), size=num_samples, p=weights)\n",
    "\n",
    "        posterior_dim = get_posterior_dim(\"Mixture\", {\n",
    "            \"component_types\": component_types,\n",
    "            \"component_params\": component_params,\n",
    "            \"weights\": weights\n",
    "        })\n",
    "\n",
    "\n",
    "        if posterior_dim > 1:\n",
    "            iid_samples = np.empty((num_samples, posterior_dim))  # Multivariate case\n",
    "        else:\n",
    "            iid_samples = np.empty(num_samples)\n",
    "\n",
    "        for i, (comp_type, comp_params) in enumerate(zip(component_types, component_params)):\n",
    "            mask = chosen_components == i  # Select samples for this component\n",
    "            num_selected = mask.sum()\n",
    "            if num_selected > 0:\n",
    "                if comp_type in scipy_distributions or comp_type == \"SkewStudentT\":\n",
    "                    iid_samples[mask] = generate_iid_samples(posterior_type=comp_type, num_samples=num_selected, rng=rng, **comp_params)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported component type in IID sampling: {comp_type}\")\n",
    "                \n",
    "        return iid_samples\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported posterior type: {posterior_type}\")\n",
    "\n",
    "\n",
    "def generate_all_iid_batches(\n",
    "    posterior_type,\n",
    "    posterior_kwargs,\n",
    "    iid_kwargs,\n",
    "    varying_attribute,\n",
    "    varying_values,\n",
    "    num_total_iid_batches,\n",
    "    num_iid_vs_iid_batches,\n",
    "    num_samples,\n",
    "    rng=None,\n",
    "    group_folder=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates all IID batches for the given posterior type and varying attribute.\n",
    "\n",
    "    Parameters:\n",
    "    - posterior_type: Type of the posterior (e.g., \"Mixture\", \"Normal\").\n",
    "    - posterior_kwargs: Dictionary of parameters for the posterior.\n",
    "    - varying_attribute: The attribute that varies (e.g., \"mu\", \"sigma\").\n",
    "    - varying_values: List of values for the varying attribute.\n",
    "    - num_total_iid_batches: Total number of IID batches to generate.\n",
    "    - num_iid_vs_iid_batches: Number of IID vs IID batches.\n",
    "    - num_samples: Number of samples per batch.\n",
    "    \n",
    "    Returns:\n",
    "    - iid_batches_dict: Dictionary of generated IID batches.\n",
    "    - iid_ref_stats_dict: Dictionary of reference statistics for SWD and MMD.\n",
    "    \"\"\"\n",
    "    \n",
    "    iid_histogram_folder = os.path.join(group_folder, \"KDE and Histograms of IID Samples\")\n",
    "    create_directories(iid_histogram_folder)\n",
    "\n",
    "    # === Handle Precomputed IID Samples for Varying Attributes ===\n",
    "    # Dictionary to store generated IID batches\n",
    "    iid_batches_dict = {}\n",
    "    # Dictionary to store reference SWD statistics\n",
    "    iid_ref_stats_dict = {}\n",
    "\n",
    "    if posterior_type == \"Mixture\":\n",
    "        component_index = posterior_kwargs.get(\"varying_component\")  # Get the selected component\n",
    "\n",
    "        # Loop through all varying values for Mixture posterior\n",
    "        for value in varying_values:\n",
    "\n",
    "            iid_kwargs[\"component_params\"][component_index][varying_attribute] = value\n",
    "            logger.debug(f\"Updating component {component_index} with {varying_attribute} = {value}\")\n",
    "\n",
    "            iid_batches = [generate_iid_samples(\n",
    "                posterior_type=posterior_type,\n",
    "                component_types=iid_kwargs[\"component_types\"],\n",
    "                component_params=iid_kwargs[\"component_params\"], \n",
    "                weights=iid_kwargs[\"weights\"],\n",
    "                num_samples= num_samples,\n",
    "                rng=rng\n",
    "            ) for _ in range(num_total_iid_batches)]\n",
    "\n",
    "            iid_batches_dict[value] = iid_batches\n",
    "\n",
    "            ref_swd_values = []\n",
    "            ref_mmd_values = []\n",
    "\n",
    "            for i in range(0, num_iid_vs_iid_batches, 2):  # 0–1, 2–3, 4–5, ...\n",
    "                x = ensure_2d(iid_batches[i])\n",
    "                y = ensure_2d(iid_batches[i+1])\n",
    "                swd = sliced_wasserstein_distance(x, y)\n",
    "                mmd_rff = compute_mmd_rff(x, y, D=500, sigma=1.0, seed=None)\n",
    "                ref_mmd_values.append(mmd_rff)\n",
    "                ref_swd_values.append(swd)\n",
    "\n",
    "            mean_ref_swd = np.mean(ref_swd_values)\n",
    "            std_ref_swd = np.std(ref_swd_values, ddof=1)\n",
    "\n",
    "            mean_ref_mmd = np.mean(ref_mmd_values)\n",
    "            std_ref_mmd = np.std(ref_mmd_values, ddof=1)\n",
    "\n",
    "            # Speichern\n",
    "            iid_ref_stats_dict[value] = {\"mean_swd\": mean_ref_swd, \"std_swd\": std_ref_swd, \"mean_mmd\": mean_ref_mmd, \"std_mmd\": std_ref_mmd}\n",
    "\n",
    "            # Plot histogram and KDE for each varying value\n",
    "            plot_histogram(\n",
    "                samples=iid_batches_dict[value][0],\n",
    "                title=f\"IID Samples Histogram & KDE ({varying_attribute}={value})\",\n",
    "                save_path=os.path.join(iid_histogram_folder, f\"iid_hist_kde_{varying_attribute}_{value}.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "            )\n",
    "        \n",
    "    # Single posterior case\n",
    "    elif varying_attribute in iid_kwargs or varying_attribute == \"num_samples\":\n",
    "        for value in varying_values:\n",
    "            if varying_attribute == \"num_samples\":\n",
    "                current_num_samples = value  \n",
    "            else:\n",
    "                iid_kwargs[varying_attribute] = value  \n",
    "                current_num_samples = num_samples      \n",
    "            \n",
    "            iid_batches = [generate_iid_samples(    \n",
    "                posterior_type=posterior_type,\n",
    "                **iid_kwargs,\n",
    "                num_samples= num_samples,\n",
    "                rng=rng) for _ in range(num_total_iid_batches)]\n",
    "\n",
    "            iid_batches_dict[value] = iid_batches\n",
    "\n",
    "            ref_swd_values = []\n",
    "            ref_mmd_values = []\n",
    "            for i in range(0, num_iid_vs_iid_batches, 2):  # 0–1, 2–3, 4–5, ...\n",
    "                x = ensure_2d(iid_batches[i])\n",
    "                y = ensure_2d(iid_batches[i+1])\n",
    "                swd = sliced_wasserstein_distance(x, y)\n",
    "                mmd_rff = compute_mmd_rff(x, y, D=500, sigma=1.0, seed=None)\n",
    "                ref_swd_values.append(swd)\n",
    "                ref_mmd_values.append(mmd_rff)\n",
    "\n",
    "            mean_ref_swd = np.mean(ref_swd_values)\n",
    "            std_ref_swd = np.std(ref_swd_values, ddof=1)\n",
    "\n",
    "            mean_ref_mmd = np.mean(ref_mmd_values)\n",
    "            std_ref_mmd = np.std(ref_mmd_values, ddof=1)\n",
    "\n",
    "            # Speichern\n",
    "            iid_ref_stats_dict[value] = {\"mean_swd\": mean_ref_swd, \"std_swd\": std_ref_swd, \"mean_mmd\": mean_ref_mmd, \"std_mmd\": std_ref_mmd}\n",
    "\n",
    "            # Plot histogram and KDE for each varying value\n",
    "            plot_histogram(\n",
    "                samples=iid_batches_dict[value][0],\n",
    "                title=f\"IID Samples Histogram & KDE ({varying_attribute}={value})\",\n",
    "                save_path=os.path.join(iid_histogram_folder, f\"iid_hist_kde_{varying_attribute}_{value}.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "            )\n",
    "\n",
    "    # Fixed posterior case (no varying attribute in posterior_kwargs)\n",
    "    else:\n",
    "        iid_batches = [generate_iid_samples(\n",
    "            posterior_type=posterior_type,\n",
    "            **iid_kwargs,\n",
    "            num_samples=num_samples,\n",
    "            rng=rng\n",
    "        ) for _ in range(num_total_iid_batches)]\n",
    "\n",
    "\n",
    "        ref_swd_values = []\n",
    "        ref_mmd_values = []\n",
    "        for i in range(0, num_iid_vs_iid_batches, 2):  # 0–1, 2–3, ...\n",
    "            swd = sliced_wasserstein_distance(iid_batches[i], iid_batches[i+1])\n",
    "            mmd_rff = compute_mmd_rff(iid_batches[i], iid_batches[i+1], D=500, sigma=1.0, seed=None)\n",
    "            ref_swd_values.append(swd)\n",
    "            ref_mmd_values.append(mmd_rff)\n",
    "\n",
    "        mean_ref_swd = np.mean(ref_swd_values)\n",
    "        std_ref_swd = np.std(ref_swd_values, ddof=1)\n",
    "\n",
    "        mean_ref_mmd = np.mean(ref_mmd_values)\n",
    "        std_ref_mmd = np.std(ref_mmd_values, ddof=1)\n",
    "\n",
    "        iid_ref_stats_dict[\"fixed\"] = {\"mean\": mean_ref_swd, \"std\": std_ref_swd, \"mean_mmd\": mean_ref_mmd, \"std_mmd\": std_ref_mmd}\n",
    "\n",
    "        plot_histogram(\n",
    "            samples=iid_batches[0],\n",
    "            title=\"IID Samples Histogram & KDE (fixed posterior)\",\n",
    "            save_path=os.path.join(iid_histogram_folder, \"iid_hist_kde.pdf\"),\n",
    "            posterior_type=posterior_type\n",
    "        )\n",
    "    \n",
    "    return iid_batches_dict, iid_ref_stats_dict\n",
    "\n",
    "\n",
    "class PosteriorExample:\n",
    "    \"\"\"Base class for different posterior types.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None  # Placeholder for the PyMC model\n",
    "    \n",
    "    def _define_posterior(self):\n",
    "        \"\"\"Subclasses should implement this method to define the posterior.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement _define_posterior()\")\n",
    "\n",
    "    def run_sampling(self, sampler_name, num_samples=2000, tune=1000, num_chains=2, initvals=None,run_id=None, plot_first_sample=None, init_folder=None, value=None, means=None, run_random_seed=None):\n",
    "        \"\"\"Runs MCMC sampling using the chosen sampler.\"\"\"\n",
    "\n",
    "        with self.model:\n",
    "\n",
    "            if sampler_name == \"SMC\":\n",
    "                trace = pm.sample_smc(num_samples, chains=num_chains, progressbar=False, random_seed=run_random_seed)\n",
    "            else:\n",
    "                \n",
    "                # Define which sampler to use\n",
    "                if sampler_name == \"Metro\":\n",
    "                    sampler = pm.Metropolis()\n",
    "                elif sampler_name == \"HMC\":\n",
    "                    sampler = pm.NUTS()\n",
    "                elif sampler_name == \"DEMetro\":\n",
    "                    sampler = pm.DEMetropolis()\n",
    "                elif sampler_name == \"DEMetro_Z\":\n",
    "                    sampler = pm.DEMetropolisZ()\n",
    "                elif sampler_name == \"Slice\":\n",
    "                    sampler = pm.Slice()\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown sampler: {sampler_name}\")\n",
    "\n",
    "                if run_id == 1:\n",
    "                    discard_tuned_samples = False\n",
    "                else:\n",
    "                    discard_tuned_samples = True\n",
    "\n",
    "                if initvals != None:\n",
    "                    trace = pm.sample(num_samples, tune=tune, step=sampler,initvals=initvals, chains=num_chains, return_inferencedata=True, discard_tuned_samples=discard_tuned_samples, progressbar=False, random_seed=run_random_seed)   \n",
    "                else:\n",
    "                    print(\"workeeed\")\n",
    "                    trace = pm.sample(num_samples, tune=tune, step=sampler, chains=num_chains, return_inferencedata=True, discard_tuned_samples=discard_tuned_samples, progressbar=False, random_seed=run_random_seed)\n",
    "\n",
    "                if run_id == 1 and plot_first_sample:\n",
    "                    first_warmup_samples = trace.warmup_posterior[\"posterior\"].isel(draw=0).values\n",
    "                    dim = first_warmup_samples.shape[1] if first_warmup_samples.ndim > 1 else 1\n",
    "\n",
    "                    warmup_info = {\n",
    "                        \"sampler\": sampler_name,\n",
    "                        \"value\": value,\n",
    "                        \"means_array\": means,\n",
    "                        \"case\": \"Warmup Samples\",\n",
    "                        \"dim\": dim,\n",
    "                        \"samples\": first_warmup_samples.tolist(),\n",
    "                    }\n",
    "\n",
    "                    # Define file paths\n",
    "                    parent_folder = os.path.join(init_folder, f\"{sampler_name}\")\n",
    "                    create_directories(parent_folder)\n",
    "                    warmup_base = os.path.join(parent_folder, \"first warum up samples\")\n",
    "                    warmup_json_path = f\"{warmup_base}.json\"\n",
    "                    warmup_plot_path = f\"{warmup_base}.pdf\"\n",
    "\n",
    "                    save_sample_info(sample_info=warmup_info, json_path=warmup_json_path, plot_path=warmup_plot_path, label=\"Samples\")\n",
    "\n",
    "                    # also plot first posterior sample\n",
    "                    first_posterior_samples = trace.posterior[\"posterior\"].isel(draw=0).values\n",
    "                    posterior_info = {\n",
    "                        \"sampler\": sampler_name,\n",
    "                        \"value\": value,\n",
    "                        \"means_array\": means,\n",
    "                        \"case\": \"Posterior Samples\",\n",
    "                        \"dim\": dim,\n",
    "                        \"samples\": first_posterior_samples.tolist(),\n",
    "                    }\n",
    "                    # Define file paths\n",
    "              \n",
    "                    posterior_base = os.path.join(parent_folder, \"first posterior samples\")\n",
    "                    posterior_json_path = f\"{posterior_base}.json\"\n",
    "                    posterior_plot_path = f\"{posterior_base}.pdf\"\n",
    "                    save_sample_info(sample_info=posterior_info, json_path=posterior_json_path, plot_path=posterior_plot_path, label=\"Samples\")\n",
    "                    \n",
    "        return trace\n",
    "\n",
    "\n",
    "class SinglePosterior(PosteriorExample):\n",
    "    def __init__(self, dist_name, dist_params):\n",
    "        \"\"\"\n",
    "        A flexible class for defining unimodal posteriors.\n",
    "\n",
    "        Parameters:\n",
    "        - dist_name: String specifying the name of the PyMC distribution (e.g., \"Normal\", \"StudentT\").\n",
    "        - dist_params: Dictionary containing the parameters for the distribution.\n",
    "        \"\"\"\n",
    "        self.dist_name = dist_name\n",
    "        self.dist_params = dist_params\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        \n",
    "        dist_class = getattr(pm, self.dist_name)   # Retrieve the distribution class from PyMC\n",
    "        dim = get_posterior_dim(self.dist_name, self.dist_params)\n",
    "        shape = (dim,) if dim > 1 else ()\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            dist_class(\"posterior\", **self.dist_params, shape=shape) \n",
    "        return model\n",
    "\n",
    "\n",
    "class MixturePosterior(PosteriorExample):\n",
    "    \n",
    "    def __init__(self, component_types, component_params, weights=None, varying_component=None): \n",
    "        \"\"\"\n",
    "        A flexible mixture posterior allowing any number of components and arbitrary distributions.\n",
    "\n",
    "        Parameters:\n",
    "        - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "        - component_params: List of dictionaries, where each dictionary contains the parameters for the corresponding distribution.\n",
    "        - weights: List of weights for the mixture components (defaults to uniform).\n",
    "        \"\"\"\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(component_types))  # Default: Equal weights\n",
    "\n",
    "        if len(weights) != len(component_types):\n",
    "            raise ValueError(\"Number of weights must match number of components.\")\n",
    "\n",
    "        self.component_types = component_types\n",
    "        self.component_params = component_params\n",
    "        self.weights = weights\n",
    "\n",
    "        # Normalize weights\n",
    "        self.weights = np.array(self.weights) / np.sum(self.weights)\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "\n",
    "    def _define_posterior(self):\n",
    "\n",
    "        first_type = self.component_types[0]\n",
    "        first_params = self.component_params[0]\n",
    "\n",
    "        dim = get_posterior_dim(first_type, first_params)\n",
    "        shape = (dim,) if dim > 1 else ()\n",
    "        \n",
    "        # Construct component distributions dynamically\n",
    "        components = []\n",
    "        for dist_type, params in zip(self.component_types, self.component_params):\n",
    "                dist_class = getattr(pm, dist_type)  \n",
    "                components.append(dist_class.dist(**params))  \n",
    "  \n",
    "        # Define the mixture model    \n",
    "        with pm.Model() as model:\n",
    "            # Mixture model\n",
    "            pm.Mixture(\"posterior\", w=self.weights, comp_dists=components, shape=shape) \n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "class CustomPosterior(PosteriorExample):\n",
    "    \"\"\"\n",
    "    A flexible class to define custom posteriors using a user-specified log-probability function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logp_func):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - logp_func: Callable function that defines the log-probability.\n",
    "                     Must accept PyMC symbolic variables.\n",
    "        - param_names: List of parameter names required by logp_func.\n",
    "        - initvals: Optional dictionary for initial values.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.logp_func = logp_func\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        with pm.Model() as model:\n",
    "\n",
    "            # Define the custom distribution using pm.CustomDist\n",
    "            pm.CustomDist(\"posterior\", logp=self.logp_func)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    results_folder,\n",
    "    experiment_settings,\n",
    "    posterior_type,\n",
    "    config_descr,\n",
    "    runs,\n",
    "    varying_attribute, \n",
    "    varying_values,      \n",
    "    num_samples,\n",
    "    num_chains,\n",
    "    init_scheme=None,\n",
    "    base_random_seed=None,\n",
    "    progress_bar=None,\n",
    "    group_name=\"default\",\n",
    "    **posterior_kwargs\n",
    "):\n",
    "    \n",
    "    set_logging_level(experiment_settings.get(\"logging_level\", \"INFO\"))\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    logger.info(f\"===== Config {config_descr} started! =====\")\n",
    "\n",
    "    # Initialize random number generator\n",
    "    rng = np.random.default_rng(base_random_seed)\n",
    "\n",
    "    # Samples\n",
    "    samples_per_chain = \"varies\" if varying_attribute in [\"num_samples\", \"num_chains\"] else num_samples // num_chains\n",
    "    # Adjust total to match per-chain sample count\n",
    "    num_samples = samples_per_chain*num_chains\n",
    "\n",
    "    # Number of IID bacthes for the IID vs IID comparison\n",
    "    num_iid_vs_iid_batches = 2*runs\n",
    "    num_mcmc_batches = runs\n",
    "    # Total number of iid batches (needs a fresh iid batch for each mcmc run)\n",
    "    num_total_iid_batches = num_iid_vs_iid_batches + num_mcmc_batches\n",
    "\n",
    "    # Define required parameters for each posterior type\n",
    "    required_parameters = {\n",
    "        \"Mixture\": [\"component_types\", \"component_params\", \"weights\"],\n",
    "        \"Cauchy\": [\"alpha\", \"beta\"],\n",
    "        \"Beta\": [\"a\", \"b\"],\n",
    "        \"Normal\": [\"mu\", \"sigma\"],\n",
    "        \"StudentT\": [\"nu\", \"mu\", \"sigma\"],\n",
    "        \"SkewStudentT\": [\"a\", \"b\", \"mu\", \"sigma\"],\n",
    "        \"Laplace\": [\"mu\", \"b\"],\n",
    "        \"MvNormal\": [\"mu\", \"cov\"],\n",
    "        \"Custom\": []\n",
    "    }\n",
    "\n",
    "    # Validate that required keys exist (except for varying attributes)\n",
    "    required_keys = [k for k in required_parameters.get(posterior_type) if k != varying_attribute]\n",
    "    if not all(k in posterior_kwargs for k in required_keys):\n",
    "        raise ValueError(f\"{posterior_type} posterior requires {required_keys}\")\n",
    "\n",
    "    # Create keyword arguments for IID sample generation\n",
    "    iid_kwargs = {key: posterior_kwargs.get(key, \"varies\") for key in required_parameters.get(posterior_type)}\n",
    "\n",
    "    logger.debug(f\"Using IID sample settings: {iid_kwargs}\")\n",
    "\n",
    "    # Create configuration and histogram folders inside the experiment root\n",
    "    group_folder = os.path.join(results_folder, group_name, config_descr)\n",
    "    #config_folder = os.path.join(group_folder, f\"{config_descr}_with_{runs}_runs\")\n",
    "    init_folder = os.path.join(group_folder, f\"init_info\")\n",
    "    create_directories(group_folder, init_folder)\n",
    "\n",
    "\n",
    "    if posterior_type != \"Custom\":\n",
    "        iid_batches_dict, iid_ref_stats_dict = generate_all_iid_batches(\n",
    "            posterior_type=posterior_type,\n",
    "            posterior_kwargs=posterior_kwargs,\n",
    "            iid_kwargs=iid_kwargs,\n",
    "            varying_attribute=varying_attribute,\n",
    "            varying_values=varying_values,\n",
    "            num_total_iid_batches=num_total_iid_batches,\n",
    "            num_iid_vs_iid_batches=num_iid_vs_iid_batches,\n",
    "            num_samples=num_samples,\n",
    "            rng=rng,\n",
    "            group_folder=group_folder\n",
    "        )       \n",
    "\n",
    "    experiment_metadata = {\n",
    "        \"config_descr\": config_descr,\n",
    "        \"runs\": runs,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"num_chains\": num_chains,\n",
    "        \"posterior_type\": posterior_type,\n",
    "        \"varying_attribute\": varying_attribute,\n",
    "        \"varying_values\": varying_values,\n",
    "        \"init_scheme\": init_scheme,\n",
    "        \"base_random_seed\": base_random_seed,\n",
    "        \"git_tag\": get_git_tag(),\n",
    "    }\n",
    "    experiment_metadata.update(iid_kwargs)  # Add posterior-specific parameters\n",
    "\n",
    "    # Save metadata\n",
    "    metadata_filename = os.path.join(group_folder, f\"metadata_config_{config_descr}.json\")\n",
    "    safe_json_dump(experiment_metadata, metadata_filename)\n",
    "\n",
    "    # Define fixed colors for each sampler\n",
    "    sampler_colors = {\n",
    "        \"Metro\": \"blue\",\n",
    "        \"HMC\": \"red\",\n",
    "        \"DEMetro\": \"green\",\n",
    "        \"Slice\": \"orange\",\n",
    "    }\n",
    "\n",
    "    plot_first_sample = experiment_settings.get(\"plot_first_sample\", False)\n",
    "\n",
    "    df_all_runs = []\n",
    "\n",
    "    # === Run the Experiment ===\n",
    "    for run_id in range(1, runs + 1):\n",
    "        logger.info(f\"Running {config_descr} - Run {run_id}\")\n",
    "\n",
    "        run_random_seed = int(rng.integers(1_000_000))\n",
    "\n",
    "        run_folder = os.path.join(group_folder, f\"run_{run_id}\")\n",
    "        csv_folder = os.path.join(run_folder, \"results\")\n",
    "        traces_folder = os.path.join(run_folder, \"traces_and_trace_plots\")\n",
    "        plots_folder = os.path.join(run_folder, \"plots_of_run\")\n",
    "        \n",
    "        create_directories(run_folder, csv_folder, traces_folder, plots_folder)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for value in varying_values:\n",
    "\n",
    "            var_attr_folder = os.path.join(traces_folder, f\"{varying_attribute}_{value}\")\n",
    "            create_directories(var_attr_folder)\n",
    "\n",
    "            if run_id == 1:\n",
    "                # create subfolder for value in init folder\n",
    "                init_value_folder = os.path.join(init_folder, f\"{varying_attribute}_{value}\")\n",
    "                create_directories(init_value_folder)\n",
    "\n",
    "            # Handle parameter changes for Mixture case\n",
    "            if posterior_type == \"Mixture\":\n",
    "                component_index = posterior_kwargs.get(\"varying_component\")\n",
    "                if component_index is None and varying_attribute not in [\"num_samples\", \"num_chains\", \"init_scheme\"]:\n",
    "                    raise ValueError(f\"`varying_component` must be specified when varying '{varying_attribute}' in a Mixture.\")\n",
    "\n",
    "                # Modify only the selected component\n",
    "                posterior_kwargs[\"component_params\"][component_index][varying_attribute] = value\n",
    "            \n",
    "            else:\n",
    "                if varying_attribute in iid_kwargs:\n",
    "                    posterior_kwargs[varying_attribute] = value\n",
    "            \n",
    "            if varying_attribute == \"num_samples\":\n",
    "                num_samples = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"num_chains\":\n",
    "                num_chains = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"init_scheme\":\n",
    "                init_scheme = value\n",
    "\n",
    "            if posterior_type == \"Mixture\":\n",
    "                model = MixturePosterior(**posterior_kwargs)\n",
    "            elif posterior_type == \"Custom\":\n",
    "                logp_func = posterior_kwargs[\"logp_func\"]\n",
    "                model = CustomPosterior(logp_func=logp_func)\n",
    "            else:\n",
    "                model = SinglePosterior(dist_name=posterior_type, dist_params=posterior_kwargs)\n",
    "\n",
    "            means = None\n",
    "            initvals = None\n",
    "            \n",
    "            if init_scheme is not None:\n",
    "                    means = extract_means_from_posterior(posterior_type, posterior_kwargs)\n",
    "                    initvals = get_initvals(init_scheme, means, num_chains, rng, run_id, init_value_folder, value)\n",
    "        \n",
    "            # Get IID samples for the current varying value\n",
    "            if posterior_type != \"Custom\" and varying_attribute not in [\"init_scheme\", \"num_chains\"]:\n",
    "                iid_batches = iid_batches_dict[value]\n",
    "            elif posterior_type == \"Custom\":\n",
    "                iid_batches = None\n",
    "\n",
    "            # Run sampling for all samplers\n",
    "            for sampler_name in experiment_settings[\"samplers\"]:\n",
    "                \n",
    "                if posterior_type == \"Mixture\":\n",
    "                    logger.info(f\"Running {sampler_name} with {varying_attribute} = {value} (Component {component_index})\")\n",
    "                else:\n",
    "                    logger.info(f\"Running {sampler_name} with {varying_attribute} = {value}\")\n",
    "\n",
    "                # **Measure Computation Time**\n",
    "                start_time = time.time()\n",
    "                trace = model.run_sampling(\n",
    "                    sampler_name, num_samples=samples_per_chain, num_chains=num_chains,\n",
    "                    initvals = initvals, run_id=run_id, plot_first_sample=plot_first_sample, init_folder= init_value_folder, value=value, means=means, run_random_seed=run_random_seed)\n",
    "                end_time = time.time()\n",
    "                runtime = end_time - start_time\n",
    "                \n",
    "                # Plot trace plots in notebook if requested\n",
    "                if experiment_settings.get(\"plot_traces_in_notebook\", False):\n",
    "                    handle_trace_plots(\n",
    "                        trace=trace,\n",
    "                        sampler_name=sampler_name,\n",
    "                        varying_attribute=varying_attribute,\n",
    "                        value=value,\n",
    "                        show=True,\n",
    "                        save_path=None,\n",
    "                        save_individual=False,\n",
    "                    )\n",
    "\n",
    "                trace_plot_mode = experiment_settings.get(\"trace_plots\", \"none\")\n",
    "\n",
    "                # Save trace plots to PDF if requested\n",
    "                if trace_plot_mode == \"all\" or (trace_plot_mode == \"first_run_only\" and run_id == 1):\n",
    "                    handle_trace_plots(\n",
    "                        trace=trace,\n",
    "                        sampler_name=sampler_name,\n",
    "                        varying_attribute=varying_attribute,\n",
    "                        value=value,\n",
    "                        show=False,\n",
    "                        save_path= os.path.join(var_attr_folder, f\"{sampler_name}_trace_plot.pdf\"),\n",
    "                        save_individual=experiment_settings.get(\"save_individual_traceplots_per_dim\", False),\n",
    "                    )\n",
    "                \n",
    "                # Save trace to NetCDF file if requested\n",
    "                if experiment_settings.get(\"save_traces\", False):\n",
    "                    trace_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace.nc\")\n",
    "                    az.to_netcdf(trace, trace_filename)\n",
    "\n",
    "\n",
    "                posterior_samples = trace.posterior[\"posterior\"].values\n",
    "\n",
    "                # Ensure posterior_samples always has shape (N, dims)\n",
    "                if posterior_samples.ndim == 2:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, 1) \n",
    "                else:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, posterior_samples.shape[-1])\n",
    "\n",
    "                    \n",
    "                # Only compute Wasserstein distance if we have iid_samples\n",
    "                if posterior_type != \"Custom\":\n",
    "                    #ws_distance = sliced_wasserstein_distance(posterior_samples, iid_samples, L=5)\n",
    "\n",
    "                    # 2*runs have already been used for iid vs iid comparison\n",
    "                    fresh_iid_index = num_iid_vs_iid_batches + run_id-1\n",
    "                    iid_batch = ensure_2d(iid_batches[fresh_iid_index]) \n",
    "                    dim = get_posterior_dim(posterior_type, posterior_kwargs)\n",
    "                    #print(f\"Posterior dim: {dim}\")\n",
    "                    if get_posterior_dim(posterior_type, posterior_kwargs) > 1:\n",
    "                        mcmc_vs_iid_swd = sliced_wasserstein_distance(posterior_samples, iid_batch, L=50)\n",
    "                    else:\n",
    "                        mcmc_vs_iid_swd = sliced_wasserstein_distance(posterior_samples, iid_batch, L=1)\n",
    "                    mmd_rff_value = compute_mmd_rff(posterior_samples, iid_batch, D=500, sigma=1.0, seed=run_random_seed)\n",
    "                    \n",
    "                    # get reference values\n",
    "                    ref_stats = iid_ref_stats_dict[value]\n",
    "                    iid_vs_iid_mean = ref_stats[\"mean_swd\"]\n",
    "                    iid_vs_iid_std = ref_stats[\"std_swd\"]\n",
    "\n",
    "                    relative_swd = mcmc_vs_iid_swd - iid_vs_iid_mean\n",
    "                    if iid_vs_iid_std > 0:\n",
    "                        # Compute z-score\n",
    "                        swd_zscore = relative_swd / iid_vs_iid_std\n",
    "                    else: \n",
    "                        swd_zscore = np.nan\n",
    "              \n",
    "                else:\n",
    "                    mcmc_vs_iid_swd = np.nan\n",
    "                    relative_swd = np.nan\n",
    "                    swd_zscore = np.nan\n",
    "\n",
    "\n",
    "                # Compute R-hat and ESS\n",
    "                r_hat, ess = get_scalar_rhat_and_ess(trace)\n",
    "\n",
    "\n",
    "                #print(f\"R-hat for sampler {sampler_name}: {r_hat}\")\n",
    "                #print(f\"ESS for sampler {sampler_name}: {ess}\")\n",
    "\n",
    "                results.append({\n",
    "                    \"run_id\": run_id,\n",
    "                    varying_attribute: value,\n",
    "                    \"sampler\": sampler_name,\n",
    "                    \"wasserstein_distance\": mcmc_vs_iid_swd,\n",
    "                    \"mmd_rff\": mmd_rff_value,\n",
    "                    \"swd_zscore\": swd_zscore,\n",
    "                    \"r_hat\": r_hat,\n",
    "                    \"ess\": ess,\n",
    "                    \"runtime\": runtime\n",
    "                })\n",
    "\n",
    "\n",
    "        # Convert results to DataFrame and save\n",
    "        df_results = pd.DataFrame(results)\n",
    "\n",
    "        var_attr_is_tuple = False\n",
    "\n",
    "        # Handle tuple-based attributes consistently\n",
    "        if isinstance(df_results[varying_attribute].iloc[0], tuple):\n",
    "            var_attr_is_tuple = True\n",
    "            df_results[varying_attribute] = df_results[varying_attribute].apply(str)\n",
    "            varying_attribute_for_plot = varying_attribute\n",
    "        else:\n",
    "            varying_attribute_for_plot = varying_attribute\n",
    "\n",
    "        df_results = df_results.sort_values(varying_attribute_for_plot, ascending=True)\n",
    "\n",
    "        if experiment_settings.get(\"save_plots_and_csv_per_run\", False):\n",
    "            plot_and_save_all_metrics(\n",
    "                df_results=df_results,\n",
    "                sampler_colors=sampler_colors,\n",
    "                varying_attribute=varying_attribute,\n",
    "                varying_attribute_for_plot=varying_attribute_for_plot,\n",
    "                csv_folder=csv_folder,\n",
    "                plots_folder=plots_folder,\n",
    "                run_id=run_id,\n",
    "                config_descr=config_descr\n",
    "            )\n",
    "\n",
    "        df_all_runs.append(df_results)\n",
    "\n",
    "        # Now increments the TQDM progress bar if it's provided\n",
    "        if progress_bar is not None:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    logger.info(\"All runs completed successfully.\")\n",
    "\n",
    "    # ===== GLOBAL RESULTS FOLDER =====\n",
    "    global_folder = os.path.join(group_folder, \"global_results\")\n",
    "    global_results_folder = os.path.join(global_folder, \"results\")\n",
    "    global_plots_folder = os.path.join(global_folder, \"plots\")\n",
    "    create_directories(global_folder, global_results_folder, global_plots_folder)\n",
    "    \n",
    "    # Combine all results into a single data frame \n",
    "    df_all_runs = pd.concat(df_all_runs, ignore_index=True)\n",
    "\n",
    "    if var_attr_is_tuple:\n",
    "        iid_ref_stats_dict = {str(k): v for k, v in iid_ref_stats_dict.items()}\n",
    "\n",
    "    compute_and_save_global_metrics(\n",
    "        df_all_runs=df_all_runs,\n",
    "        sampler_colors=sampler_colors,\n",
    "        varying_attribute=varying_attribute,\n",
    "        varying_values=varying_values,\n",
    "        runs=runs,\n",
    "        config_descr=config_descr,\n",
    "        global_results_folder=global_results_folder,\n",
    "        global_plots_folder=global_plots_folder,\n",
    "        iid_ref_stats_dict=iid_ref_stats_dict\n",
    "    )\n",
    "\n",
    "    logger.info(f\"===== Config {config_descr} completed successfully. =====\")\n",
    "\n",
    "\n",
    "def validate_config(config):\n",
    "    \"\"\"Checks if the config correctly defines one varying attribute and all other attributes are fixed.\"\"\"\n",
    "    \n",
    "    REQUIRED_ATTRIBUTES = {\n",
    "    \"config_descr\",\n",
    "    \"posterior_type\",\n",
    "    \"runs\",\n",
    "    \"num_samples\",\n",
    "    \"num_chains\",\n",
    "    \"varying_attribute\",\n",
    "    \"varying_values\",\n",
    "    }\n",
    "\n",
    "    # Posterior-specific required attributes\n",
    "    POSTERIOR_ATTRIBUTES = {\n",
    "        \"Cauchy\": {\"alpha\", \"beta\"},\n",
    "        \"Beta\": {\"a\", \"b\"},\n",
    "        \"Normal\": {\"mu\", \"sigma\"},\n",
    "        \"StudentT\": {\"nu\", \"mu\", \"sigma\"},\n",
    "        \"Laplace\": {\"mu\", \"b\"},\n",
    "        \"SkewStudentT\": {\"a\", \"b\", \"mu\", \"sigma\"},\n",
    "        \"Mixture\": {\"component_types\", \"component_params\", \"weights\"},\n",
    "        \"MvNormal\": {\"mu\", \"cov\"},\n",
    "        \"Custom\": {\"logp_func\"}\n",
    "    }\n",
    "\n",
    "    OPTIONAL_ATTRIBUTES = {\"base_random_seed\", \"init_scheme\", \"varying_component\"}\n",
    "\n",
    "    if \"config_descr\" not in config:\n",
    "        raise ValueError(\"Config is missing 'config_descr'.\")\n",
    "    \n",
    "    config_descr = config[\"config_descr\"]\n",
    "\n",
    "    if \"varying_attribute\" not in config:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing 'varying_attribute'.\")\n",
    "    \n",
    "    varying_attr = config[\"varying_attribute\"]\n",
    "\n",
    "    # Ensure all required attributes are present\n",
    "    missing_attrs = REQUIRED_ATTRIBUTES - config.keys() - {varying_attr}\n",
    "\n",
    "    if missing_attrs:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing required attributes: {missing_attrs}.\")\n",
    "    \n",
    "    posterior_type = config[\"posterior_type\"]\n",
    "\n",
    "    if posterior_type not in POSTERIOR_ATTRIBUTES:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'posterior_type': '{posterior_type}'.\")\n",
    "\n",
    "    if posterior_type == \"Mixture\" and \"varying_component\" in config:\n",
    "        varying_index = config[\"varying_component\"]\n",
    "        varying_component = config[\"component_types\"][varying_index]\n",
    "        all_valid_attributes = REQUIRED_ATTRIBUTES.union(POSTERIOR_ATTRIBUTES[posterior_type], POSTERIOR_ATTRIBUTES[varying_component], OPTIONAL_ATTRIBUTES)\n",
    "        \n",
    "    else:\n",
    "        # Ensure varying_attribute is a recognized attribute\n",
    "        all_valid_attributes = REQUIRED_ATTRIBUTES.union(POSTERIOR_ATTRIBUTES[posterior_type], OPTIONAL_ATTRIBUTES)\n",
    "\n",
    "    if varying_attr not in all_valid_attributes:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'varying_attribute': '{varying_attr}'.\")\n",
    "        \n",
    "    if posterior_type == \"Mixture\" and varying_attr not in (\"num_samples\", \"num_chains\", \"init_scheme\"):\n",
    "        if \"varying_component\" not in config:\n",
    "            raise ValueError(\n",
    "                f\"Config '{config_descr}' must have 'varying_component' defined \"\n",
    "                f\"when varying '{varying_attr}' for a Mixture.\"\n",
    "            )\n",
    "        \n",
    "    vc = config.get(\"varying_component\")    \n",
    "    if vc is not None and not (0 <= vc < len(config[\"component_types\"])):\n",
    "        raise ValueError(\n",
    "            f\"Config '{config_descr}' has invalid 'varying_component' index {vc}, \"\n",
    "            f\"but 'component_types' has length {len(config['component_types'])}.\"\n",
    "        )\n",
    "    \n",
    "    VALID_INIT_SCHEMES = {\"equal_per_mode\",\"all_in_middle\", \"all_near_mode\", \"thesis_scheme\", \"None\"} \n",
    "\n",
    "    if \"init_scheme\" in config:\n",
    "        if config[\"init_scheme\"] not in VALID_INIT_SCHEMES and not config[\"init_scheme\"].startswith(\"all_near_mode_\"):\n",
    "            raise ValueError(\n",
    "                f\"Config '{config_descr}' has invalid 'init_scheme': \"\n",
    "                f\"'{config['init_scheme']}'. Must be one of {VALID_INIT_SCHEMES} \"\n",
    "                \"or 'all_near_mode_<int>'.\"\n",
    "            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of runs: 57\n",
      "All configurations are valid. Starting experiments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total experiment progress:   5%|▌         | 3/57 [00:30<09:02, 10.05s/it]The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 04:55:49,988 - ERROR - The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total experiment progress:   5%|▌         | 3/57 [00:49<14:52, 16.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m exp_group:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m         \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresults_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexperiment_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposterior_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposterior_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_descr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_descr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvarying_attribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvarying_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit_scheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvaries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_random_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_random_seed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_descr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_attribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvarying_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_scheme\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_random_seed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposterior_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass remaining keys as posterior_kwargs\u001b[39;49;00m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in config \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_descr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[81], line 1477\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(results_folder, experiment_settings, posterior_type, config_descr, runs, varying_attribute, varying_values, num_samples, num_chains, init_scheme, base_random_seed, progress_bar, group_name, **posterior_kwargs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;66;03m# **Measure Computation Time**\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 1477\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_sampling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples_per_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_first_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_first_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minit_value_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_random_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_random_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1480\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1481\u001b[0m runtime \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[81], line 1138\u001b[0m, in \u001b[0;36mPosteriorExample.run_sampling\u001b[0;34m(self, sampler_name, num_samples, tune, num_chains, initvals, run_id, plot_first_sample, init_folder, value, means, run_random_seed)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     discard_tuned_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initvals \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m     trace \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43minitvals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_random_seed\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkeeed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/sampling/mcmc.py:776\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m ip: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ip \u001b[38;5;129;01min\u001b[39;00m initial_points:\n\u001b[0;32m--> 776\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_start_vals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m     _check_start_shape(model, ip)\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/model/core.py:1790\u001b[0m, in \u001b[0;36mModel.check_start_vals\u001b[0;34m(self, start)\u001b[0m\n\u001b[1;32m   1784\u001b[0m     valid_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(value_names_set)\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1786\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome start parameters do not appear in the model!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1787\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid keys are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1788\u001b[0m     )\n\u001b[0;32m-> 1790\u001b[0m initial_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint_logps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(np\u001b[38;5;241m.\u001b[39misfinite(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m initial_eval\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m   1793\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SamplingError(\n\u001b[1;32m   1794\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial evaluation of model at starting point failed!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1795\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00melem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogp initial evaluation results:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minitial_eval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can call `model.debug()` for more details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1798\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/model/core.py:1825\u001b[0m, in \u001b[0;36mModel.point_logps\u001b[0;34m(self, point, round_vals)\u001b[0m\n\u001b[1;32m   1819\u001b[0m factors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_RVs \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpotentials\n\u001b[1;32m   1820\u001b[0m factor_logps_fn \u001b[38;5;241m=\u001b[39m [pt\u001b[38;5;241m.\u001b[39msum(factor) \u001b[38;5;28;01mfor\u001b[39;00m factor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogp(factors, \u001b[38;5;28msum\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m   1822\u001b[0m     factor\u001b[38;5;241m.\u001b[39mname: np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39masarray(factor_logp), round_vals)\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m factor, factor_logp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m   1824\u001b[0m         factors,\n\u001b[0;32m-> 1825\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor_logps_fn\u001b[49m\u001b[43m)\u001b[49m(point),\n\u001b[1;32m   1826\u001b[0m     )\n\u001b[1;32m   1827\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/model/core.py:1664\u001b[0m, in \u001b[0;36mModel.compile_fn\u001b[0;34m(self, outs, inputs, mode, point_fn, **kwargs)\u001b[0m\n\u001b[1;32m   1661\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputvars(outs)\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1664\u001b[0m     fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_pymc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_input_downcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m point_fn:\n\u001b[1;32m   1674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PointFunc(fn)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pymc/pytensorf.py:1039\u001b[0m, in \u001b[0;36mcompile_pymc\u001b[0;34m(inputs, outputs, random_seed, mode, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m opt_qry \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mprovided_optimizer\u001b[38;5;241m.\u001b[39mincluding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_make_inplace\u001b[39m\u001b[38;5;124m\"\u001b[39m, check_parameter_opt)\n\u001b[1;32m   1038\u001b[0m mode \u001b[38;5;241m=\u001b[39m Mode(linker\u001b[38;5;241m=\u001b[39mmode\u001b[38;5;241m.\u001b[39mlinker, optimizer\u001b[38;5;241m=\u001b[39mopt_qry)\n\u001b[0;32m-> 1039\u001b[0m pytensor_function \u001b[38;5;241m=\u001b[39m \u001b[43mpytensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrng_updates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pytensor_function\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/__init__.py:318\u001b[0m, in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    312\u001b[0m     fn \u001b[38;5;241m=\u001b[39m orig_function(\n\u001b[1;32m    313\u001b[0m         inputs, outputs, mode\u001b[38;5;241m=\u001b[39mmode, accept_inplace\u001b[38;5;241m=\u001b[39maccept_inplace, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    314\u001b[0m     )\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# note: pfunc will also call orig_function -- orig_function is\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m#      a choke point that all compilation must pass through\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     fn \u001b[38;5;241m=\u001b[39m \u001b[43mpfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgivens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgivens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_default_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_default_updates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrebuild_strict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrebuild_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_input_downcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_input_downcast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_unused_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_unused_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/pfunc.py:465\u001b[0m, in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys, fgraph)\u001b[0m\n\u001b[1;32m    451\u001b[0m     profile \u001b[38;5;241m=\u001b[39m ProfileStats(message\u001b[38;5;241m=\u001b[39mprofile)\n\u001b[1;32m    453\u001b[0m inputs, cloned_outputs \u001b[38;5;241m=\u001b[39m construct_pfunc_ins_and_outs(\n\u001b[1;32m    454\u001b[0m     params,\n\u001b[1;32m    455\u001b[0m     outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     fgraph\u001b[38;5;241m=\u001b[39mfgraph,\n\u001b[1;32m    463\u001b[0m )\n\u001b[0;32m--> 465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43morig_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_unused_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_unused_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/types.py:1750\u001b[0m, in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys, fgraph)\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1749\u001b[0m     Maker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_maker\u001b[39m\u001b[38;5;124m\"\u001b[39m, FunctionMaker)\n\u001b[0;32m-> 1750\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mMaker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_unused_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_unused_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1761\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config\u001b[38;5;241m.\u001b[39mchange_flags(compute_test_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1762\u001b[0m         fn \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mcreate(defaults)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/types.py:1523\u001b[0m, in \u001b[0;36mFunctionMaker.__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys, name, no_fgraph_prep)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfgraph \u001b[38;5;241m=\u001b[39m fgraph\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_fgraph_prep:\n\u001b[0;32m-> 1523\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_fgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfound_updates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fgraph\u001b[38;5;241m.\u001b[39moutputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(outputs \u001b[38;5;241m+\u001b[39m found_updates)\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;66;03m# The 'no_borrow' outputs are the ones for which that we can't\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;66;03m# return the internal storage pointer.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/types.py:1411\u001b[0m, in \u001b[0;36mFunctionMaker.prepare_fgraph\u001b[0;34m(inputs, outputs, additional_outputs, fgraph, mode, profile)\u001b[0m\n\u001b[1;32m   1404\u001b[0m rewrite_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config\u001b[38;5;241m.\u001b[39mchange_flags(\n\u001b[1;32m   1407\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   1408\u001b[0m     compute_test_value\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcompute_test_value_opt,\n\u001b[1;32m   1409\u001b[0m     traceback__limit\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtraceback__compile_limit,\n\u001b[1;32m   1410\u001b[0m ):\n\u001b[0;32m-> 1411\u001b[0m     rewriter_profile \u001b[38;5;241m=\u001b[39m \u001b[43mrewriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m     end_rewriter \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m   1414\u001b[0m     rewrite_time \u001b[38;5;241m=\u001b[39m end_rewriter \u001b[38;5;241m-\u001b[39m start_rewriter\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/graph/rewriting/basic.py:125\u001b[0m, in \u001b[0;36mGraphRewriter.__call__\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fgraph):\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Rewrite a `FunctionGraph`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfgraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/graph/rewriting/basic.py:121\u001b[0m, in \u001b[0;36mGraphRewriter.rewrite\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03mThis is meant as a shortcut for the following::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_requirements(fgraph)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/graph/rewriting/basic.py:291\u001b[0m, in \u001b[0;36mSequentialGraphRewriter.apply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    289\u001b[0m nb_nodes_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fgraph\u001b[38;5;241m.\u001b[39mapply_nodes)\n\u001b[1;32m    290\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 291\u001b[0m sub_prof \u001b[38;5;241m=\u001b[39m \u001b[43mrewriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m l\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m t0))\n\u001b[1;32m    293\u001b[0m sub_profs\u001b[38;5;241m.\u001b[39mappend(sub_prof)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/graph/rewriting/basic.py:291\u001b[0m, in \u001b[0;36mSequentialGraphRewriter.apply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    289\u001b[0m nb_nodes_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fgraph\u001b[38;5;241m.\u001b[39mapply_nodes)\n\u001b[1;32m    290\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 291\u001b[0m sub_prof \u001b[38;5;241m=\u001b[39m \u001b[43mrewriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m l\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m t0))\n\u001b[1;32m    293\u001b[0m sub_profs\u001b[38;5;241m.\u001b[39mappend(sub_prof)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/tensor/rewriting/elemwise.py:1033\u001b[0m, in \u001b[0;36mFusionOptimizer.apply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     warn(\n\u001b[1;32m   1028\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoop fusion failed because the resulting node would exceed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1029\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe kernel argument limit.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1030\u001b[0m     )\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1033\u001b[0m scalar_inputs, scalar_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melemwise_to_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m composite_outputs \u001b[38;5;241m=\u001b[39m Elemwise(ps\u001b[38;5;241m.\u001b[39mComposite(scalar_inputs, scalar_outputs))(\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;241m*\u001b[39minputs\n\u001b[1;32m   1036\u001b[0m )\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(composite_outputs, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/tensor/rewriting/elemwise.py:631\u001b[0m, in \u001b[0;36mFusionOptimizer.elemwise_to_scalar\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melemwise_to_scalar\u001b[39m(inputs, outputs):\n\u001b[1;32m    630\u001b[0m     replace_inputs \u001b[38;5;241m=\u001b[39m [(inp, inp\u001b[38;5;241m.\u001b[39mclone()) \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[0;32m--> 631\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mclone_replace\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m [inp \u001b[38;5;28;01mfor\u001b[39;00m _, inp \u001b[38;5;129;01min\u001b[39;00m replace_inputs]\n\u001b[1;32m    634\u001b[0m     fg \u001b[38;5;241m=\u001b[39m FunctionGraph(inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, clone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/graph/replace.py:82\u001b[0m, in \u001b[0;36mclone_replace\u001b[0;34m(output, replace, **rebuild_kwds)\u001b[0m\n\u001b[1;32m     80\u001b[0m tmp_replace \u001b[38;5;241m=\u001b[39m [(x, x\u001b[38;5;241m.\u001b[39mtype()) \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m items]\n\u001b[1;32m     81\u001b[0m new_replace \u001b[38;5;241m=\u001b[39m [(x, y) \u001b[38;5;28;01mfor\u001b[39;00m ((_, x), (_, y)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tmp_replace, items)]\n\u001b[0;32m---> 82\u001b[0m _, _outs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrebuild_collect_shared\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_replace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrebuild_kwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# TODO Explain why we call it twice ?!\u001b[39;00m\n\u001b[1;32m     85\u001b[0m _, outs, _ \u001b[38;5;241m=\u001b[39m rebuild_collect_shared(_outs, [], new_replace, [], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrebuild_kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/pfunc.py:313\u001b[0m, in \u001b[0;36mrebuild_collect_shared\u001b[0;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates, clone_inner_graphs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, Variable):\n\u001b[0;32m--> 313\u001b[0m         cloned_v \u001b[38;5;241m=\u001b[39m \u001b[43mclone_v_get_shared_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_inputs_over\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m         cloned_outputs\u001b[38;5;241m.\u001b[39mappend(cloned_v)\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, Out):\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/pfunc.py:189\u001b[0m, in \u001b[0;36mrebuild_collect_shared.<locals>.clone_v_get_shared_updates\u001b[0;34m(v, copy_inputs_over)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m owner \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m clone_d:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m owner\u001b[38;5;241m.\u001b[39minputs:\n\u001b[0;32m--> 189\u001b[0m         \u001b[43mclone_v_get_shared_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_inputs_over\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     clone_node_and_cache(\n\u001b[1;32m    191\u001b[0m         owner,\n\u001b[1;32m    192\u001b[0m         clone_d,\n\u001b[1;32m    193\u001b[0m         strict\u001b[38;5;241m=\u001b[39mrebuild_strict,\n\u001b[1;32m    194\u001b[0m         clone_inner_graphs\u001b[38;5;241m=\u001b[39mclone_inner_graphs,\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clone_d\u001b[38;5;241m.\u001b[39msetdefault(v, v)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/pfunc.py:189\u001b[0m, in \u001b[0;36mrebuild_collect_shared.<locals>.clone_v_get_shared_updates\u001b[0;34m(v, copy_inputs_over)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m owner \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m clone_d:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m owner\u001b[38;5;241m.\u001b[39minputs:\n\u001b[0;32m--> 189\u001b[0m         \u001b[43mclone_v_get_shared_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_inputs_over\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     clone_node_and_cache(\n\u001b[1;32m    191\u001b[0m         owner,\n\u001b[1;32m    192\u001b[0m         clone_d,\n\u001b[1;32m    193\u001b[0m         strict\u001b[38;5;241m=\u001b[39mrebuild_strict,\n\u001b[1;32m    194\u001b[0m         clone_inner_graphs\u001b[38;5;241m=\u001b[39mclone_inner_graphs,\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clone_d\u001b[38;5;241m.\u001b[39msetdefault(v, v)\n",
      "    \u001b[0;31m[... skipping similar frames: rebuild_collect_shared.<locals>.clone_v_get_shared_updates at line 189 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/pfunc.py:189\u001b[0m, in \u001b[0;36mrebuild_collect_shared.<locals>.clone_v_get_shared_updates\u001b[0;34m(v, copy_inputs_over)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m owner \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m clone_d:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m owner\u001b[38;5;241m.\u001b[39minputs:\n\u001b[0;32m--> 189\u001b[0m         \u001b[43mclone_v_get_shared_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_inputs_over\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     clone_node_and_cache(\n\u001b[1;32m    191\u001b[0m         owner,\n\u001b[1;32m    192\u001b[0m         clone_d,\n\u001b[1;32m    193\u001b[0m         strict\u001b[38;5;241m=\u001b[39mrebuild_strict,\n\u001b[1;32m    194\u001b[0m         clone_inner_graphs\u001b[38;5;241m=\u001b[39mclone_inner_graphs,\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clone_d\u001b[38;5;241m.\u001b[39msetdefault(v, v)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/compile/function/pfunc.py:190\u001b[0m, in \u001b[0;36mrebuild_collect_shared.<locals>.clone_v_get_shared_updates\u001b[0;34m(v, copy_inputs_over)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m owner\u001b[38;5;241m.\u001b[39minputs:\n\u001b[1;32m    189\u001b[0m             clone_v_get_shared_updates(i, copy_inputs_over)\n\u001b[0;32m--> 190\u001b[0m         \u001b[43mclone_node_and_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mowner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone_d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrebuild_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone_inner_graphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone_inner_graphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone_d\u001b[38;5;241m.\u001b[39msetdefault(v, v)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, SharedVariable):\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/graph/basic.py:1286\u001b[0m, in \u001b[0;36mclone_node_and_cache\u001b[0;34m(node, clone_d, clone_inner_graphs, **kwargs)\u001b[0m\n\u001b[1;32m   1282\u001b[0m new_op: Op \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m cast(Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOp\u001b[39m\u001b[38;5;124m\"\u001b[39m], clone_d\u001b[38;5;241m.\u001b[39mget(node\u001b[38;5;241m.\u001b[39mop))\n\u001b[1;32m   1284\u001b[0m cloned_inputs: \u001b[38;5;28mlist\u001b[39m[Variable] \u001b[38;5;241m=\u001b[39m [cast(Variable, clone_d[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39minputs]\n\u001b[0;32m-> 1286\u001b[0m new_node \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone_with_new_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Only clone inner-graph `Op`s when there isn't a cached clone (and\u001b[39;49;00m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# when `clone_inner_graphs` is enabled)\u001b[39;49;00m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclone_inner_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone_inner_graphs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnew_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_op:\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m# If we didn't clone the inner-graph `Op` above, because\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;66;03m# there was a cached version, set the cloned `Apply` to use\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;66;03m# the cached clone `Op`\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m     new_node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m=\u001b[39m new_op\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/graph/basic.py:300\u001b[0m, in \u001b[0;36mApply.clone_with_new_inputs\u001b[0;34m(self, inputs, strict, clone_inner_graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m     new_node\u001b[38;5;241m.\u001b[39mtag \u001b[38;5;241m=\u001b[39m copy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtag)\u001b[38;5;241m.\u001b[39m__update__(new_node\u001b[38;5;241m.\u001b[39mtag)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m     new_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone_inner_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone_inner_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     new_node\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m new_inputs\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_node\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_immo_env/lib/python3.12/site-packages/pytensor/graph/basic.py:229\u001b[0m, in \u001b[0;36mApply.clone\u001b[0;34m(self, clone_inner_graph)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HasInnerGraph\n\u001b[1;32m    227\u001b[0m new_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHasInnerGraph\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m clone_inner_graph:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     new_op \u001b[38;5;241m=\u001b[39m new_op\u001b[38;5;241m.\u001b[39mclone()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    232\u001b[0m cp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\n\u001b[1;32m    233\u001b[0m     new_op, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs, [output\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs]\n\u001b[1;32m    234\u001b[0m )\n",
      "File \u001b[0;32m<frozen abc>:117\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "experiment_name = \"5_categories\"\n",
    "config_names = [\"unimodal\", \"multimodal\", \"high_dim_wo_correlation\", \"high_dim_with_correlation\", \"difficult_geometries\"]\n",
    "\n",
    "# Define the root directory for all experiments\n",
    "experiment_root_folder = f\"exp_{experiment_name}\"\n",
    "# Check if the folder already exists\n",
    "if os.path.exists(experiment_root_folder):\n",
    "    user_input = input(\n",
    "        f\"Folder '{experiment_root_folder}' already exists and will be overwritten.\\n\"\n",
    "        \"Do you want to continue? (yes/no): \"\n",
    "    ).strip().lower()\n",
    "\n",
    "    if user_input not in [\"yes\", \"y\"]:\n",
    "        print(\"Operation aborted. No files were deleted.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    shutil.rmtree(experiment_root_folder)\n",
    "\n",
    "create_directories(experiment_root_folder)\n",
    "results_folder = os.path.join(experiment_root_folder, \"results\")\n",
    "create_directories(results_folder)\n",
    "\n",
    "# Copy current_exp_config folders into experiment_root\n",
    "for subfolder in [\"configs\", \"default_vals\", \"settings\"]:\n",
    "    src = os.path.join(\"current_exp_config\", subfolder)\n",
    "    dst = os.path.join(experiment_root_folder, subfolder)\n",
    "    if not os.path.exists(dst):\n",
    "        shutil.copytree(src, dst)\n",
    "    else:\n",
    "        print(f\"Skipping copy: {dst} already exists.\")\n",
    "\n",
    "\n",
    "experiment_paths = get_experiment_paths(config_names)\n",
    "\n",
    "settings_path = os.path.join(experiment_root_folder, \"settings\", \"experiment_settings.yaml\")\n",
    "defaults_path = os.path.join(experiment_root_folder, \"default_vals\", \"attribute_default_vals.yaml\")\n",
    "\n",
    "experiment_settings = load_experiment_settings(settings_path)\n",
    "defaults = load_default_values(defaults_path)\n",
    "\n",
    "experiments = []\n",
    "for path in experiment_paths:\n",
    "    group_name, config_list = load_config_file(path)\n",
    "    config_list = [apply_defaults_to_config(cfg, defaults) for cfg in config_list]\n",
    "    experiments.append((group_name, config_list))\n",
    "\n",
    "\n",
    "failed_configs = []\n",
    "start_time = time.time()\n",
    "start_dt = datetime.now()\n",
    "\n",
    "# Validate all configurations before running the experiments\n",
    "for group_name, exp_group in experiments:\n",
    "    for config in exp_group:\n",
    "        validate_config(config)\n",
    "\n",
    "total_runs = sum(config[\"runs\"] for _,exp_group in experiments for config in exp_group)\n",
    "print(f\"Total number of runs: {total_runs}\")\n",
    "\n",
    "print(\"All configurations are valid. Starting experiments...\")\n",
    "with tqdm(total=total_runs, desc=\"Total experiment progress\") as pbar:\n",
    "    for group_name, exp_group in experiments:\n",
    "        for config in exp_group:\n",
    "            try:\n",
    "                run_experiment(\n",
    "                    results_folder,\n",
    "                    experiment_settings,\n",
    "                    posterior_type=config[\"posterior_type\"],\n",
    "                    config_descr=config[\"config_descr\"],\n",
    "                    runs=config[\"runs\"],\n",
    "                    varying_attribute=config[\"varying_attribute\"],\n",
    "                    varying_values=config[\"varying_values\"],\n",
    "                    init_scheme=\"varies\" if config[\"varying_attribute\"] == \"init_scheme\" else config.get(\"init_scheme\", None),\n",
    "                    num_samples=\"varies\" if config[\"varying_attribute\"] == \"num_samples\" else config[\"num_samples\"],\n",
    "                    num_chains=\"varies\" if config[\"varying_attribute\"] == \"num_chains\" else config[\"num_chains\"],\n",
    "                    base_random_seed=config.get(\"base_random_seed\", None),\n",
    "                    group_name=group_name,\n",
    "                    progress_bar=pbar, \n",
    "                    **{k: v for k, v in config.items() if k not in [\n",
    "                        \"config_descr\", \"runs\", \"varying_attribute\", \"varying_values\", \n",
    "                        \"num_samples\", \"num_chains\", \"init_scheme\", \n",
    "                        \"base_random_seed\", \"posterior_type\"\n",
    "                    ]}  # Pass remaining keys as posterior_kwargs\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error in config '{config['config_descr']}': {e}\")\n",
    "                traceback.print_exc()\n",
    "                failed_configs.append((config['config_descr'], str(e)))\n",
    "                \n",
    "\n",
    "end_time = time.time()\n",
    "end_dt = datetime.now()\n",
    "duration = end_time - start_time\n",
    "hours = int(duration // 3600)\n",
    "minutes = int((duration % 3600) // 60)\n",
    "seconds = round(duration % 60, 1)\n",
    "\n",
    "def get_folder_size(path='.'):\n",
    "    \"\"\"Compute total size of all files in directory.\"\"\"\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total += os.path.getsize(fp)\n",
    "    return total\n",
    "\n",
    "# Prepare the summary text\n",
    "size_bytes = get_folder_size(experiment_root_folder)\n",
    "total_configs = sum(len(exp) for exp in experiments)\n",
    "\n",
    "summary_lines = [\n",
    "    \"\\n============================\",\n",
    "    \"Experiment Summary\",\n",
    "    \"============================\",\n",
    "    f\"Started at:               {start_dt.strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"Finished at:              {end_dt.strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"Total duration:           {hours}h {minutes}m {seconds}s\",\n",
    "    f\"Output folder:            {experiment_root_folder}\",\n",
    "    f\"Output folder size:       {humanize.naturalsize(size_bytes)}\",\n",
    "    f\"Total configurations:     {total_configs}\",\n",
    "    f\"Successful runs:          {total_configs - len(failed_configs)}\",\n",
    "    f\"Failed configurations:    {len(failed_configs)}\"\n",
    "]\n",
    "\n",
    "if failed_configs:\n",
    "    summary_lines.append(\"\\n Failed Configurations:\")\n",
    "    for cfg, msg in failed_configs:\n",
    "        summary_lines.append(f\" - {cfg}: {msg}\")\n",
    "\n",
    "# Print to console\n",
    "print(\"\\n\".join(summary_lines))\n",
    "\n",
    "# Also save to summary.txt\n",
    "summary_path = os.path.join(results_folder, \"summary.txt\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(summary_lines))\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# posterior_type = \"Cauchy\", \"Beta\", \"Normal\", \"StudentT\", \"Laplace\", \"SkewstudentT\"\n",
    "# varying_attribute = \"num_samples\", \"num_chains\", \"init_scheme\" or posterior specific attribute\n",
    "# mixture specific attributes = \"component_types\", component_params\", \"weights\"\n",
    "# cauchy specific attributes = \"alpha\", \"beta\"\n",
    "# beta specific attributes = \"alpha\", \"beta\"\n",
    "# normal specific attributes = \"mu\", \"sigma\"\n",
    "# student_t specific attributes = \"nu\", \"mu\", \"sigma\"\n",
    "# laplace specific attributes = \"mu\", \"b\"\n",
    "# skewed_student_t specific attributes = \"a\", \"b\", \"mu\", \"sigma\"\n",
    "# all but the varying attribute must be fixed and present in the config\n",
    "\n",
    "\n",
    "r_hat_test_2d = [\n",
    "    {\n",
    "        \"config_descr\": \"4_Mixture_of_Normal_2d\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3), (10, 10)],\n",
    "        \"varying_component\": 3,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "            {\"mu\": [-10, -10], \"cov\": [[1, 0.2], [0.2, 1.5]]},\n",
    "            {\"mu\": [10, -10], \"cov\": [[1.2, -0.3], [-0.3, 1.2]]},\n",
    "            {\"mu\": [-10, 10], \"cov\": [[0.9, 0.1], [0.1, 1.1]]},\n",
    "            {\"cov\": [[1.5, 0.4], [0.4, 1.8]]}\n",
    "        ],\n",
    "        \"weights\": [0.25, 0.25, 0.25, 0.25],\n",
    "        \"init_scheme\": \"equal_per_mode\"\n",
    "    }\n",
    "]\n",
    "\n",
    "r_hat_test_1d = [\n",
    "    {\n",
    "        \"config_descr\": \"4_Mixture_of_Normal_1d\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [30, 35, 40], \n",
    "        \"varying_component\": 3,\n",
    "        \"component_types\": [\"Normal\", \"Normal\", \"Normal\", \"Normal\"],\n",
    "        \"component_params\": [\n",
    "            {\"mu\": -30, \"sigma\": 1},\n",
    "            {\"mu\": 10, \"sigma\": 1},\n",
    "            {\"mu\": -10, \"sigma\": 1},\n",
    "            {\"sigma\": 1}\n",
    "        ],\n",
    "        \"weights\": [0.25, 0.25, 0.25, 0.25],\n",
    "        \"init_scheme\": \"equal_per_mode\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "cauchy = [\n",
    "    {\n",
    "        \"config_descr\": \"Cauchy\",\n",
    "        \"posterior_type\": \"Cauchy\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"alpha\",\n",
    "        \"varying_values\": [2],\n",
    "        \"beta\": 2,\n",
    "        \"init_scheme\": default_init_scheme,\n",
    "    }\n",
    "]\n",
    "\n",
    "unimodal = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Normal\",\n",
    "        \"posterior_type\": \"Normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [2,3,4],\n",
    "        \"sigma\": 1,\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Student_t\",\n",
    "        \"posterior_type\": \"StudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\":  default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 3, 5, 30],\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Laplace_test\",\n",
    "        \"posterior_type\": \"Laplace\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"b\",\n",
    "        \"varying_values\": [0.5, 1, 2, 5],\n",
    "        \"mu\": 0,\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "high_dim_and_correlated = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_3d_high_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (-5, 0, 5),\n",
    "            (0, 0, 0),\n",
    "            (-10, 20, -30),\n",
    "            (50, -50, 100)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.9, 0.85], \n",
    "              [0.9, 1, 0.88], \n",
    "              [0.85, 0.88, 1]],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_2d_low_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (0, 0),\n",
    "            (-10, 10),\n",
    "            (20, -20),\n",
    "            (50, -50)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.1], [0.1, 1]],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    }\n",
    "]\n",
    "\n",
    "multimodal = [\n",
    "        {\n",
    "            \"config_descr\": \"Mv_normal_3d_low_corr\",\n",
    "            \"posterior_type\": \"MvNormal\",\n",
    "            \"num_samples\": default_num_samples,\n",
    "            \"runs\": default_runs,\n",
    "            \"num_chains\": default_num_chains,\n",
    "            \"base_random_seed\": default_base_random_seed,\n",
    "            \"varying_attribute\": \"mu\",\n",
    "            \"varying_values\": [\n",
    "                (-5, 0, 5),\n",
    "                (0, 0, 0),\n",
    "                (-10, 20, -30),\n",
    "                (50, -50, 100)\n",
    "            ],\n",
    "            \"cov\": [[1, 0.2, 0.1], \n",
    "                    [0.2, 1, 0.15], \n",
    "                    [0.1, 0.15, 1]],\n",
    "            \"init_scheme\": default_init_scheme\n",
    "        },\n",
    "\n",
    "        \n",
    "        {\n",
    "            \"config_descr\": \"Mv_normal_2d_high_corr\",\n",
    "            \"posterior_type\": \"MvNormal\",\n",
    "            \"num_samples\": default_num_samples,\n",
    "            \"runs\": default_runs,\n",
    "            \"num_chains\": default_num_chains,\n",
    "            \"base_random_seed\": default_base_random_seed,\n",
    "            \"varying_attribute\": \"mu\",\n",
    "            \"varying_values\": [\n",
    "                (0, 0),\n",
    "                (-10, 10),\n",
    "                (20, -20),\n",
    "                (50, -50)\n",
    "            ],\n",
    "            \"cov\": [[1, 0.95], [0.95, 1]],\n",
    "            \"init_scheme\": default_init_scheme\n",
    "        },\n",
    "\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(5, 5), (10, -10), (-10, 10)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"mu\": [0, 0], \"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.3, 0.4, 0.3],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"config_descr\": \"Normal_and_student_t\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"StudentT\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"nu\": 3, \"mu\": 10, \"sigma\": 2}],\n",
    "        \"weights\": [0.6, 0.4],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "mv_normal_mixture = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_of_Normal_2d\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3), (10, 10)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "            {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},\n",
    "            {\"cov\": [[2, 0.3], [0.3, 2]]}\n",
    "        ],\n",
    "        \"weights\": [0.7, 0.3],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_of_Normal_3d\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3, 3), (10, 10, 10)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "            {\"mu\": [0, 0, 0], \"cov\": [[1, 0.5, 0.3], [0.5, 1, 0.4], [0.3, 0.4, 1]]},\n",
    "            {\"cov\": [[2, 0.3, 0.2], [0.3, 2, 0.1], [0.2, 0.1, 2]]}\n",
    "        ],\n",
    "        \"weights\": [0.7, 0.3],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "test_sorted = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(5, 5), (10, -10), (20, 20)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"mu\": [0, 0], \"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.3, 0.4, 0.3],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mixture_of_Normal\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [10,1,17],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"component_params\": [\n",
    "            {\"mu\": 0, \"sigma\": 1},\n",
    "            {\"mu\": 10, \"sigma\": 1}\n",
    "        ],\n",
    "        \"weights\": [0.7, 0.3],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    }\n",
    "]\n",
    "\n",
    "easy_multimodal = [\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_of_Normal_2d\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3), (20, 50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "            {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},\n",
    "            {\"cov\": [[2, 0.3], [0.3, 2]]}\n",
    "        ],\n",
    "        \"weights\": [0.7, 0.3],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "]\n",
    "\n",
    "single_mv_normal = [\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_5d\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(10, 10, 20, 30, 30)],\n",
    "        \"cov\": np.eye(5).tolist(),\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "]\n",
    "\n",
    "difficult_geometries = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"SkewStudentT\",\n",
    "        \"posterior_type\": \"SkewStudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [1, 2, 3, 5],\n",
    "        \"b\": 1,\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_of_SkewStudentT\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 3, 6, 10],\n",
    "        \"varying_component\": 0,\n",
    "        \"component_types\": [\"SkewStudentT\", \"SkewStudentT\"],\n",
    "        \"component_params\": [\n",
    "            {\"a\": 3, \"b\": 1, \"sigma\": 1},\n",
    "            {\"a\": 9, \"b\": 3, \"mu\": 3, \"sigma\": 4}\n",
    "        ],\n",
    "        \"weights\": [0.5, 0.5],\n",
    "        \"init_scheme\": default_init_scheme\n",
    "    }\n",
    "]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_immo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
