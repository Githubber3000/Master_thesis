{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import shutil \n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "import humanize \n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "logger = logging.getLogger(\"pymc\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# Function to get the current git tag\n",
    "def get_git_tag():\n",
    "        try:\n",
    "            tag = subprocess.check_output([\"git\", \"describe\", \"--tags\"], stderr=subprocess.DEVNULL).strip().decode()\n",
    "            return tag\n",
    "        except subprocess.CalledProcessError:\n",
    "            return \"No tag found\"\n",
    "\n",
    "def create_directories(*paths):\n",
    "    \"\"\"Creates multiple directories if they don't exist.\"\"\"\n",
    "    for path in paths:\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def plot_and_save_all_metrics(df_results, sampler_colors, varying_attribute, varying_attribute_for_plot, results_folder, plots_folder, run_id, config_descr):\n",
    "    \"\"\"\n",
    "    Generates and saves multiple metric plots for different samplers.\n",
    "\n",
    "    Parameters:\n",
    "    - df_results: DataFrame containing experiment results.\n",
    "    - sampler_colors: Dictionary mapping sampler names to colors.\n",
    "    - varying_attribute: The attribute that varies.\n",
    "    - varying_attribute_for_plot: The attribute used for plotting.\n",
    "    - plots_folder: Folder where plots should be saved.\n",
    "    - run_id: ID of the current run.\n",
    "    - config_descr: Description of the configuration.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define metric labels\n",
    "    metrics = [\"wasserstein_distance\", \"r_hat\", \"ess\", \"runtime\"]\n",
    "\n",
    "    # Initialize plots for all metrics\n",
    "    fig_ax_pairs = {key: plt.subplots(figsize=(10, 6)) for key in metrics}\n",
    "\n",
    "    # Iterate over samplers and plot all metrics\n",
    "    for sampler in df_results[\"sampler\"].unique():\n",
    "        df_sampler = df_results[df_results[\"sampler\"] == sampler]\n",
    "        csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "        df_sampler.to_csv(csv_filename, index=False)\n",
    "\n",
    "        for metric in metrics:\n",
    "            fig, ax = fig_ax_pairs[metric]\n",
    "            ax.plot(df_sampler[varying_attribute_for_plot], df_sampler[metric], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "    # Set dynamic axis labels and save plots\n",
    "    attribute_label = \"Mode Distance\" if varying_attribute == \"mu\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "\n",
    "    for metric in metrics:\n",
    "        fig, ax = fig_ax_pairs[metric]\n",
    "        finalize_and_save_plot(fig,ax, attribute_label, metric, \n",
    "                               f\"{metric} for Samplers (config =_{config_descr})\",\n",
    "                               os.path.join(plots_folder, f\"{metric}_run_{run_id}.pdf\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_and_save_global_metrics(df_all_runs, sampler_colors, varying_attribute, runs, config_descr, global_results_folder, global_plots_folder):\n",
    "    \"\"\"\n",
    "    Computes and saves global metric plots (averaged across runs) for different samplers.\n",
    "\n",
    "    Parameters:\n",
    "    - df_all_runs: DataFrame containing results from all runs.\n",
    "    - sampler_colors: Dictionary mapping sampler names to colors.\n",
    "    - varying_attribute: The attribute that varies.\n",
    "    - runs: Number of experiment runs.\n",
    "    - config_descr: Configuration description.\n",
    "    - global_results_folder: Folder to save CSVs.\n",
    "    - global_plots_folder: Folder to save plots.\n",
    "    \"\"\"\n",
    "\n",
    "    df_all_runs = df_all_runs.sort_values(varying_attribute, ascending=True)\n",
    "    varying_attribute_for_plot = varying_attribute\n",
    "\n",
    "    # Define metrics for aggregation\n",
    "    metrics = [\"wasserstein_distance\", \"r_hat\", \"ess\", \"runtime\"]\n",
    "\n",
    "    # Initialize global plots\n",
    "    #fig_ax_pairs_bars = {metric: plt.subplots(figsize=(10, 6)) for metric in metrics}\n",
    "\n",
    "    # New figure set (line + fill)\n",
    "    fig_ax_pairs_shaded = {metric: plt.subplots(figsize=(10, 6))\n",
    "                       for metric in metrics}\n",
    "\n",
    "    for sampler in df_all_runs[\"sampler\"].unique():\n",
    "        df_sampler = df_all_runs[df_all_runs[\"sampler\"] == sampler]\n",
    "        color = sampler_colors.get(sampler, \"black\")\n",
    "\n",
    "\n",
    "        # Pivot tables: rows = varying attribute, columns = run_id, values = metric\n",
    "        df_pivot = {metric: df_sampler.pivot_table(index=varying_attribute_for_plot, columns=\"run_id\", values=metric)\n",
    "                    for metric in metrics}\n",
    "\n",
    "        # Compute mean and standard deviation\n",
    "        metric_stats = {metric: (df_pivot[metric].mean(axis=1), df_pivot[metric].std(axis=1))\n",
    "                        for metric in metrics}\n",
    "\n",
    "        for metric, (mean, std) in metric_stats.items():\n",
    "            #fig_bar, ax_bar = fig_ax_pairs_bars[metric]\n",
    "            #ax_bar.errorbar(mean.index, mean, yerr=std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "\n",
    "            # New figure set (line + shaded area)\n",
    "            fig_shaded, ax_shaded = fig_ax_pairs_shaded[metric]\n",
    "            ax_shaded.plot(mean.index, mean, \"o-\", label=sampler, color=color)\n",
    "            ax_shaded.fill_between(mean.index, mean - std, mean + std, \n",
    "                                color=color, alpha=0.2)\n",
    "            \n",
    "        # Save global averages CSV\n",
    "        df_global_avg = pd.DataFrame({\n",
    "            varying_attribute: metric_stats[\"wasserstein_distance\"][0].index,\n",
    "            **{f\"global_avg_{metric}\": metric_stats[metric][0].values for metric in metrics},\n",
    "            **{f\"global_avg_{metric}_std\": metric_stats[metric][1].values for metric in metrics},\n",
    "        })\n",
    "\n",
    "\n",
    "        csv_filename = os.path.join(global_results_folder, f\"Global_results_{sampler}.csv\")\n",
    "        df_global_avg.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # Save plots\n",
    "    attribute_label = \"Mode Distance\" if varying_attribute == \"mu\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "    for metric in metrics:\n",
    "        #fig_bar, ax_bar = fig_ax_pairs_bars[metric]\n",
    "        #finalize_and_save_plot(fig_bar, ax_bar, attribute_label, metric,\n",
    "        #                       f\"Averaged {metric.replace('_', ' ').title()} ({runs} Runs, config = {config_descr})\",\n",
    "        #                       os.path.join(global_plots_folder, f\"{metric}_global_plot.pdf\"))\n",
    "        \n",
    "        fig_shaded, ax_shaded = fig_ax_pairs_shaded[metric]\n",
    "        finalize_and_save_plot(fig_shaded, ax_shaded, attribute_label, metric,\n",
    "                               f\"Averaged {metric.replace('_', ' ').title()} ({runs} Runs, config = {config_descr})\",\n",
    "                               os.path.join(global_plots_folder, f\"{metric}_global_plot_shaded.pdf\"))\n",
    "\n",
    "\n",
    "\n",
    "def finalize_and_save_plot(fig, ax, xlabel, ylabel, title, save_path):\n",
    "    \"\"\"\n",
    "    Finalizes the plot with labels, grid, and saves it to a file.\n",
    "    \n",
    "    Parameters:\n",
    "    - fig: Matplotlib figure\n",
    "    - ax: Matplotlib axis\n",
    "    - xlabel: Label for x-axis\n",
    "    - ylabel: Label for y-axis\n",
    "    - title: Title of the plot\n",
    "    - save_path: Path to save the figure.\n",
    "    \"\"\"\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(title=\"Sampler\")\n",
    "    ax.grid(True)\n",
    "    fig.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram(samples, title, save_path=None, posterior_type=None):\n",
    "    \"\"\"\n",
    "    Plots a histogram and KDE of the given samples.\n",
    "\n",
    "    Parameters:\n",
    "    - samples: 1D or 2D array of samples.\n",
    "    - title: Title of the plot.\n",
    "    - save_path: If provided, saves the figure to this path.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if samples.ndim == 2:\n",
    "        # Handle multivariate case\n",
    "        if samples.shape[1] == 2:\n",
    "            plt.scatter(samples[:, 0], samples[:, 1], alpha=0.3, label=\"2D Samples\")\n",
    "            plt.xlabel(\"Dimension 1\")\n",
    "            plt.ylabel(\"Dimension 2\")\n",
    "            plt.title(title)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "        elif posterior_type == \"MvNormal\" and samples.shape[1] > 2:\n",
    "            print(f\"Skipping plotting: Multivariate Normal with dimension {samples.shape[1]}.\")\n",
    "            return\n",
    "        \n",
    "    else:\n",
    "        # Standard 1D histogram + KDE\n",
    "        plt.hist(samples, bins=50, alpha=0.5, density=True, color='blue', edgecolor='black', label=\"Histogram\")\n",
    "        sns.kdeplot(samples, color='red', lw=2, label=\"KDE\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Sample Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def generate_iid_samples(posterior_type = None, num_samples=2000, rng=None,**params):\n",
    "    \"\"\"\n",
    "    Generate IID samples from a mixture distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "    - component_params: List of dictionaries with parameters for each component.\n",
    "    - num_samples: Number of samples to generate.\n",
    "    - weights: List of weights for the components.\n",
    "    - rng: Random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - iid_samples: Array of generated IID samples.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = rng or np.random.default_rng()\n",
    "\n",
    "    # Mapping from string names to scipy sampling functions\n",
    "    scipy_distributions = {\n",
    "        \"Normal\": lambda p: sp.norm.rvs(loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"StudentT\": lambda p: sp.t.rvs(df=p[\"nu\"], loc=p[\"mu\"], scale=p[\"sigma\"], size=num_samples, random_state=rng),\n",
    "        \"Beta\": lambda p: sp.beta.rvs(a=p[\"a\"], b=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"Cauchy\": lambda p: sp.cauchy.rvs(loc=p[\"loc\"], scale=p[\"scale\"], size=num_samples, random_state=rng),\n",
    "        \"Laplace\": lambda p: sp.laplace.rvs(loc=p[\"mu\"], scale=p[\"b\"], size=num_samples, random_state=rng),\n",
    "        \"MvNormal\": lambda p: rng.multivariate_normal(mean=np.array(p[\"mu\"]), cov=np.array(p[\"cov\"]), size=num_samples),\n",
    "    }\n",
    "\n",
    "    # Handle Skewed Student-T (which needs PyMC)\n",
    "    if posterior_type == \"SkewStudentT\":\n",
    "        with pm.Model():\n",
    "            skewed_t = pm.SkewStudentT.dist(a=params[\"a\"], b=params[\"b\"], mu=params[\"mu\"], sigma=params[\"sigma\"])\n",
    "            return pm.draw(skewed_t, draws=num_samples, random_seed=rng)\n",
    "\n",
    "    # Handle single distributions\n",
    "    if posterior_type in scipy_distributions:\n",
    "        print(f\"Generating {posterior_type} samples...\", params)\n",
    "        return scipy_distributions[posterior_type](params)\n",
    "\n",
    "    elif posterior_type == \"Mixture\":\n",
    "        component_types = params[\"component_types\"]\n",
    "        component_params = params[\"component_params\"]\n",
    "        weights = params[\"weights\"]\n",
    "\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        # normalize weights\n",
    "        weights = np.array(weights) / np.sum(weights)\n",
    "\n",
    "        # Choose which component each sample belongs to based on weights\n",
    "        chosen_components = rng.choice(len(component_types), size=num_samples, p=weights)\n",
    "\n",
    "        posterior_dim = None  \n",
    "\n",
    "        # Check if all components have the same dimension\n",
    "        for comp_params in component_params:\n",
    "            first_param = next(iter(comp_params))  # Get first parameter of current component\n",
    "            first_value = comp_params[first_param]  # Get its value\n",
    "            comp_dim = len(first_value) if isinstance(first_value, (np.ndarray, list)) else 1 # Get dimensionality of the first parameter\n",
    "\n",
    "            if posterior_dim is None:\n",
    "                posterior_dim = comp_dim  # Set the posterior dimension based on the first component\n",
    "               \n",
    "            elif comp_dim != posterior_dim:\n",
    "                raise ValueError(\"All mixture components must have the same dimensionality.\")\n",
    "\n",
    "        if posterior_dim > 1:\n",
    "            iid_samples = np.empty((num_samples, posterior_dim))  # Multivariate case\n",
    "        else:\n",
    "            iid_samples = np.empty(num_samples)\n",
    "\n",
    "        for i, (comp_type, comp_params) in enumerate(zip(component_types, component_params)):\n",
    "            mask = chosen_components == i  # Select samples for this component\n",
    "            num_selected = mask.sum()\n",
    "            if num_selected > 0:\n",
    "                if comp_type in scipy_distributions or comp_type == \"SkewStudentT\":\n",
    "                    iid_samples[mask] = generate_iid_samples(posterior_type=comp_type, num_samples=num_selected, rng=rng, **comp_params)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported component type in IID sampling: {comp_type}\")\n",
    "                \n",
    "        return iid_samples\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported posterior type: {posterior_type}\")\n",
    "\n",
    "\n",
    "def extract_means_from_components(component_params):\n",
    "    \"\"\"\n",
    "    Extracts central tendency (mu or loc) from each component's parameters.\n",
    "    \"\"\"\n",
    "    means = []\n",
    "    for params in component_params:\n",
    "        if \"mu\" in params:\n",
    "            means.append(params[\"mu\"])\n",
    "        elif \"loc\" in params:\n",
    "            means.append(params[\"loc\"])\n",
    "        else:\n",
    "            raise ValueError(\"Component missing a central tendency parameter (mu or loc).\")\n",
    "    return means\n",
    "\n",
    "\n",
    "def get_initvals(init_scheme, means, num_chains, rng=None):\n",
    "    \"\"\"Generates initialization values based on the chosen scheme.\"\"\"\n",
    "\n",
    "    if init_scheme == \"equal_per_mode\":\n",
    "        initvals = [{\"mixed_post_var\": means[i % len(means)]} for i in range(num_chains)]\n",
    "\n",
    "\n",
    "    elif init_scheme == \"all_in_middle\":\n",
    "        means_array = np.array(means)\n",
    "        middle_point = np.mean(means_array, axis=0)\n",
    "        initvals = [{\"mixed_post_var\": middle_point} for _ in range(num_chains)]\n",
    "\n",
    "    elif init_scheme == \"random\":\n",
    "        means_array = np.array(means)\n",
    "        if means_array.shape[0] < 2:\n",
    "            raise ValueError(\"random init_scheme requires at least 2 modes.\")\n",
    "            \n",
    "        # Compute bounding box across all dimensions\n",
    "        min_mode = np.min(means_array, axis=0)\n",
    "        max_mode = np.max(means_array, axis=0)\n",
    "        border = (max_mode - min_mode) / len(means)\n",
    "\n",
    "        low = min_mode - border\n",
    "        high = max_mode + border\n",
    "\n",
    "        initvals = [\n",
    "            {\"mixed_post_var\": rng.uniform(low, high)}\n",
    "            for _ in range(num_chains)\n",
    "        ]\n",
    "\n",
    "\n",
    "    elif init_scheme.startswith(\"all_near_mode_\"):\n",
    "        try:\n",
    "            mode_index = int(init_scheme.split(\"_\")[-1])\n",
    "            if mode_index >= len(means):\n",
    "                raise IndexError(f\"Mode index {mode_index} out of bounds for available means.\")\n",
    "            initvals = [{\"mixed_post_var\": means[mode_index]} for _ in range(num_chains)]\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Invalid mode index in init_scheme: '{init_scheme}'\")\n",
    "\n",
    "    print(f\"Initvals: {initvals}\")\n",
    "\n",
    "    return initvals\n",
    "\n",
    "\n",
    "def sliced_wasserstein_distance(X, Y, L=100):\n",
    "    \"\"\"\n",
    "    Computes the sliced Wasserstein distance (SWD_p) between two sets of samples.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: numpy array of shape (N, d) -> first sample set\n",
    "    - Y: numpy array of shape (N, d) -> second sample set\n",
    "    - L: int, number of random projections\n",
    "    - p: int, order of Wasserstein distance (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "    - SWD_p: float, the sliced Wasserstein distance\n",
    "    \"\"\"\n",
    "    \n",
    "    #X = X.reshape(-1, 1)\n",
    "    #Y = Y.reshape(-1, 1)\n",
    "    # Ensure X and Y are at least 2D\n",
    "\n",
    "    N, d = X.shape  # Assuming X and Y have the same shape\n",
    "    S = 0  # Accumulation variable\n",
    "\n",
    "    for _ in range(L):\n",
    "        # Sample a random unit vector (projection direction)\n",
    "        theta = np.random.randn(d)\n",
    "        theta /= np.linalg.norm(theta)  # Normalize to unit sphere\n",
    "\n",
    "        # Compute projections\n",
    "        alpha = X @ theta\n",
    "        beta = Y @ theta\n",
    "\n",
    "        # Compute 1D Wasserstein distance\n",
    "        W_i = sp.wasserstein_distance(alpha, beta)\n",
    "\n",
    "        # Accumulate\n",
    "        S += W_i\n",
    "\n",
    "    # Compute final SWD\n",
    "    SWD_p = (S / L) \n",
    "\n",
    "    return SWD_p\n",
    "\n",
    "\n",
    "class PosteriorExample:\n",
    "    \"\"\"Base class for different posterior types.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None  # Placeholder for the PyMC model\n",
    "    \n",
    "    def _define_posterior(self):\n",
    "        \"\"\"Subclasses should implement this method to define the posterior.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement _define_posterior()\")\n",
    "\n",
    "    def run_sampling(self, sampler_name, num_samples=2000, tune=1000, num_chains=2, initvals=None, init_scheme=None, run_random_seed=None):\n",
    "        \"\"\"Runs MCMC sampling using the chosen sampler.\"\"\"\n",
    "        \n",
    "        with self.model:\n",
    "\n",
    "            # Define which sampler to use\n",
    "            if sampler_name == \"Metro\":\n",
    "                sampler = pm.Metropolis()\n",
    "            elif sampler_name == \"HMC\":\n",
    "                sampler = pm.NUTS()\n",
    "            elif sampler_name == \"DEMetro\":\n",
    "                sampler = pm.DEMetropolis()\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown sampler: {sampler_name}\")\n",
    "           \n",
    "            if init_scheme != None:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler,initvals=initvals, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)    #initvals=initvals,\n",
    "            else:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)\n",
    "        \n",
    "        return trace\n",
    "\n",
    "\n",
    "class SinglePosterior(PosteriorExample):\n",
    "    def __init__(self, dist_name, dist_params):\n",
    "        \"\"\"\n",
    "        A flexible class for defining unimodal posteriors.\n",
    "\n",
    "        Parameters:\n",
    "        - dist_name: String specifying the name of the PyMC distribution (e.g., \"Normal\", \"StudentT\").\n",
    "        - dist_params: Dictionary containing the parameters for the distribution.\n",
    "        \"\"\"\n",
    "        self.dist_name = dist_name\n",
    "        self.dist_params = dist_params\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        \n",
    "        dist_class = getattr(pm, self.dist_name)   # Retrieve the distribution class from PyMC\n",
    "        \n",
    "        with pm.Model() as model:\n",
    "            posterior_var = dist_class(\"posterior_var\", **self.dist_params)\n",
    "        return model\n",
    "\n",
    "\n",
    "class MixturePosterior(PosteriorExample):\n",
    "    \n",
    "    def __init__(self, component_types, component_params, weights=None, varying_component=None): \n",
    "        \"\"\"\n",
    "        A flexible mixture posterior allowing any number of components and arbitrary distributions.\n",
    "\n",
    "        Parameters:\n",
    "        - component_types: List of strings specifying the type of each component (e.g., [\"normal\", \"beta\"]).\n",
    "        - component_params: List of dictionaries, where each dictionary contains the parameters for the corresponding distribution.\n",
    "        - weights: List of weights for the mixture components (defaults to uniform).\n",
    "        \"\"\"\n",
    "        if len(component_types) != len(component_params):\n",
    "            raise ValueError(\"Each component type must have a corresponding parameter dictionary.\")\n",
    "\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(component_types))  # Default: Equal weights\n",
    "\n",
    "        if len(weights) != len(component_types):\n",
    "            raise ValueError(\"Number of weights must match number of components.\")\n",
    "\n",
    "        self.component_types = component_types\n",
    "        self.component_params = component_params\n",
    "        self.weights = weights\n",
    "\n",
    "        # Normalize weights\n",
    "        self.weights = np.array(self.weights) / np.sum(self.weights)\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        \n",
    "        # Construct component distributions dynamically\n",
    "        components = []\n",
    "        for dist_type, params in zip(self.component_types, self.component_params):\n",
    "            try:\n",
    "                dist_class = getattr(pm, dist_type)  # Retrieve PyMC distribution dynamically\n",
    "                components.append(dist_class.dist(**params))  # Use `.dist()` to create distribution\n",
    "            except AttributeError:\n",
    "                raise ValueError(f\"Unsupported distribution type: {dist_type}\")\n",
    "            \n",
    "        # Define the mixture model    \n",
    "        with pm.Model() as model:\n",
    "            # Mixture model\n",
    "            mixed_post_var = pm.Mixture(\"mixed_post_var\", w=self.weights, comp_dists=components)\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "class CustomPosterior(PosteriorExample):\n",
    "    \"\"\"\n",
    "    A flexible class to define custom posteriors using a user-specified log-probability function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logp_func):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - logp_func: Callable function that defines the log-probability.\n",
    "                     Must accept PyMC symbolic variables.\n",
    "        - param_names: List of parameter names required by logp_func.\n",
    "        - initvals: Optional dictionary for initial values.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.logp_func = logp_func\n",
    "        self.model = self._define_posterior()\n",
    "\n",
    "    def _define_posterior(self):\n",
    "        with pm.Model() as model:\n",
    "\n",
    "            # Define the custom distribution using pm.CustomDist\n",
    "            custom_var = pm.CustomDist(\"cust_var\", logp=self.logp_func, shape=(2,))\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "def run_experiment(\n",
    "    experiment_settings,\n",
    "    posterior_type,\n",
    "    config_descr,\n",
    "    runs,\n",
    "    varying_attribute, \n",
    "    varying_values,      \n",
    "    num_samples,\n",
    "    num_chains,\n",
    "    init_scheme=None,\n",
    "    base_random_seed=None,\n",
    "    progress_bar=None,\n",
    "    **posterior_kwargs\n",
    "):\n",
    "    print(f\"\\n===== Config {config_descr} started! =====\\n\")\n",
    "\n",
    "    # Initialize random number generator\n",
    "    rng = np.random.default_rng(base_random_seed)\n",
    "\n",
    "    # Define required parameters for each posterior type\n",
    "    required_parameters = {\n",
    "        \"Mixture\": [\"component_types\", \"component_params\", \"weights\"],\n",
    "        \"Cauchy\": [\"loc\", \"scale\"],\n",
    "        \"Beta\": [\"a\", \"b\"],\n",
    "        \"Normal\": [\"mu\", \"sigma\"],\n",
    "        \"StudentT\": [\"nu\", \"mu\", \"sigma\"],\n",
    "        \"SkewStudentT\": [\"a\", \"b\", \"mu\", \"sigma\"],\n",
    "        \"Laplace\": [\"mu\", \"b\"],\n",
    "        \"MvNormal\": [\"mu\", \"cov\"],\n",
    "        \"Custom\": []\n",
    "    }\n",
    "\n",
    "    # Validate that required keys exist (except for varying attributes)\n",
    "    required_keys = [k for k in required_parameters.get(posterior_type) if k != varying_attribute]\n",
    "    if not all(k in posterior_kwargs for k in required_keys):\n",
    "        raise ValueError(f\"{posterior_type} posterior requires {required_keys}\")\n",
    "\n",
    "    # Create keyword arguments for IID sample generation\n",
    "    iid_kwargs = {key: posterior_kwargs.get(key, \"varies\") for key in required_parameters.get(posterior_type)}\n",
    "\n",
    "    print(f\"Using IID sample settings: {iid_kwargs}\")\n",
    "\n",
    "    # Create configuration and histogram folders inside the experiment root\n",
    "    config_folder = os.path.join(experiment_root_folder, f\"{config_descr}_with_{runs}_runs\")\n",
    "    iid_histogram_folder = os.path.join(config_folder, \"KDE and Histograms of IID Samples\")\n",
    "    create_directories(config_folder, iid_histogram_folder)\n",
    "\n",
    "    # === Handle Precomputed IID Samples for Varying Attributes ===\n",
    "    iid_samples_dict = {}\n",
    "\n",
    "    if posterior_type == \"Mixture\":\n",
    "        component_index = posterior_kwargs.get(\"varying_component\")  # Get the selected component\n",
    "\n",
    "        if component_index is None and varying_attribute not in [\"num_samples\", \"num_chains\", \"init_scheme\"]:\n",
    "            raise ValueError(f\"`varying_component` must be specified when varying '{varying_attribute}' in a Mixture.\")\n",
    "\n",
    "        # Loop through all varying values for Mixture posterior\n",
    "        for value in varying_values:\n",
    "\n",
    "            iid_kwargs[\"component_params\"][component_index][varying_attribute] = value\n",
    "            print(f\"Updating component {component_index} with {varying_attribute} = {value}\")\n",
    "\n",
    "            iid_samples_dict[value] = generate_iid_samples(\n",
    "                posterior_type=posterior_type,\n",
    "                component_types=iid_kwargs[\"component_types\"],\n",
    "                component_params=iid_kwargs[\"component_params\"], \n",
    "                weights=iid_kwargs[\"weights\"],\n",
    "                num_samples=num_samples,\n",
    "                rng=rng\n",
    "            )\n",
    "\n",
    "            # Plot histogram and KDE for each varying value\n",
    "            plot_histogram(\n",
    "                samples=iid_samples_dict[value],\n",
    "                title=f\"IID Samples Histogram & KDE ({varying_attribute}={value})\",\n",
    "                save_path=os.path.join(iid_histogram_folder, f\"iid_hist_kde_{varying_attribute}_{value}.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "            )\n",
    "\n",
    "\n",
    "    elif posterior_type == \"Custom\":\n",
    "        # Skip generating any IID samples here.\n",
    "        pass\n",
    "        \n",
    "\n",
    "    # Single posterior case\n",
    "    elif varying_attribute in iid_kwargs or varying_attribute == \"num_samples\":\n",
    "        for value in varying_values:\n",
    "            if varying_attribute == \"num_samples\":\n",
    "                current_num_samples = value  \n",
    "            else:\n",
    "                iid_kwargs[varying_attribute] = value  \n",
    "                current_num_samples = num_samples  \n",
    "            \n",
    "            iid_samples_dict[value] = generate_iid_samples(\n",
    "                posterior_type=posterior_type,\n",
    "                **iid_kwargs,\n",
    "                num_samples=current_num_samples,\n",
    "                rng=rng\n",
    "            )\n",
    "\n",
    "            # Plot histogram and KDE for each varying value\n",
    "            plot_histogram(\n",
    "                samples=iid_samples_dict[value],\n",
    "                title=f\"IID Samples Histogram & KDE ({varying_attribute}={value})\",\n",
    "                save_path=os.path.join(iid_histogram_folder, f\"iid_hist_kde_{varying_attribute}_{value}.pdf\"),\n",
    "                posterior_type=posterior_type\n",
    "            )\n",
    "\n",
    "    # Fixed posterior case (no varying attributes)\n",
    "    else:\n",
    "        iid_samples = generate_iid_samples(\n",
    "            posterior_type=posterior_type,\n",
    "            **iid_kwargs,\n",
    "            num_samples=num_samples,\n",
    "            rng=rng\n",
    "        )\n",
    "\n",
    "        plot_histogram(\n",
    "            samples=iid_samples,\n",
    "            title=\"IID Samples Histogram & KDE (fixed posterior)\",\n",
    "            save_path=os.path.join(iid_histogram_folder, \"iid_hist_kde.pdf\"),\n",
    "            posterior_type=posterior_type\n",
    "        )\n",
    "\n",
    "\n",
    "    # === Experiment Setup ===\n",
    "    samples_per_chain = \"varies\" if varying_attribute in [\"num_samples\", \"num_chains\"] else num_samples // num_chains\n",
    "\n",
    "    experiment_metadata = {\n",
    "        \"config_descr\": config_descr,\n",
    "        \"runs\": runs,\n",
    "        \"posterior_type\": posterior_type,\n",
    "        \"varying_attribute\": varying_attribute,\n",
    "        \"varying_values\": varying_values,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"num_chains\": num_chains,\n",
    "        \"samples_per_chain\": samples_per_chain,\n",
    "        \"init_scheme\": init_scheme,\n",
    "        \"base_random_seed\": base_random_seed,\n",
    "        \"git_tag\": get_git_tag(),\n",
    "    }\n",
    "    experiment_metadata.update(iid_kwargs)  # Add posterior-specific parameters\n",
    "\n",
    "    # Save metadata\n",
    "    metadata_filename = os.path.join(config_folder, f\"metadata_config_{config_descr}.json\")\n",
    "    with open(metadata_filename, \"w\") as f:\n",
    "        json.dump(experiment_metadata, f, indent=4)\n",
    "\n",
    "    # Define fixed colors for each sampler\n",
    "    sampler_colors = {\n",
    "        \"Metro\": \"blue\",\n",
    "        \"HMC\": \"red\",\n",
    "        \"DEMetro\": \"green\"\n",
    "    }\n",
    "\n",
    "    # === Run the Experiment ===\n",
    "    for run_id in range(1, runs + 1):\n",
    "        print(f\"\\n===== Running {config_descr} - Run {run_id} =====\\n\")\n",
    "\n",
    "        run_random_seed = int(rng.integers(1_000_000))\n",
    "\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "        traces_folder = os.path.join(run_folder, \"traces_and_trace_plots\")\n",
    "        plots_folder = os.path.join(run_folder, \"plots_of_run\")\n",
    "        \n",
    "\n",
    "        create_directories(run_folder, results_folder, traces_folder, plots_folder)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for value in varying_values:\n",
    "\n",
    "            var_attr_folder = os.path.join(traces_folder, f\"{varying_attribute}_{value}\")\n",
    "            create_directories(var_attr_folder)\n",
    "\n",
    "            # Handle parameter changes for Mixture case\n",
    "            if posterior_type == \"Mixture\":\n",
    "                component_index = posterior_kwargs.get(\"varying_component\")\n",
    "                if component_index is None and varying_attribute not in [\"num_samples\", \"num_chains\", \"init_scheme\"]:\n",
    "                    raise ValueError(f\"`varying_component` must be specified when varying '{varying_attribute}' in a Mixture.\")\n",
    "\n",
    "                # Modify only the selected component\n",
    "                posterior_kwargs[\"component_params\"][component_index][varying_attribute] = value\n",
    "            \n",
    "            else:\n",
    "                if varying_attribute in iid_kwargs:\n",
    "                    posterior_kwargs[varying_attribute] = value\n",
    "            \n",
    "            if varying_attribute == \"num_samples\":\n",
    "                num_samples = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"num_chains\":\n",
    "                num_chains = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"init_scheme\":\n",
    "                init_scheme = value\n",
    "\n",
    "            if posterior_type == \"Mixture\":\n",
    "                model = MixturePosterior(**posterior_kwargs)\n",
    "            elif posterior_type == \"Custom\":\n",
    "                logp_func = posterior_kwargs[\"logp_func\"]\n",
    "                model = CustomPosterior(logp_func=logp_func)\n",
    "            else:\n",
    "                model = SinglePosterior(dist_name=posterior_type, dist_params=posterior_kwargs)\n",
    "\n",
    "            # Generate initialization values\n",
    "            if posterior_type == \"Mixture\" and init_scheme is not None:\n",
    "                means = extract_means_from_components(posterior_kwargs[\"component_params\"])\n",
    "                initvals = get_initvals(init_scheme, means, num_chains, rng)\n",
    "            else:\n",
    "                initvals = None\n",
    "           \n",
    "\n",
    "            # Get IID samples for the current varying value\n",
    "            if posterior_type != \"Custom\" and varying_attribute not in [\"init_scheme\", \"num_chains\"]:\n",
    "                iid_samples = iid_samples_dict[value]\n",
    "            elif posterior_type == \"Custom\":\n",
    "                iid_samples = None\n",
    "\n",
    "\n",
    "            # Run sampling for all samplers\n",
    "            for sampler_name in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "                \n",
    "                if posterior_type == \"Mixture\":\n",
    "                    print(f\"Running {sampler_name} with {varying_attribute} = {value} (Component {component_index})\")\n",
    "                else:\n",
    "                    print(f\"Running {sampler_name} with {varying_attribute} = {value}\")\n",
    "\n",
    "                # **Measure Computation Time**\n",
    "                start_time = time.time()\n",
    "                trace = model.run_sampling(\n",
    "                    sampler_name, num_samples=samples_per_chain, num_chains=num_chains, init_scheme=init_scheme,\n",
    "                    initvals = initvals, run_random_seed=run_random_seed\n",
    "                )\n",
    "                end_time = time.time()\n",
    "                runtime = end_time - start_time\n",
    "\n",
    "                # Plot trace plots in notebook if requested\n",
    "                if experiment_settings.get(\"plot_traces_in_notebook\", False):\n",
    "                    az.plot_trace(trace, compact=True)\n",
    "                    plt.title(f\"Trace Plot ({sampler_name}, {varying_attribute} = {value})\")\n",
    "                    plt.show()\n",
    "                \n",
    "\n",
    "                # Save trace to NetCDF file if requested\n",
    "                if experiment_settings.get(\"save_traces\", False):\n",
    "                    trace_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace.nc\")\n",
    "                    az.to_netcdf(trace, trace_filename)\n",
    "\n",
    "                trace_plot_mode = experiment_settings.get(\"trace_plots\", \"none\")\n",
    "\n",
    "                # Save trace plots to PDF if requested\n",
    "                if trace_plot_mode == \"all\" or (trace_plot_mode == \"first_run_only\" and run_id == 1):\n",
    "                    trace_plot_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace_plot.pdf\")\n",
    "                    az.plot_trace(trace, compact=True)\n",
    "                    plt.savefig(trace_plot_filename, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "\n",
    "                # Select correct posterior variable name\n",
    "                if posterior_type == \"Mixture\":\n",
    "                    post_var_name = \"mixed_post_var\"\n",
    "                elif posterior_type == \"SinglePosterior\":\n",
    "                    post_var_name = \"posterior_var\"\n",
    "                elif posterior_type == \"Custom\":\n",
    "                    post_var_name = \"cust_var\"\n",
    "\n",
    "                posterior_samples = trace.posterior[post_var_name].values\n",
    "        \n",
    "                # Ensure posterior_samples always has shape (N, dims)\n",
    "                if posterior_samples.ndim == 2:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, 1) \n",
    "                else:\n",
    "                    posterior_samples = posterior_samples.reshape(-1, posterior_samples.shape[-1])\n",
    "\n",
    "\n",
    "                if iid_samples is not None:\n",
    "                    # Ensure iid_samples always has shape (N, dims)\n",
    "                    if iid_samples.ndim == 1:\n",
    "                        iid_samples = iid_samples[:, np.newaxis]\n",
    "                    else:\n",
    "                        iid_samples = iid_samples.reshape(-1, iid_samples.shape[-1])\n",
    "                    \n",
    "\n",
    "                # Only compute Wasserstein distance if we have iid_samples\n",
    "                if posterior_type != \"Custom\":\n",
    "                    ws_distance = sliced_wasserstein_distance(posterior_samples, iid_samples, L=5)\n",
    "                else:\n",
    "                    ws_distance = np.nan \n",
    " \n",
    "                # Compute R-hat and ESS\n",
    "                r_hat = az.rhat(trace)[post_var_name].max().item()\n",
    "                ess = az.ess(trace)[post_var_name].min().item()\n",
    "\n",
    "                results.append({\n",
    "                    varying_attribute: value,\n",
    "                    \"sampler\": sampler_name,\n",
    "                    \"wasserstein_distance\": ws_distance,\n",
    "                    \"r_hat\": r_hat,\n",
    "                    \"ess\": ess,\n",
    "                    \"runtime\": runtime\n",
    "                })\n",
    "\n",
    "        # Convert results to DataFrame and save\n",
    "        df_results = pd.DataFrame(results)\n",
    "\n",
    "        # Handle tuple-based attributes consistently\n",
    "        if isinstance(df_results[varying_attribute].iloc[0], tuple):\n",
    "            df_results[varying_attribute] = df_results[varying_attribute].apply(str)\n",
    "            varying_attribute_for_plot = varying_attribute\n",
    "        else:\n",
    "            varying_attribute_for_plot = varying_attribute\n",
    "\n",
    "        # Sort the DataFrame by the final chosen attribute\n",
    "        df_results = df_results.sort_values(varying_attribute_for_plot, ascending=True)\n",
    "\n",
    "        plot_and_save_all_metrics(\n",
    "            df_results=df_results,\n",
    "            sampler_colors=sampler_colors,\n",
    "            varying_attribute=varying_attribute,\n",
    "            varying_attribute_for_plot=varying_attribute_for_plot,\n",
    "            results_folder=results_folder,\n",
    "            plots_folder=plots_folder,\n",
    "            run_id=run_id,\n",
    "            config_descr=config_descr\n",
    "        )\n",
    "\n",
    "        # Now increment the TQDM progress bar if it's provided\n",
    "        if progress_bar is not None:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    print(\"\\n===== All Runs Completed Successfully! =====\\n\")\n",
    "\n",
    "    # ===== GLOBAL RESULTS FOLDER =====\n",
    "    global_folder = os.path.join(config_folder, \"global_results\")\n",
    "    global_results_folder = os.path.join(global_folder, \"results\")\n",
    "    global_plots_folder = os.path.join(global_folder, \"plots\")\n",
    "    create_directories(global_folder, global_results_folder, global_plots_folder)\n",
    "\n",
    "    # Collect all results from all runs\n",
    "    df_all_runs = []\n",
    "\n",
    "    for run_id in range(1, runs + 1):\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "\n",
    "        for sampler in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "            csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "            df_run = pd.read_csv(csv_filename)\n",
    "            df_run[\"run_id\"] = run_id \n",
    "            df_run[\"sampler\"] = sampler  \n",
    "            df_all_runs.append(df_run)\n",
    "\n",
    "\n",
    "    # Combine all results into a single data frame \n",
    "    df_all_runs = pd.concat(df_all_runs, ignore_index=True)\n",
    "\n",
    "    compute_and_save_global_metrics(\n",
    "        df_all_runs=df_all_runs,\n",
    "        sampler_colors=sampler_colors,\n",
    "        varying_attribute=varying_attribute,\n",
    "        runs=runs,\n",
    "        config_descr=config_descr,\n",
    "        global_results_folder=global_results_folder,\n",
    "        global_plots_folder=global_plots_folder\n",
    "    )\n",
    "\n",
    "    print(f\"\\n===== Config {config_descr} Completed Successfully! =====\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ring_logp_numpy(x, y):\n",
    "    \"\"\"\n",
    "    NumPy-Version der Ring-Log-Dichte:\n",
    "    x, y können auch Arrays sein.\n",
    "    \"\"\"\n",
    "    r0 = 3.0\n",
    "    sigma = 0.5\n",
    "    radius = np.sqrt(x**2 + y**2)\n",
    "    return -0.5 * ((radius - r0) / sigma)**2\n",
    "\n",
    "# Gitter anlegen: z.B. von -6 bis +6 mit 200 Schritten\n",
    "xs = np.linspace(-6, 6, 200)\n",
    "ys = np.linspace(-6, 6, 200)\n",
    "X, Y = np.meshgrid(xs, ys)\n",
    "\n",
    "# Logp auf dem gesamten Gitter berechnen\n",
    "Z = ring_logp_numpy(X, Y)\n",
    "\n",
    "# Konturplot\n",
    "plt.figure(figsize=(7, 6))\n",
    "cs = plt.contourf(X, Y, Z, levels=30, cmap=\"viridis\")\n",
    "plt.colorbar(cs, label=\"Log-Dichte\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Log-Dichte des Ring-Datensatzes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def validate_config(config):\n",
    "    \"\"\"Checks if the config correctly defines one varying attribute and all other attributes are fixed.\"\"\"\n",
    "    \n",
    "    REQUIRED_ATTRIBUTES = {\n",
    "    \"config_descr\",\n",
    "    \"posterior_type\",\n",
    "    \"runs\",\n",
    "    \"num_samples\",\n",
    "    \"num_chains\",\n",
    "    \"varying_attribute\",\n",
    "    \"varying_values\",\n",
    "    }\n",
    "\n",
    "    # Posterior-specific required attributes\n",
    "    POSTERIOR_ATTRIBUTES = {\n",
    "        \"Cauchy\": {\"loc\", \"scale\"},\n",
    "        \"Beta\": {\"a\", \"b\"},\n",
    "        \"Normal\": {\"mu\", \"sigma\"},\n",
    "        \"StudentT\": {\"nu\", \"mu\", \"sigma\"},\n",
    "        \"Laplace\": {\"mu\", \"b\"},\n",
    "        \"SkewStudentT\": {\"a\", \"b\", \"mu\", \"sigma\"},\n",
    "        \"Mixture\": {\"component_types\", \"component_params\", \"weights\"},\n",
    "        \"MvNormal\": {\"mu\", \"cov\"},\n",
    "        \"Custom\": {\"logp_func\"}\n",
    "    }\n",
    "\n",
    "    OPTIONAL_ATTRIBUTES = {\"base_random_seed\", \"init_scheme\", \"varying_component\"}\n",
    "\n",
    "    if \"config_descr\" not in config:\n",
    "        raise ValueError(\"Config is missing 'config_descr'.\")\n",
    "    \n",
    "    config_descr = config[\"config_descr\"]\n",
    "\n",
    "    if \"varying_attribute\" not in config:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing 'varying_attribute'.\")\n",
    "    \n",
    "    varying_attr = config[\"varying_attribute\"]\n",
    "\n",
    "    # Ensure all required attributes are present\n",
    "    missing_attrs = REQUIRED_ATTRIBUTES - config.keys() - {varying_attr}\n",
    "\n",
    "    if missing_attrs:\n",
    "        raise ValueError(f\"Config '{config_descr}' is missing required attributes: {missing_attrs}.\")\n",
    "    \n",
    "    posterior_type = config[\"posterior_type\"]\n",
    "\n",
    "    if posterior_type not in POSTERIOR_ATTRIBUTES:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'posterior_type': '{posterior_type}'.\")\n",
    "\n",
    "    if posterior_type == \"Mixture\" and \"varying_component\" in config:\n",
    "        varying_index = config[\"varying_component\"]\n",
    "        varying_component = config[\"component_types\"][varying_index]\n",
    "        all_valid_attributes = REQUIRED_ATTRIBUTES.union(POSTERIOR_ATTRIBUTES[posterior_type], POSTERIOR_ATTRIBUTES[varying_component], OPTIONAL_ATTRIBUTES)\n",
    "        print(all_valid_attributes)\n",
    "\n",
    "    else:\n",
    "        # Ensure varying_attribute is a recognized attribute\n",
    "        all_valid_attributes = REQUIRED_ATTRIBUTES.union(POSTERIOR_ATTRIBUTES[posterior_type], OPTIONAL_ATTRIBUTES)\n",
    "\n",
    "    if varying_attr not in all_valid_attributes:\n",
    "        raise ValueError(f\"Config '{config_descr}' has an invalid 'varying_attribute': '{varying_attr}'.\")\n",
    "        \n",
    "    if posterior_type == \"Mixture\" and varying_attr not in (\"num_samples\", \"num_chains\", \"init_scheme\"):\n",
    "        if \"varying_component\" not in config:\n",
    "            raise ValueError(\n",
    "                f\"Config '{config_descr}' must have 'varying_component' defined \"\n",
    "                f\"when varying '{varying_attr}' for a Mixture.\"\n",
    "            )\n",
    "        \n",
    "    vc = config.get(\"varying_component\")    \n",
    "    if vc is not None and not (0 <= vc < len(config[\"component_types\"])):\n",
    "        raise ValueError(\n",
    "            f\"Config '{config_descr}' has invalid 'varying_component' index {vc}, \"\n",
    "            f\"but 'component_types' has length {len(config['component_types'])}.\"\n",
    "        )\n",
    "    \n",
    "    VALID_INIT_SCHEMES = {\"equal_per_mode\", \"random\", \"all_in_middle\"} \n",
    "\n",
    "    if \"init_scheme\" in config:\n",
    "        if config[\"init_scheme\"] not in VALID_INIT_SCHEMES and not config[\"init_scheme\"].startswith(\"all_near_mode_\"):\n",
    "            raise ValueError(\n",
    "                f\"Config '{config_descr}' has invalid 'init_scheme': \"\n",
    "                f\"'{config['init_scheme']}'. Must be one of {VALID_INIT_SCHEMES} \"\n",
    "                \"or 'all_near_mode_<int>'.\"\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "# to do: if init_schme is present, check that it is a valid init scheme\n",
    "\n",
    "# posterior_type = \"Cauchy\", \"Beta\", \"Normal\", \"StudentT\", \"Laplace\", \"SkewstudentT\"\n",
    "# varying_attribute = \"num_samples\", \"num_chains\", \"init_scheme\" or posterior specific attribute\n",
    "# bimmodal specific attributes = \"mode_means\", \"std_of_modes\", \"weights\"\n",
    "# cauchy specific attributes = \"loc\", \"scale\"\n",
    "# beta specific attributes = \"a\", \"b\"\n",
    "# normal specific attributes = \"mu\", \"sigma\"\n",
    "# student_t specific attributes = \"nu\", \"mu\", \"sigma\"\n",
    "# laplace specific attributes = \"mu\", \"b\"\n",
    "# skewed_student_t specific attributes = \"a\", \"b\", \"mu\", \"sigma\"\n",
    "# all but the varying attribute must be fixed and present in the config\n",
    "\n",
    "def my_custom_logp_function(x):\n",
    "    w1, w2 = 0.4, 0.6\n",
    "    mu1, mu2 = -2, 2\n",
    "    sigma1, sigma2 = 1, 1\n",
    "\n",
    "    log_like1 = pm.logp(pm.Normal.dist(mu=mu1, sigma=sigma1), x)\n",
    "    log_like2 = pm.logp(pm.Normal.dist(mu=mu2, sigma=sigma2), x)\n",
    "\n",
    "    return pm.math.logsumexp([np.log(w1) + log_like1, np.log(w2) + log_like2])\n",
    "\n",
    "def ring_logp(value):\n",
    "    \"\"\"\n",
    "    Defines the log-prob of a point in 2D:\n",
    "    - value is shape (2,), where value[0] = x, value[1] = y.\n",
    "    - We place mass around a circle of radius r0 with thickness sigma.\n",
    "    \"\"\"\n",
    "\n",
    "    x = value[0]\n",
    "    y = value[1]\n",
    "    r0 = 3.0       # ring center radius\n",
    "    sigma = 0.5    # ring thickness\n",
    "\n",
    "    # radial distance from origin:\n",
    "    radius = pt.sqrt(x**2 + y**2)\n",
    "\n",
    "    # negative half-squared difference from the ring radius:\n",
    "    logp_val = -0.5 * ((radius - r0) / sigma) ** 2\n",
    "\n",
    "    # No normalizing constant needed for MCMC\n",
    "    return logp_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# default attributes\n",
    "default_num_samples = 2000\n",
    "default_num_chains = 4\n",
    "default_base_random_seed = 42\n",
    "default_runs = 3\n",
    "\n",
    "\n",
    "custom_test = [\n",
    "\n",
    "    {\n",
    "            \"config_descr\": \"Custom_mixture_normals\",\n",
    "            \"posterior_type\": \"Custom\",\n",
    "            \"runs\": default_runs,\n",
    "            \"num_chains\": default_num_chains,\n",
    "            \"base_random_seed\": default_base_random_seed,\n",
    "            \"logp_func\": my_custom_logp_function,\n",
    "            \"varying_attribute\": \"num_samples\",\n",
    "            \"varying_values\": [2000, 2500, 3000, 10000],\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "custom_ring_test = [\n",
    "\n",
    "    {\n",
    "            \"config_descr\": \"Custom_ring_test\",\n",
    "            \"posterior_type\": \"Custom\",\n",
    "            \"runs\": default_runs,\n",
    "            \"num_chains\": default_num_chains,\n",
    "            \"base_random_seed\": default_base_random_seed,\n",
    "            \"logp_func\": ring_logp,\n",
    "            \"varying_attribute\": \"num_samples\",\n",
    "            \"varying_values\": [2000, 2500, 3000, 10000],\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unimodal = [\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Normal\",\n",
    "        \"posterior_type\": \"Normal\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 2, 5, 10],\n",
    "        \"sigma\": 1\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Student_t\",\n",
    "        \"posterior_type\": \"StudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\":  default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 3, 5, 30],\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Laplace_test\",\n",
    "        \"posterior_type\": \"Laplace\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"b\",\n",
    "        \"varying_values\": [0.5, 1, 2, 5],\n",
    "        \"mu\": 0,\n",
    "    },\n",
    "]\n",
    "\n",
    "high_dim_and_correlated = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_3d_high_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (-5, 0, 5),\n",
    "            (0, 0, 0),\n",
    "            (-10, 20, -30),\n",
    "            (50, -50, 100)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.9, 0.85], \n",
    "              [0.9, 1, 0.88], \n",
    "              [0.85, 0.88, 1]]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_2d_low_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (0, 0),\n",
    "            (-10, 10),\n",
    "            (20, -20),\n",
    "            (50, -50)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.1], [0.1, 1]]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_2d_high_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (0, 0),\n",
    "            (-10, 10),\n",
    "            (20, -20),\n",
    "            (50, -50)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.95], [0.95, 1]] \n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mv_normal_3d_low_corr\",\n",
    "        \"posterior_type\": \"MvNormal\",\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [\n",
    "            (-5, 0, 5),\n",
    "            (0, 0, 0),\n",
    "            (-10, 20, -30),\n",
    "            (50, -50, 100)\n",
    "        ],\n",
    "        \"cov\": [[1, 0.2, 0.1], \n",
    "                [0.2, 1, 0.15], \n",
    "                [0.1, 0.15, 1]]  \n",
    "    }\n",
    "]\n",
    "\n",
    "multimodal = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(5, 5), (10, -10), (20, 20), (50, -50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.3, 0.4, 0.3]\n",
    "    },\n",
    "    {   \n",
    "        \"config_descr\": \"Normal_and_student_t\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"StudentT\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"nu\",\n",
    "        \"varying_values\": [1, 2, 5, 10],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"nu\": 3, \"mu\": 10, \"sigma\": 2}],\n",
    "        \"weights\": [0.6, 0.4]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "difficult_geometries = [\n",
    "\n",
    "        {\n",
    "        \"config_descr\": \"SkewStudentT\",\n",
    "        \"posterior_type\": \"SkewStudentT\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [1, 2, 3, 5],\n",
    "        \"b\": 1,\n",
    "        \"mu\": 0,\n",
    "        \"sigma\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_of_SkewStudentT\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [0, 3, 6, 10],\n",
    "        \"varying_component\": 0,\n",
    "        \"component_types\": [\"SkewStudentT\", \"SkewStudentT\"],\n",
    "        \"component_params\": [\n",
    "            {\"a\": 3, \"b\": 1, \"sigma\": 1},\n",
    "            {\"a\": 9, \"b\": 3, \"mu\": 3, \"sigma\": 4}\n",
    "        ],\n",
    "        \"weights\": [0.5, 0.5]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "asymmetric_weights_mixture = [\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3),(5, 5), (10, 10), (20, 20), (50, 50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.2, 0.2, 0.6]\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "symmetric_weights_mixture = [\n",
    "        {\n",
    "        \"config_descr\": \"Mv_normal_2d_mixture_3_comp\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [(3, 3),(5, 5), (10, 10), (20, 20), (50, 50)],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_types\": [\"MvNormal\", \"MvNormal\", \"MvNormal\"],\n",
    "        \"component_params\": [\n",
    "                {\"mu\": [0, 0], \"cov\": [[1, 0.5], [0.5, 1]]},  \n",
    "                {\"cov\": [[2, 0.3], [0.3, 2]]},  \n",
    "                {\"mu\": [-10, -10], \"cov\": [[1, -0.2], [-0.2, 1]]}  \n",
    "        ],\n",
    "        \"weights\": [0.3, 0.3, 0.4]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "Mixture_test_init_scheme = [\n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_init_scheme_and_asymmetric_weights (pro DEMetro)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.1, 0.9],\n",
    "        \"init_scheme\": \"equal_per_mode\"\n",
    "\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_asymmetric_weights (only weights)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.1, 0.9]\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_init_scheme (only init_scheme)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.5, 0.5],\n",
    "        \"init_scheme\": \"equal_per_mode\"\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_def_init_scheme_and_equal_weights (fair case)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.5, 0.5]\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_asymmetric_weights_and_random_init (only weights + random init)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.1, 0.9],\n",
    "        \"init_scheme\": \"random\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Mixture_random_init_scheme_and_equal_weights (random init + fair case)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.5, 0.5],\n",
    "        \"init_scheme\": \"random\"\n",
    "    }\n",
    "]\n",
    "\n",
    "new_mixture_test = [\n",
    "\n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_middle_init_scheme_and_asymmetric_weights (pro DEMetro)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.1, 0.9],\n",
    "        \"init_scheme\": \"all_in_middle\"\n",
    "\n",
    "    },     \n",
    "    {   \n",
    "        \"config_descr\": \"Mixture_with_middle_init_scheme (only init_scheme)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.5, 0.5],\n",
    "        \"init_scheme\": \"all_in_middle\"\n",
    "\n",
    "    },\n",
    "    {   \n",
    "        \"config_descr\": \"28_Mixture_with_init_scheme_and_less_asymmetric_weights (pro DEMetro)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.2, 0.8],\n",
    "        \"init_scheme\": \"equal_per_mode\"\n",
    "\n",
    "    },\n",
    "        \n",
    "    {   \n",
    "        \"config_descr\": \"37_Mixture_with_init_scheme_and_lowest_asymmetric_weights (pro DEMetro)\",\n",
    "        \"posterior_type\": \"Mixture\",\n",
    "        \"component_types\": [\"Normal\", \"Normal\"],\n",
    "        \"runs\": default_runs,\n",
    "        \"num_samples\": default_num_samples,\n",
    "        \"num_chains\": default_num_chains,\n",
    "        \"base_random_seed\": default_base_random_seed,\n",
    "        \"varying_attribute\": \"mu\",\n",
    "        \"varying_values\": [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        \"varying_component\": 1,\n",
    "        \"component_params\": [{\"mu\": 0, \"sigma\": 1}, {\"mu\": 5, \"sigma\": 1}],\n",
    "        \"weights\": [0.3, 0.7],\n",
    "        \"init_scheme\": \"equal_per_mode\"\n",
    "\n",
    "    }\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ring_logp_numpy(x, y):\n",
    "    # Kopiere deine Logp-Formel, aber jetzt als NumPy-Ausdruck:\n",
    "    r0 = 3.0\n",
    "    sigma = 0.5\n",
    "    radius = np.sqrt(x**2 + y**2)\n",
    "    return -0.5 * ((radius - r0) / sigma)**2  # ohne Konstante\n",
    "# 1. Erzeuge ein Gitter: z.B. von -6 bis 6 in beiden Dimensionen\n",
    "xs = np.linspace(-6, 6, 200)\n",
    "ys = np.linspace(-6, 6, 200)\n",
    "X, Y = np.meshgrid(xs, ys)\n",
    "\n",
    "# 2. Berechne Logp auf dem Gitter\n",
    "Z = ring_logp_numpy(X, Y)\n",
    "\n",
    "# 3. Plot als Konturlinien oder Heatmap\n",
    "plt.figure(figsize=(7,6))\n",
    "# wähle z.B. contourf\n",
    "levels = 30  # Anzahl der Konturlinien\n",
    "cs = plt.contourf(X, Y, Z, levels=levels, cmap=\"viridis\")\n",
    "plt.colorbar(cs, label=\"Log-Dichte\")\n",
    "\n",
    "# 4. Achsen beschriften, Titel etc.\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Log-Dichte eines Ring-Distribution\")\n",
    "plt.axis(\"equal\")  # gleiches Seitenverhältnis, damit Ring nicht verzerrt wird\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of runs: 3\n",
      "All configurations are valid. Starting experiments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total experiment progress:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Config Custom_mixture_normals started! =====\n",
      "\n",
      "Using IID sample settings: {}\n",
      "\n",
      "===== Running Custom_mixture_normals - Run 1 =====\n",
      "\n",
      "Running Metro with num_samples = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with num_samples = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Metro with num_samples = 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with num_samples = 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Metro with num_samples = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with num_samples = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Metro with num_samples = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with num_samples = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total experiment progress:  33%|███▎      | 1/3 [09:09<18:19, 549.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running Custom_mixture_normals - Run 2 =====\n",
      "\n",
      "Running Metro with num_samples = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with num_samples = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Metro with num_samples = 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with num_samples = 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Metro with num_samples = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with num_samples = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 3000\n",
      "Running Metro with num_samples = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with num_samples = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total experiment progress:  67%|██████▋   | 2/3 [17:40<08:46, 526.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running Custom_mixture_normals - Run 3 =====\n",
      "\n",
      "Running Metro with num_samples = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HMC with num_samples = 2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#experiments = [unimodal, high_dim_and_correlated, multimodal, difficult_geometries, asymmetric_weights_mixture, symmetric_weights_mixture, Mixture_test_init_scheme]\n",
    "#experiments = [new_mixture_test]\n",
    "\n",
    "experiments = [custom_test]\n",
    "experiment_name = \"ring_test\"\n",
    "\n",
    "# Define the root directory for all experiments\n",
    "experiment_root_folder = f\"exp_{experiment_name}\"\n",
    "\n",
    "# Check if the folder already exists\n",
    "if os.path.exists(experiment_root_folder):\n",
    "    user_input = input(\n",
    "        f\"Folder '{experiment_root_folder}' already exists and will be overwritten.\\n\"\n",
    "        \"Do you want to continue? (yes/no): \"\n",
    "    ).strip().lower()\n",
    "\n",
    "    if user_input not in [\"yes\", \"y\"]:\n",
    "        print(\"Operation aborted. No files were deleted.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    shutil.rmtree(experiment_root_folder)\n",
    "\n",
    "create_directories(experiment_root_folder)\n",
    "\n",
    "# important for reduced file size (only about the individual traces, the global traces and traces per run are always saved)\n",
    "experiment_settings = {\n",
    "    \"save_traces\": False,                 # if True, save traces to NetCDF files\n",
    "    \"trace_plots\": \"first_run_only\",                # \"none\", \"first_run_only\", \"all\" \n",
    "    \"plot_traces_in_notebook\": False       # if True, plot traces in the notebook\n",
    "}\n",
    "\n",
    "failed_configs = []\n",
    "start_time = time.time()\n",
    "start_dt = datetime.now()\n",
    "\n",
    "# Validate all configurations before running the experiments\n",
    "for exp in experiments:\n",
    "    for config in exp:\n",
    "        validate_config(config)\n",
    "\n",
    "\n",
    "total_runs = sum(config[\"runs\"] for exp in experiments for config in exp)\n",
    "print(f\"Total number of runs: {total_runs}\")\n",
    "\n",
    "print(\"All configurations are valid. Starting experiments...\")\n",
    "with tqdm(total=total_runs, desc=\"Total experiment progress\") as pbar:\n",
    "    for exp in experiments:\n",
    "        for config in exp:\n",
    "            try:\n",
    "                run_experiment(\n",
    "                    experiment_settings,\n",
    "                    posterior_type=config[\"posterior_type\"],\n",
    "                    config_descr=config[\"config_descr\"],\n",
    "                    runs=config[\"runs\"],\n",
    "                    varying_attribute=config[\"varying_attribute\"],\n",
    "                    varying_values=config[\"varying_values\"],\n",
    "                    init_scheme=\"varies\" if config[\"varying_attribute\"] == \"init_scheme\" else config.get(\"init_scheme\", None),\n",
    "                    num_samples=\"varies\" if config[\"varying_attribute\"] == \"num_samples\" else config[\"num_samples\"],\n",
    "                    num_chains=\"varies\" if config[\"varying_attribute\"] == \"num_chains\" else config[\"num_chains\"],\n",
    "                    base_random_seed=config.get(\"base_random_seed\", None),\n",
    "                    progress_bar=pbar, \n",
    "                    **{k: v for k, v in config.items() if k not in [\n",
    "                        \"config_descr\", \"runs\", \"varying_attribute\", \"varying_values\", \n",
    "                        \"num_samples\", \"num_chains\", \"init_scheme\", \n",
    "                        \"base_random_seed\", \"posterior_type\"\n",
    "                    ]}  # Pass remaining keys as posterior_kwargs\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error in config '{config['config_descr']}': {e}\")\n",
    "                failed_configs.append((config['config_descr'], str(e)))\n",
    "\n",
    "end_time = time.time()\n",
    "end_dt = datetime.now()\n",
    "duration = end_time - start_time\n",
    "hours = int(duration // 3600)\n",
    "minutes = int((duration % 3600) // 60)\n",
    "seconds = round(duration % 60, 1)\n",
    "\n",
    "def get_folder_size(path='.'):\n",
    "    \"\"\"Compute total size of all files in directory.\"\"\"\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total += os.path.getsize(fp)\n",
    "    return total\n",
    "\n",
    "# Prepare the summary text\n",
    "size_bytes = get_folder_size(experiment_root_folder)\n",
    "total_configs = sum(len(exp) for exp in experiments)\n",
    "\n",
    "summary_lines = [\n",
    "    \"\\n============================\",\n",
    "    \"Experiment Summary\",\n",
    "    \"============================\",\n",
    "    f\"Started at:               {start_dt.strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"Finished at:              {end_dt.strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"Total duration:           {hours}h {minutes}m {seconds}s\",\n",
    "    f\"Output folder:            {experiment_root_folder}\",\n",
    "    f\"Output folder size:       {humanize.naturalsize(size_bytes)}\",\n",
    "    f\"Total configurations:     {total_configs}\",\n",
    "    f\"Successful runs:          {total_configs - len(failed_configs)}\",\n",
    "    f\"Failed configurations:    {len(failed_configs)}\"\n",
    "]\n",
    "\n",
    "if failed_configs:\n",
    "    summary_lines.append(\"\\n Failed Configurations:\")\n",
    "    for cfg, msg in failed_configs:\n",
    "        summary_lines.append(f\" - {cfg}: {msg}\")\n",
    "\n",
    "# Print to console\n",
    "print(\"\\n\".join(summary_lines))\n",
    "\n",
    "# Also save to summary.txt\n",
    "summary_path = os.path.join(experiment_root_folder, \"summary.txt\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(summary_lines))\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_immo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
