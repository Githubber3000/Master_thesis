{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "logger = logging.getLogger(\"pymc\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# Function to get the current git tag\n",
    "def get_git_tag():\n",
    "        try:\n",
    "            tag = subprocess.check_output([\"git\", \"describe\", \"--tags\"], stderr=subprocess.DEVNULL).strip().decode()\n",
    "            return tag\n",
    "        except subprocess.CalledProcessError:\n",
    "            return \"No tag found\"\n",
    "\n",
    "\n",
    "def generate_iid_samples(mode_means = [1,2], num_samples=2000, weights=[1,1], std_of_modes=1, rng= None):\n",
    "    \"\"\"\n",
    "    Generate IID samples from the bimodal posterior directly.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = rng or np.random.default_rng()\n",
    "\n",
    "    # Normalize weights\n",
    "    weights = np.array(weights) / np.sum(weights)\n",
    "\n",
    "    # Ensure std_of_modes has the same length as means\n",
    "    if len(std_of_modes) != len(mode_means):\n",
    "        raise ValueError(\"Length of std_of_modes must match the number of modes (means).\")\n",
    "\n",
    "    # Choose which mode each sample belongs to based on weights\n",
    "    chosen_modes = rng.choice(len(mode_means), size=num_samples, p=weights)\n",
    "    \n",
    "    # Map the chosen mode indices to corresponding means and standard deviations\n",
    "    chosen_means = np.array(mode_means)[chosen_modes]\n",
    "    chosen_stds = np.array(std_of_modes)[chosen_modes]\n",
    "    \n",
    "    # Generate samples using the corresponding standard deviations for each sample\n",
    "    iid_samples = rng.normal(loc=chosen_means, scale=chosen_stds, size=num_samples)\n",
    "\n",
    "    return iid_samples\n",
    "\n",
    "\n",
    "def get_initvals(init_scheme, means, num_chains, rng=None):\n",
    "    \"\"\"Generates initialization values based on the chosen scheme.\"\"\"\n",
    "\n",
    "    middle_point = sum(means) / 2\n",
    "\n",
    "    if init_scheme == \"half_per_mode\":\n",
    "        # Half the chains start near the first mode, half near the second mode\n",
    "        initvals = [\n",
    "            {\"mixed_normal\": means[0]} for _ in range(num_chains // 2)  #\"w\": np.array([0.9, 0.1]), \n",
    "        ] + [\n",
    "            {\"mixed_normal\": means[1]} for _ in range(num_chains // 2) #\"w\": np.array([0.1, 0.9])\n",
    "        ]\n",
    "\n",
    "    elif init_scheme == \"all_in_middle\":\n",
    "        # All chains start in the middle between the two modes\n",
    "        initvals = [{\"w\": np.array([0.5, 0.5]), \"mixed_normal\": middle_point} for _ in range(num_chains)]\n",
    "\n",
    "    elif init_scheme == \"random\":\n",
    "        # Chains are initialized randomly between the modes\n",
    "        initvals = [\n",
    "            {\"w\": rng.dirichlet(np.ones(2)), \"mixed_normal\": rng.uniform(means[0], means[1])}\n",
    "            for _ in range(num_chains)\n",
    "        ]\n",
    "\n",
    "    elif init_scheme == \"all_near_first_mode\":\n",
    "        # All chains start near the first mode\n",
    "        initvals = [{\"w\": np.array([0.9, 0.1]), \"mixed_normal\": means[0]} for _ in range(num_chains)]\n",
    "\n",
    "    elif init_scheme == \"all_near_second_mode\":\n",
    "        # All chains start near the second mode\n",
    "        initvals = [{\"w\": np.array([0.1, 0.9]), \"mixed_normal\": means[1]} for _ in range(num_chains)]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown initialization scheme: {init_scheme}\")\n",
    "\n",
    "    return initvals\n",
    "\n",
    "\n",
    "class PosteriorExample:\n",
    "    \"\"\"Base class for different posterior types.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None  # Placeholder for the PyMC model\n",
    "    \n",
    "    def _define_posterior(self):\n",
    "        \"\"\"Subclasses should implement this method to define the posterior.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement _define_posterior()\")\n",
    "\n",
    "    def run_sampling(self, sampler_name, num_samples=2000, tune=1000, num_chains=2, initvals=None, init_scheme=None, run_random_seed=None):\n",
    "        \"\"\"Runs MCMC sampling using the chosen sampler.\"\"\"\n",
    "        \n",
    "        with self.model:\n",
    "\n",
    "            # Define which sampler to use\n",
    "            if sampler_name == \"Metro\":\n",
    "                sampler = pm.Metropolis()\n",
    "            elif sampler_name == \"HMC\":\n",
    "                sampler = pm.NUTS()\n",
    "            elif sampler_name == \"DEMetro\":\n",
    "                sampler = pm.DEMetropolis()\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown sampler: {sampler_name}\")\n",
    "\n",
    "            if init_scheme != None:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler, initvals=initvals, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)\n",
    "            else:\n",
    "                trace = pm.sample(num_samples, tune=tune, step=sampler, chains=num_chains, return_inferencedata=True, progressbar=False, random_seed=run_random_seed)\n",
    "        \n",
    "        return trace\n",
    "\n",
    "\n",
    "class BimodalPosterior(PosteriorExample):\n",
    "    \n",
    "    def __init__(self, mode_means=[-2, 2], std_of_modes=[1, 1], weights=[1, 1]):\n",
    "        if len(mode_means) != len(std_of_modes):\n",
    "            raise ValueError(\"Each mode must have a corresponding standard deviation.\")\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior(mode_means, std_of_modes, weights)\n",
    "    \n",
    "    def _define_posterior(self, mode_means, std_of_modes, weights):        \n",
    "        with pm.Model() as model:\n",
    "            \n",
    "            weights = np.array(weights) / np.sum(weights)  # Normalize weights\n",
    "\n",
    "            # Create component distributions\n",
    "            components = [pm.Normal.dist(mu, sigma) for mu, sigma in zip(mode_means, std_of_modes)]\n",
    "            \n",
    "            # Mixture distribution\n",
    "            mixed_normal = pm.Mixture(\"mixed_normal\", w=pm.math.constant(weights), comp_dists=components)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "class CauchyPosterior(PosteriorExample):\n",
    "    def __init__(self, loc=0, scale=1):\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior(loc, scale)\n",
    "\n",
    "    def _define_posterior(self, loc, scale):\n",
    "        with pm.Model() as model:\n",
    "            \n",
    "            cauchy = pm.Cauchy(\"cauchy\", alpha=loc, beta=scale)\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "class BetaPosterior(PosteriorExample):\n",
    "    def __init__(self, a=2, b=2):\n",
    "        super().__init__()\n",
    "        self.model = self._define_posterior(a, b)\n",
    "\n",
    "    def _define_posterior(self, a, b):\n",
    "        with pm.Model() as model:\n",
    "            \n",
    "            beta = pm.Beta(\"beta\", alpha=a, beta=b)\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "\n",
    "# new generalized version\n",
    "\n",
    "def run_experiment(\n",
    "    posterior_type,\n",
    "    config_descr,\n",
    "    runs,\n",
    "    varying_attribute, \n",
    "    varying_values,      \n",
    "    num_samples,\n",
    "    num_chains,\n",
    "    init_scheme=None,\n",
    "    base_random_seed=None,\n",
    "    **posterior_kwargs\n",
    "):\n",
    "    print(f\"\\n===== Config {config_descr} started! =====\\n\")\n",
    "\n",
    "    # Initialize random number generator\n",
    "    rng = np.random.default_rng(base_random_seed)\n",
    "\n",
    "    # === Select Posterior Type and Precompute IID Samples ===\n",
    "    if posterior_type == \"bimodal\":\n",
    "        required_keys = [\"mode_means\", \"std_of_modes\", \"weights\"]\n",
    "        # Remove varying attribute from required keys\n",
    "        required_keys = [k for k in required_keys if k != varying_attribute]  \n",
    "\n",
    "        if not all(k in posterior_kwargs for k in required_keys):\n",
    "            raise ValueError(f\"Bimodal posterior requires {required_keys}\")\n",
    "        \n",
    "        posterior_cls = BimodalPosterior\n",
    "        iid_kwargs = {\n",
    "            \"mode_means\": posterior_kwargs.get(\"mode_means\", \"varies\"),\n",
    "            \"std_of_modes\": posterior_kwargs.get(\"std_of_modes\", \"varies\"),\n",
    "            \"weights\": posterior_kwargs.get(\"weights\", \"varies\")\n",
    "        }\n",
    "\n",
    "    elif posterior_type == \"cauchy\":\n",
    "        required_keys = [\"loc\", \"scale\"]\n",
    "        required_keys = [k for k in required_keys if k != varying_attribute]\n",
    "\n",
    "        if not all(k in posterior_kwargs for k in required_keys):\n",
    "            raise ValueError(f\"Cauchy posterior requires {required_keys}\")\n",
    "        \n",
    "        posterior_cls = CauchyPosterior\n",
    "        iid_kwargs = {\"loc\": posterior_kwargs.get(\"loc\", \"varies\"), \"scale\": posterior_kwargs.get(\"scale\", \"varies\")}\n",
    "\n",
    "    elif posterior_type == \"beta\":\n",
    "        required_keys = [\"a\", \"b\"]\n",
    "        required_keys = [k for k in required_keys if k != varying_attribute]\n",
    "\n",
    "        if not all(k in posterior_kwargs for k in required_keys):\n",
    "            raise ValueError(f\"Beta posterior requires {required_keys}\")\n",
    "        \n",
    "        posterior_cls = BetaPosterior\n",
    "        iid_kwargs = {\"a\": posterior_kwargs.get(\"a\", \"varies\"), \"b\": posterior_kwargs.get(\"b\", \"varies\")}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown posterior type: {posterior_type}\")\n",
    "\n",
    "\n",
    "    # Create configuration folder inside the experiment root\n",
    "    config_folder = os.path.join(experiment_root_folder, f\"{config_descr}_with_{runs}_runs\")\n",
    "    os.makedirs(config_folder)\n",
    "\n",
    "\n",
    "    # Define folder for saving histograms\n",
    "    iid_histogram_folder = os.path.join(config_folder, \"iid_histograms\")\n",
    "    os.makedirs(iid_histogram_folder)\n",
    "\n",
    "    # === Handle Precomputed IID Samples for Varying Attributes ===\n",
    "    iid_samples_dict = {}\n",
    "\n",
    "    if varying_attribute in iid_kwargs or varying_attribute == \"num_samples\":\n",
    "        # If num_samples or a posterior parameter varies, generate IID samples for each value\n",
    "        for value in varying_values:\n",
    "            if varying_attribute == \"num_samples\":\n",
    "                current_num_samples = value  # Update num_samples dynamically\n",
    "            else:\n",
    "                iid_kwargs[varying_attribute] = value  # Adjust the varying posterior parameter\n",
    "                current_num_samples = num_samples  # Use fixed num_samples if not varying\n",
    "                \n",
    "            # Generate IID samples for each varying value\n",
    "            if posterior_type == \"bimodal\":\n",
    "                iid_samples_dict[value] = generate_iid_samples(num_samples=current_num_samples, rng=rng, **iid_kwargs)\n",
    "            elif posterior_type == \"cauchy\":\n",
    "                iid_samples_dict[value] = sp.cauchy.rvs(**iid_kwargs, size=current_num_samples, random_state=rng)\n",
    "            elif posterior_type == \"beta\":\n",
    "                iid_samples_dict[value] = sp.beta.rvs(**iid_kwargs, size=current_num_samples, random_state=rng)\n",
    "\n",
    "            # Define extreme percentile cutoffs\n",
    "            lower_percentile = 1\n",
    "            upper_percentile = 99\n",
    "\n",
    "            if posterior_type == \"cauchy\":\n",
    "                # Trim extreme percentiles for better visualization\n",
    "                lower_bound, upper_bound = np.percentile(iid_samples_dict[value], [lower_percentile, upper_percentile])\n",
    "                filtered_samples = iid_samples_dict[value][(iid_samples_dict[value] >= lower_bound) & (iid_samples_dict[value] <= upper_bound)]\n",
    "\n",
    "            else:\n",
    "                filtered_samples = iid_samples_dict[value]\n",
    "\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(filtered_samples, bins=50, alpha=0.75, density=True, color='blue', edgecolor='black')\n",
    "            plt.title(f\"IID Samples Histogram ({varying_attribute}={value})\")\n",
    "            plt.xlabel(\"Sample Value\")\n",
    "            plt.ylabel(\"Density\")\n",
    "            plt.grid(True)\n",
    "            histogram_filename = os.path.join(iid_histogram_folder, f\"iid_hist_{varying_attribute}_{value}.pdf\")\n",
    "            plt.savefig(histogram_filename, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "\n",
    "                \n",
    "    else:\n",
    "\n",
    "        # If the posterior is fixed (var_attr == chain or var== init_scheme), generate IID samples once\n",
    "        if posterior_type == \"bimodal\":\n",
    "            iid_samples = generate_iid_samples(num_samples=num_samples, rng=rng, **iid_kwargs)\n",
    "        elif posterior_type == \"cauchy\":\n",
    "            iid_samples = sp.cauchy.rvs(**iid_kwargs, size=num_samples, random_state=rng)\n",
    "        elif posterior_type == \"beta\":\n",
    "            iid_samples = sp.beta.rvs(**iid_kwargs, size=num_samples, random_state=rng)\n",
    "\n",
    "        \n",
    "        # Apply trimming only for Cauchy distribution\n",
    "        if posterior_type == \"cauchy\":\n",
    "            lower_bound, upper_bound = np.percentile(iid_samples, [lower_percentile, upper_percentile])\n",
    "            filtered_samples = iid_samples[(iid_samples >= lower_bound) & (iid_samples <= upper_bound)]\n",
    "        else:\n",
    "            filtered_samples = iid_samples\n",
    "\n",
    "        \n",
    "        # Save a single histogram\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.hist(filtered_samples, bins=50, alpha=0.75, density=True, color='blue', edgecolor='black')\n",
    "        plt.title(f\"IID Samples Histogram (Fixed Posterior)\")\n",
    "        plt.xlabel(\"Sample Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.grid(True)\n",
    "        histogram_filename = os.path.join(iid_histogram_folder, \"iid_hist_fixed.pdf\")\n",
    "        plt.savefig(histogram_filename, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    # === Experiment Setup ===\n",
    "    samples_per_chain = \"varies\" if varying_attribute in [\"num_samples\", \"num_chains\"] else num_samples // num_chains\n",
    "\n",
    "    experiment_metadata = {\n",
    "        \"config_descr\": config_descr,\n",
    "        \"runs\": runs,\n",
    "        \"posterior_type\": posterior_type,\n",
    "        \"varying_attribute\": varying_attribute,\n",
    "        \"varying_values\": varying_values,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"num_chains\": num_chains,\n",
    "        \"samples_per_chain\": samples_per_chain,\n",
    "        \"init_scheme\": init_scheme,\n",
    "        \"base_random_seed\": base_random_seed,\n",
    "        \"git_tag\": get_git_tag(),\n",
    "    }\n",
    "    experiment_metadata.update(posterior_kwargs)  # Add posterior-specific parameters\n",
    "\n",
    "    # Save metadata\n",
    "    metadata_filename = os.path.join(config_folder, f\"metadata_config_{config_descr}.json\")\n",
    "    with open(metadata_filename, \"w\") as f:\n",
    "        json.dump(experiment_metadata, f, indent=4)\n",
    "\n",
    "    # Define fixed colors for each sampler\n",
    "    sampler_colors = {\n",
    "        \"Metro\": \"blue\",\n",
    "        \"HMC\": \"red\",\n",
    "        \"DEMetro\": \"green\"\n",
    "    }\n",
    "\n",
    "    # === Run the Experiment ===\n",
    "    for run_id in range(1, runs + 1):\n",
    "        print(f\"\\n===== Running {config_descr} - Run {run_id} =====\\n\")\n",
    "\n",
    "        run_random_seed = int(rng.integers(1_000_000))\n",
    "\n",
    "\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "        traces_folder = os.path.join(run_folder, \"traces_and_trace_plots\")\n",
    "        plots_folder = os.path.join(run_folder, \"plots_of_run\")\n",
    "        \n",
    "\n",
    "        os.makedirs(run_folder)\n",
    "        os.makedirs(results_folder)\n",
    "        os.makedirs(traces_folder)\n",
    "        os.makedirs(plots_folder)\n",
    "\n",
    "        results = []\n",
    "\n",
    "\n",
    "        for value in varying_values:\n",
    "\n",
    "            var_attr_folder = os.path.join(traces_folder, f\"{varying_attribute}_{value}\")\n",
    "            os.makedirs(var_attr_folder)\n",
    "\n",
    "            # Ensure `posterior_kwargs` is not modified globally\n",
    "            current_posterior_kwargs = posterior_kwargs.copy()  #  Create a copy for this iteration\n",
    "            if varying_attribute in current_posterior_kwargs:\n",
    "                current_posterior_kwargs[varying_attribute] = value  #  Modify only the copy\n",
    "\n",
    "            \n",
    "            if varying_attribute == \"num_samples\":\n",
    "                num_samples = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"num_chains\":\n",
    "                num_chains = value\n",
    "                samples_per_chain = num_samples // num_chains\n",
    "            elif varying_attribute == \"init_scheme\":\n",
    "                init_scheme = value\n",
    "    \n",
    "\n",
    "            model = posterior_cls(**current_posterior_kwargs)  #  Use the loop-specific copy\n",
    "\n",
    "\n",
    "            # Generate initialization values\n",
    "            #if init_scheme != None:\n",
    "            #    initvals = get_initvals(init_scheme, current_posterior_kwargs.get(\"mode_means\", [0]), num_chains, rng)\n",
    "            #initvals = get_initvals(init_scheme, posterior_kwargs.get(\"means\", [0]), num_chains, rng) if use_init_scheme else None\n",
    "\n",
    "\n",
    "            # Get IID samples for the current varying value\n",
    "            if varying_attribute != \"init_scheme\" and varying_attribute != \"num_chains\":\n",
    "                iid_samples = iid_samples_dict[value] \n",
    "\n",
    "\n",
    "            # Run sampling for all samplers\n",
    "            for sampler_name in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "                print(f\"Running {sampler_name} with {varying_attribute} = {value}\")\n",
    "\n",
    "\n",
    "                # **Measure Computation Time**\n",
    "                start_time = time.time()\n",
    "                trace = model.run_sampling(\n",
    "                    sampler_name, num_samples=samples_per_chain, num_chains=num_chains,\n",
    "                    init_scheme = init_scheme, run_random_seed=run_random_seed\n",
    "                )\n",
    "                end_time = time.time()\n",
    "                runtime = end_time - start_time\n",
    "\n",
    "                # Save trace to NetCDF file\n",
    "                trace_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace.nc\")\n",
    "                az.to_netcdf(trace, trace_filename)\n",
    "\n",
    "                # Save trace plot\n",
    "                trace_plot_filename = os.path.join(var_attr_folder, f\"{sampler_name}_trace_plot.pdf\")\n",
    "                az.plot_trace(trace, compact=True)\n",
    "                plt.savefig(trace_plot_filename, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "\n",
    "                \n",
    "\n",
    "                # Select correct posterior variable name\n",
    "                if posterior_type == \"bimodal\":\n",
    "                    posterior_var_name = \"mixed_normal\"\n",
    "                elif posterior_type == \"cauchy\":\n",
    "                    posterior_var_name = \"cauchy\"\n",
    "                elif posterior_type == \"beta\":\n",
    "                    posterior_var_name = \"beta\"\n",
    "                else:\n",
    "                    raise ValueError(\"Unknown posterior type for diagnostics.\")\n",
    "\n",
    "                # Compute Wasserstein distance\n",
    "                ws_distance = sp.wasserstein_distance(trace.posterior[posterior_var_name].values.flatten(), iid_samples)\n",
    "\n",
    "                # Compute R-hat and ESS\n",
    "                r_hat = az.rhat(trace)[posterior_var_name].item()\n",
    "                ess = az.ess(trace)[posterior_var_name].item()\n",
    "\n",
    "\n",
    "                results.append({\n",
    "                    varying_attribute: value,\n",
    "                    \"sampler\": sampler_name,\n",
    "                    \"wasserstein_distance\": ws_distance,\n",
    "                    \"r_hat\": r_hat,\n",
    "                    \"ess\": ess,\n",
    "                    \"runtime\": runtime\n",
    "                })\n",
    "\n",
    "        # Convert results to DataFrame and save\n",
    "        df_results = pd.DataFrame(results)\n",
    "\n",
    "        # Handle tuple-based attributes consistently\n",
    "        if isinstance(df_results[varying_attribute].iloc[0], tuple):\n",
    "            if varying_attribute == \"mode_means\":\n",
    "                df_results[\"mode_distance\"] = df_results[varying_attribute].apply(lambda x: abs(x[1] - x[0]))\n",
    "                varying_attribute_for_plot = \"mode_distance\"\n",
    "            else:\n",
    "                df_results[varying_attribute] = df_results[varying_attribute].apply(str)\n",
    "                varying_attribute_for_plot = varying_attribute\n",
    "        else:\n",
    "            varying_attribute_for_plot = varying_attribute\n",
    "\n",
    "        # Sort the DataFrame by the final chosen attribute\n",
    "        df_results = df_results.sort_values(varying_attribute_for_plot, ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "        # initialize plots for all samplers\n",
    "        fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\n",
    "        fig_rhat, ax_rhat = plt.subplots(figsize=(10, 6))\n",
    "        fig_ess, ax_ess = plt.subplots(figsize=(10, 6))\n",
    "        fig_time, ax_time = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "\n",
    "        for sampler in df_results[\"sampler\"].unique():\n",
    "            df_sampler = df_results[df_results[\"sampler\"] == sampler]\n",
    "            csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "            df_sampler.to_csv(csv_filename, index=False)\n",
    "\n",
    "  \n",
    "            # Plot Wasserstein Distance\n",
    "            ax_ws.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"wasserstein_distance\"], \n",
    "                marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "            # Plot R-hat values\n",
    "            ax_rhat.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"r_hat\"], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "            \n",
    "            # Plot ESS values\n",
    "            ax_ess.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"ess\"], \n",
    "                    marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                    color=sampler_colors.get(sampler, \"black\"))\n",
    "\n",
    "            # **Plot Computation Time**\n",
    "            ax_time.plot(df_sampler[varying_attribute_for_plot], df_sampler[\"runtime\"], \n",
    "                        marker=\"o\", linestyle=\"-\", label=sampler, \n",
    "                        color=sampler_colors.get(sampler, \"black\"))\n",
    "            \n",
    "        \n",
    "        # Set dynamic axis labels and titles\n",
    "        attribute_label = \"Mode Distance\" if varying_attribute == \"mode_means\" else varying_attribute.replace(\"_\", \" \").title()\n",
    "        \n",
    "        # ===== Finalize and Save Wasserstein Plot =====\n",
    "        ax_ws.set_xlabel(attribute_label)\n",
    "        ax_ws.set_ylabel(\"Wasserstein Distance\")\n",
    "        ax_ws.set_title(f\"Wasserstein Distance for Samplers (config =_{config_descr})\")\n",
    "        ax_ws.legend(title=\"Sampler\")\n",
    "        ax_ws.grid(True)\n",
    "        plot_filename = os.path.join(plots_folder, f\"Wasserstein_run_{run_id}.pdf\")\n",
    "        fig_ws.savefig(plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_ws)\n",
    "\n",
    "        # ===== Finalize and Save R-hat Plot =====\n",
    "        ax_rhat.set_xlabel(attribute_label)\n",
    "        ax_rhat.set_ylabel(\"R-hat\")\n",
    "        ax_rhat.set_title(f\"R-hat for Samplers (config =_{config_descr})\")\n",
    "        ax_rhat.legend(title=\"Sampler\")\n",
    "        ax_rhat.grid(True)\n",
    "        rhat_plot_filename = os.path.join(plots_folder, f\"R-hat_run_{run_id}.pdf\")\n",
    "        fig_rhat.savefig(rhat_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_rhat)\n",
    "\n",
    "        # ===== Finalize and Save ESS Plot =====\n",
    "        ax_ess.set_xlabel(attribute_label)\n",
    "        ax_ess.set_ylabel(\"ESS\")\n",
    "        ax_ess.set_title(f\"ESS for Samplers (config =_{config_descr})\")\n",
    "        ax_ess.legend(title=\"Sampler\")\n",
    "        ax_ess.grid(True)\n",
    "        ess_plot_filename = os.path.join(plots_folder, f\"ESS_run_{run_id}.pdf\")\n",
    "        fig_ess.savefig(ess_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_ess)\n",
    "\n",
    "        # ===== Finalize and Save Time Plot =====\n",
    "        ax_time.set_xlabel(attribute_label)\n",
    "        ax_time.set_ylabel(\"Computation Time (seconds)\")\n",
    "        ax_time.set_title(f\"Computation Time for Samplers (config =_{config_descr})\")\n",
    "        ax_time.legend(title=\"Sampler\")\n",
    "        ax_time.grid(True)\n",
    "        time_plot_filename = os.path.join(plots_folder, f\"ComputationTime_run_{run_id}.pdf\")\n",
    "        fig_time.savefig(time_plot_filename, bbox_inches=\"tight\")\n",
    "        plt.close(fig_time)\n",
    "\n",
    "\n",
    "    print(\"\\n===== All Runs Completed Successfully! =====\\n\")\n",
    "\n",
    "    # ===== GLOBAL RESULTS FOLDER =====\n",
    "    global_folder = os.path.join(config_folder, \"global_results\")\n",
    "    global_results_folder = os.path.join(global_folder, \"results\")\n",
    "    global_plots_folder = os.path.join(global_folder, \"plots\")\n",
    "\n",
    "    os.makedirs(global_folder)\n",
    "    os.makedirs(global_results_folder)\n",
    "    os.makedirs(global_plots_folder)\n",
    "\n",
    "    # Collect all results from all runs\n",
    "    df_all_runs = []\n",
    "\n",
    "    for run_id in range(1, runs + 1):\n",
    "        run_folder = os.path.join(config_folder, f\"run_{run_id}\")\n",
    "        results_folder = os.path.join(run_folder, \"results\")\n",
    "\n",
    "        for sampler in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "            csv_filename = os.path.join(results_folder, f\"{sampler}_results.csv\")\n",
    "            df_run = pd.read_csv(csv_filename)\n",
    "            df_run[\"run_id\"] = run_id \n",
    "            df_run[\"sampler\"] = sampler  \n",
    "            df_all_runs.append(df_run)\n",
    "\n",
    "\n",
    "    # Combine all results into a single data frame \n",
    "    df_all_runs = pd.concat(df_all_runs, ignore_index=True)\n",
    "\n",
    "    if varying_attribute == \"mode_means\":\n",
    "        df_all_runs[\"mode_distance\"] = df_all_runs[varying_attribute].apply(lambda x: abs(eval(x)[1] - eval(x)[0]))\n",
    "        df_all_runs = df_all_runs.sort_values(\"mode_distance\", ascending=True)\n",
    "        varying_attribute_for_global_plot = \"mode_distance\"\n",
    "    else:\n",
    "        df_all_runs = df_all_runs.sort_values(varying_attribute, ascending=True)\n",
    "        varying_attribute_for_global_plot = varying_attribute\n",
    "\n",
    "\n",
    "    # Initialize global plots\n",
    "    fig_ws, ax_ws = plt.subplots(figsize=(10, 6))\n",
    "    fig_rhat, ax_rhat = plt.subplots(figsize=(10, 6))\n",
    "    fig_ess, ax_ess = plt.subplots(figsize=(10, 6))\n",
    "    fig_time, ax_time = plt.subplots(figsize=(10, 6)) \n",
    "\n",
    "    for sampler in [\"Metro\", \"HMC\", \"DEMetro\"]:\n",
    "        df_sampler = df_all_runs[df_all_runs[\"sampler\"] == sampler]\n",
    "\n",
    "        # Pivot tables: rows = varying attribute, columns = run_id, values = metrics\n",
    "        df_ws = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"wasserstein_distance\")\n",
    "        df_rhat = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"r_hat\")\n",
    "        df_ess = df_sampler.pivot_table(index=varying_attribute_for_global_plot, columns=\"run_id\", values=\"ess\")\n",
    "        df_time = df_sampler.pivot_table(index=varying_attribute, columns=\"run_id\", values=\"runtime\")\n",
    "    \n",
    "        # Compute mean and standard deviation for error bars\n",
    "        ws_mean, ws_std = df_ws.mean(axis=1), df_ws.std(axis=1)\n",
    "        rhat_mean, rhat_std = df_rhat.mean(axis=1), df_rhat.std(axis=1)\n",
    "        ess_mean, ess_std = df_ess.mean(axis=1), df_ess.std(axis=1)\n",
    "        time_mean, time_std = df_time.mean(axis=1), df_time.std(axis=1)\n",
    "\n",
    "        color = sampler_colors.get(sampler, \"black\")\n",
    "\n",
    "        # Plot with error bars\n",
    "        ax_ws.errorbar(ws_mean.index, ws_mean, yerr=ws_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_rhat.errorbar(rhat_mean.index, rhat_mean, yerr=rhat_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_ess.errorbar(ess_mean.index, ess_mean, yerr=ess_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "        ax_time.errorbar(time_mean.index, time_mean, yerr=time_std, fmt=\"o-\", label=sampler, color=color, capsize=5)\n",
    "\n",
    "        # Save global averages \n",
    "        df_global_avg = pd.DataFrame({\n",
    "            varying_attribute: ws_mean.index,\n",
    "            \"global_avg_ws\": ws_mean.values,\n",
    "            \"global_avg_ws_std\": ws_std.values,\n",
    "            \"global_avg_rhat\": rhat_mean.values,\n",
    "            \"global_avg_rhat_std\": rhat_std.values,\n",
    "            \"global_avg_ess\": ess_mean.values,\n",
    "            \"global_avg_ess_std\": ess_std.values,\n",
    "            \"global_avg_time\": time_mean.values,\n",
    "            \"global_avg_time_std\": time_std.values\n",
    "        })\n",
    "\n",
    "        sampler_csv_filename = os.path.join(global_results_folder, f\"Global_results_{sampler}.csv\")\n",
    "        df_global_avg.to_csv(sampler_csv_filename, index=False)\n",
    "\n",
    "    # ===== Save Global Wasserstein Plot =====\n",
    "    ax_ws.set_xlabel(attribute_label)\n",
    "    ax_ws.set_ylabel(\"Average Wasserstein Distance\")\n",
    "    ax_ws.set_title(f\"Averaged Wasserstein Distance ({runs} Runs, config = {config_descr})\")\n",
    "    ax_ws.legend(title=\"Sampler\")\n",
    "    ax_ws.grid(True)\n",
    "    fig_ws.savefig(os.path.join(global_plots_folder, \"Wasserstein_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_ws)\n",
    "\n",
    "    # ===== Save Global R-hat Plot =====\n",
    "    ax_rhat.set_xlabel(attribute_label)\n",
    "    ax_rhat.set_ylabel(\"Average R-hat\")\n",
    "    ax_rhat.set_title(f\"Averaged R-hat Values ({runs} Runs, config = {config_descr})\")\n",
    "    ax_rhat.legend(title=\"Sampler\")\n",
    "    ax_rhat.grid(True)\n",
    "    fig_rhat.savefig(os.path.join(global_plots_folder, \"Rhat_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_rhat)\n",
    "\n",
    "    # ===== Save Global ESS Plot =====\n",
    "    ax_ess.set_xlabel(attribute_label)\n",
    "    ax_ess.set_ylabel(\"Average ESS\")\n",
    "    ax_ess.set_title(f\"Averaged ESS ({runs} Runs,  config = {config_descr})\")\n",
    "    ax_ess.legend(title=\"Sampler\")\n",
    "    ax_ess.grid(True)\n",
    "    fig_ess.savefig(os.path.join(global_plots_folder, \"ESS_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_ess)\n",
    "\n",
    "    # ===== Save Global Time Plot =====\n",
    "    ax_time.set_xlabel(attribute_label)\n",
    "    ax_time.set_ylabel(\"Average Computation Time (seconds)\")\n",
    "    ax_time.set_title(f\"Averaged Computation Time ({runs} Runs, config = {config_descr})\")\n",
    "    ax_time.legend(title=\"Sampler\")\n",
    "    ax_time.grid(True)\n",
    "    fig_time.savefig(os.path.join(global_plots_folder, \"Time_global_plot.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close(fig_time)\n",
    "\n",
    "    print(f\"\\n===== Config {config_descr} Completed Successfully! =====\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of all possible attributes in a config\n",
    "REQUIRED_ATTRIBUTES = {\n",
    "    \"mode_means\",\n",
    "    \"std_of_modes\",\n",
    "    \"weights\",\n",
    "    \"num_samples\",\n",
    "    \"num_chains\",\n",
    "    \"use_init_scheme\",\n",
    "}\n",
    "\n",
    "\n",
    "# needs to be adapetd for new posterior types\n",
    "def validate_config(config):\n",
    "    \"\"\"Checks if the config correctly defines one varying attribute and all other attributes are fixed.\"\"\"\n",
    "    \n",
    "    # Ensure \"varying_attribute\" is specified\n",
    "    if \"varying_attribute\" not in config:\n",
    "        raise ValueError(f\"Config '{config.get('config_descr', 'Unnamed')}' is missing 'varying_attribute'.\")\n",
    "\n",
    "    varying_attr = config[\"varying_attribute\"]\n",
    "\n",
    "    # Ensure \"varying_values\" is present\n",
    "    if \"varying_values\" not in config:\n",
    "        raise ValueError(f\"Config '{config['config_descr']}' is missing 'varying_values' for '{varying_attr}'.\")\n",
    "\n",
    "    # Ensure varying_attribute is a recognized attribute\n",
    "    if varying_attr not in REQUIRED_ATTRIBUTES and varying_attr!= \"init_scheme\":\n",
    "        raise ValueError(f\"Config '{config['config_descr']}' has an invalid 'varying_attribute': '{varying_attr}'.\")\n",
    "\n",
    "    # Validate that `init_scheme` is present only if `use_init_scheme` is True\n",
    "    if \"use_init_scheme\" in config:\n",
    "        if config[\"use_init_scheme\"] and \"init_scheme\" not in config and varying_attr != \"init_scheme\":\n",
    "            raise ValueError(f\"Config '{config['config_descr']}' is missing 'init_scheme' but 'use_init_scheme' is set to True.\")\n",
    "        elif not config[\"use_init_scheme\"] and \"init_scheme\" in config:\n",
    "            raise ValueError(f\"Config '{config['config_descr']}' defines 'init_scheme' but 'use_init_scheme' is False.\")\n",
    "\n",
    "\n",
    "    # Check that all other required attributes are fixed (not missing)\n",
    "    for attr in REQUIRED_ATTRIBUTES:\n",
    "        if attr == varying_attr:\n",
    "            # The varying attribute should not have a fixed value\n",
    "            if attr in config:\n",
    "                raise ValueError(f\"Config '{config['config_descr']}' incorrectly defines '{attr}' as both fixed and varying.\")\n",
    "        else:\n",
    "            # All other attributes must be explicitly defined\n",
    "            if attr not in config:\n",
    "                raise ValueError(f\"Config '{config['config_descr']}' is missing required fixed attribute '{attr}'.\")\n",
    "\n",
    "\n",
    "\n",
    "# posterior_type = \"bimodal\", \"cauchy\", \"beta\"\n",
    "# varying_attribute = \"num_samples\", \"num_chains\", \"init_scheme\" or posterior specific attribute\n",
    "# bimmodal specific attributes = \"mode_means\", \"std_of_modes\", \"weights\"\n",
    "# cauchy specific attributes = \"loc\", \"scale\"\n",
    "# beta specific attributes = \"a\", \"b\"\n",
    "# all but the varying attribute must be fixed and present in the config\n",
    "\n",
    "\n",
    "\n",
    "Testcases_all_attr = [\n",
    "    {\n",
    "        \"config_descr\": \"Weights_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": 2,\n",
    "        \"varying_attribute\": \"weights\",    \n",
    "        \"varying_values\": [(1,1), (1,2), (5,1)],\n",
    "        \"mode_means\": (3,14),\n",
    "        \"num_samples\": 100,\n",
    "        \"num_chains\": 4,\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"use_init_scheme\": False,\n",
    "        \"base_random_seed\": 42\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Mode_Means_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": 2,\n",
    "        \"varying_attribute\": \"mode_means\",    \n",
    "        \"varying_values\": [(0,3), (0,10), (0, 20)],\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1),\n",
    "        \"num_samples\": 100,\n",
    "        \"num_chains\": 4,\n",
    "        \"use_init_scheme\": False,\n",
    "        \"base_random_seed\": 42\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Std_of_Modes_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": 2,\n",
    "        \"varying_attribute\": \"std_of_modes\",    \n",
    "        \"varying_values\": [(1,1),(1,4),(2,1)],\n",
    "        \"mode_means\": (3,-3),\n",
    "        \"weights\": (1,1),\n",
    "        \"num_samples\": 100,\n",
    "        \"num_chains\": 4,\n",
    "        \"use_init_scheme\": False,\n",
    "        \"base_random_seed\": 42\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"config_descr\": \"Samples_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": 2,\n",
    "        \"varying_attribute\": \"num_samples\",    \n",
    "        \"varying_values\": [100, 200, 300],\n",
    "        \"mode_means\": (3,-3),\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1),\n",
    "        \"num_chains\": 4,\n",
    "        \"use_init_scheme\": False,\n",
    "        \"base_random_seed\": 42\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"config_descr\": \"Chains_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": 2,\n",
    "        \"varying_attribute\": \"num_chains\",    \n",
    "        \"varying_values\": [4,6,8],\n",
    "        \"mode_means\": (3,-3),\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1),\n",
    "        \"num_samples\": 100,\n",
    "        \"use_init_scheme\": False,\n",
    "        \"base_random_seed\": 42\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "Test_bimodal_posterior = [\n",
    "    {\n",
    "        \"config_descr\": \"Bimodal_test\",\n",
    "        \"posterior_type\": \"bimodal\",\n",
    "        \"runs\": 2,\n",
    "        \"varying_attribute\": \"mode_means\",\n",
    "        \"varying_values\": [(3,8), (4,20)],\n",
    "        \"std_of_modes\": (1,1),\n",
    "        \"weights\": (1,1),\n",
    "        \"num_samples\": 100,\n",
    "        \"num_chains\": 4,\n",
    "        \"use_init_scheme\": False,\n",
    "        \"base_random_seed\": 42\n",
    "    }\n",
    "]\n",
    "\n",
    "Test_new_posterior_types = [\n",
    "    {\n",
    "        \"config_descr\": \"Cauchy_test\",\n",
    "        \"posterior_type\": \"cauchy\",\n",
    "        \"runs\": 2,\n",
    "        \"varying_attribute\": \"loc\",\n",
    "        \"varying_values\": [0, -2, 5],\n",
    "        \"num_chains\": 4,\n",
    "        \"scale\": 1,\n",
    "        \"num_samples\": 10000,\n",
    "        #\"num_chains\": 4,\n",
    "        \"base_random_seed\": 42\n",
    "    },\n",
    "    {\n",
    "        \"config_descr\": \"Beta_test\",\n",
    "        \"posterior_type\": \"beta\",\n",
    "        \"runs\": 2,\n",
    "        \"varying_attribute\": \"a\",\n",
    "        \"varying_values\": [0.5,5,1],\n",
    "        \"num_chains\": 4,\n",
    "        \"b\": 3,\n",
    "        \"num_samples\": 10000,\n",
    "        #\"num_chains\": 4,\n",
    "        \"base_random_seed\": 42\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Config Weights_test started! =====\n",
      "\n",
      "\n",
      "===== Running Weights_test - Run 1 =====\n",
      "\n",
      "Running Metro with weights = (1, 1)\n",
      "Running HMC with weights = (1, 1)\n",
      "Running DEMetro with weights = (1, 1)\n",
      "Running Metro with weights = (1, 2)\n",
      "Running HMC with weights = (1, 2)\n",
      "Running DEMetro with weights = (1, 2)\n",
      "Running Metro with weights = (5, 1)\n",
      "Running HMC with weights = (5, 1)\n",
      "Running DEMetro with weights = (5, 1)\n",
      "\n",
      "===== Running Weights_test - Run 2 =====\n",
      "\n",
      "Running Metro with weights = (1, 1)\n",
      "Running HMC with weights = (1, 1)\n",
      "Running DEMetro with weights = (1, 1)\n",
      "Running Metro with weights = (1, 2)\n",
      "Running HMC with weights = (1, 2)\n",
      "Running DEMetro with weights = (1, 2)\n",
      "Running Metro with weights = (5, 1)\n",
      "Running HMC with weights = (5, 1)\n",
      "Running DEMetro with weights = (5, 1)\n",
      "\n",
      "===== All Runs Completed Successfully! =====\n",
      "\n",
      "\n",
      "===== Config Weights_test Completed Successfully! =====\n",
      "\n",
      "\n",
      "===== Config Mode_Means_test started! =====\n",
      "\n",
      "\n",
      "===== Running Mode_Means_test - Run 1 =====\n",
      "\n",
      "Running Metro with mode_means = (0, 3)\n",
      "Running HMC with mode_means = (0, 3)\n",
      "Running DEMetro with mode_means = (0, 3)\n",
      "Running Metro with mode_means = (0, 10)\n",
      "Running HMC with mode_means = (0, 10)\n",
      "Running DEMetro with mode_means = (0, 10)\n",
      "Running Metro with mode_means = (0, 20)\n",
      "Running HMC with mode_means = (0, 20)\n",
      "Running DEMetro with mode_means = (0, 20)\n",
      "\n",
      "===== Running Mode_Means_test - Run 2 =====\n",
      "\n",
      "Running Metro with mode_means = (0, 3)\n",
      "Running HMC with mode_means = (0, 3)\n",
      "Running DEMetro with mode_means = (0, 3)\n",
      "Running Metro with mode_means = (0, 10)\n",
      "Running HMC with mode_means = (0, 10)\n",
      "Running DEMetro with mode_means = (0, 10)\n",
      "Running Metro with mode_means = (0, 20)\n",
      "Running HMC with mode_means = (0, 20)\n",
      "Running DEMetro with mode_means = (0, 20)\n",
      "\n",
      "===== All Runs Completed Successfully! =====\n",
      "\n",
      "\n",
      "===== Config Mode_Means_test Completed Successfully! =====\n",
      "\n",
      "\n",
      "===== Config Std_of_Modes_test started! =====\n",
      "\n",
      "\n",
      "===== Running Std_of_Modes_test - Run 1 =====\n",
      "\n",
      "Running Metro with std_of_modes = (1, 1)\n",
      "Running HMC with std_of_modes = (1, 1)\n",
      "Running DEMetro with std_of_modes = (1, 1)\n",
      "Running Metro with std_of_modes = (1, 4)\n",
      "Running HMC with std_of_modes = (1, 4)\n",
      "Running DEMetro with std_of_modes = (1, 4)\n",
      "Running Metro with std_of_modes = (2, 1)\n",
      "Running HMC with std_of_modes = (2, 1)\n",
      "Running DEMetro with std_of_modes = (2, 1)\n",
      "\n",
      "===== Running Std_of_Modes_test - Run 2 =====\n",
      "\n",
      "Running Metro with std_of_modes = (1, 1)\n",
      "Running HMC with std_of_modes = (1, 1)\n",
      "Running DEMetro with std_of_modes = (1, 1)\n",
      "Running Metro with std_of_modes = (1, 4)\n",
      "Running HMC with std_of_modes = (1, 4)\n",
      "Running DEMetro with std_of_modes = (1, 4)\n",
      "Running Metro with std_of_modes = (2, 1)\n",
      "Running HMC with std_of_modes = (2, 1)\n",
      "Running DEMetro with std_of_modes = (2, 1)\n",
      "\n",
      "===== All Runs Completed Successfully! =====\n",
      "\n",
      "\n",
      "===== Config Std_of_Modes_test Completed Successfully! =====\n",
      "\n",
      "\n",
      "===== Config Samples_test started! =====\n",
      "\n",
      "\n",
      "===== Running Samples_test - Run 1 =====\n",
      "\n",
      "Running Metro with num_samples = 100\n",
      "Running HMC with num_samples = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 1 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 100\n",
      "Running Metro with num_samples = 200\n",
      "Running HMC with num_samples = 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 200\n",
      "Running Metro with num_samples = 300\n",
      "Running HMC with num_samples = 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_samples = 300\n",
      "\n",
      "===== Running Samples_test - Run 2 =====\n",
      "\n",
      "Running Metro with num_samples = 100\n",
      "Running HMC with num_samples = 100\n",
      "Running DEMetro with num_samples = 100\n",
      "Running Metro with num_samples = 200\n",
      "Running HMC with num_samples = 200\n",
      "Running DEMetro with num_samples = 200\n",
      "Running Metro with num_samples = 300\n",
      "Running HMC with num_samples = 300\n",
      "Running DEMetro with num_samples = 300\n",
      "\n",
      "===== All Runs Completed Successfully! =====\n",
      "\n",
      "\n",
      "===== Config Samples_test Completed Successfully! =====\n",
      "\n",
      "\n",
      "===== Config Chains_test started! =====\n",
      "\n",
      "\n",
      "===== Running Chains_test - Run 1 =====\n",
      "\n",
      "Running Metro with num_chains = 4\n",
      "Running HMC with num_chains = 4\n",
      "Running DEMetro with num_chains = 4\n",
      "Running Metro with num_chains = 6\n",
      "Running HMC with num_chains = 6\n",
      "Running DEMetro with num_chains = 6\n",
      "Running Metro with num_chains = 8\n",
      "Running HMC with num_chains = 8\n",
      "Running DEMetro with num_chains = 8\n",
      "\n",
      "===== Running Chains_test - Run 2 =====\n",
      "\n",
      "Running Metro with num_chains = 4\n",
      "Running HMC with num_chains = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_chains = 4\n",
      "Running Metro with num_chains = 6\n",
      "Running HMC with num_chains = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 5 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_chains = 6\n",
      "Running Metro with num_chains = 8\n",
      "Running HMC with num_chains = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DEMetro with num_chains = 8\n",
      "\n",
      "===== All Runs Completed Successfully! =====\n",
      "\n",
      "\n",
      "===== Config Chains_test Completed Successfully! =====\n",
      "\n",
      "All experiments completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Choose the experiment to run\n",
    "experiment = Testcases_all_attr\n",
    "experiment_name = \"all_attr_but_init_scheme\"\n",
    "\n",
    "# Define the root directory for all experiments\n",
    "experiment_root_folder = f\"experiment_{experiment_name}\"\n",
    "os.makedirs(experiment_root_folder)\n",
    "\n",
    "#for config in experiment:\n",
    "#    validate_config(config)\n",
    "\n",
    "#print(\"All configurations are valid. Starting experiments...\")\n",
    "\n",
    "for config in experiment:\n",
    "    run_experiment(\n",
    "    posterior_type=config[\"posterior_type\"],\n",
    "    config_descr=config[\"config_descr\"],\n",
    "    runs=config[\"runs\"],\n",
    "    varying_attribute=config[\"varying_attribute\"],\n",
    "    varying_values=config[\"varying_values\"],\n",
    "    init_scheme=\"varies\" if config[\"varying_attribute\"] == \"init_scheme\" else config.get(\"init_scheme\", None),\n",
    "    num_samples=\"varies\" if config[\"varying_attribute\"] == \"num_samples\" else config[\"num_samples\"],\n",
    "    num_chains=\"varies\" if config[\"varying_attribute\"] == \"num_chains\" else config[\"num_chains\"],\n",
    "    base_random_seed=config[\"base_random_seed\"],\n",
    "    **{k: v for k, v in config.items() if k not in [\n",
    "        \"config_descr\", \"runs\", \"varying_attribute\", \"varying_values\", \n",
    "        \"num_samples\", \"num_chains\", \"init_scheme\", \n",
    "        \"base_random_seed\", \"posterior_type\"\n",
    "    ]}  # Pass remaining keys as posterior_kwargs\n",
    ")\n",
    "\n",
    "print(\"All experiments completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_immo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
